#!/usr/bin/env python3
"""
MMRS-1M DINOv3 å•å¡æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯é…ç½®æ–‡ä»¶ã€æ•°æ®é›†å’Œæ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
åœ¨è¿›è¡Œ8å¡åˆ†å¸ƒå¼è®­ç»ƒå‰çš„é¢„æ£€æŸ¥
"""

import os
import sys
import torch
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_mmrs1m_config():
    """æµ‹è¯•MMRS1Mé…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡®åŠ è½½"""
    print("ğŸ” æµ‹è¯•MMRS1Mé…ç½®æ–‡ä»¶...")
    
    try:
        from mmengine.config import Config
        
        # åŠ è½½8å¡åˆ†å¸ƒå¼é…ç½®
        config_path = project_root / "configs" / "train_dinov3_mmrs1m_t20_gcu_8card.py"
        if not config_path.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
            
        cfg = Config.fromfile(str(config_path))
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        required_keys = [
            'model', 'train_dataloader', 'val_dataloader', 
            'optim_wrapper', 'train_cfg', 'custom_imports'
        ]
        
        for key in required_keys:
            if key not in cfg:
                print(f"âŒ ç¼ºå°‘é…ç½®é¡¹: {key}")
                return False
            print(f"âœ… é…ç½®é¡¹æ£€æŸ¥é€šè¿‡: {key}")
        
        # æ£€æŸ¥æ•°æ®é›†é…ç½®
        dataset_type = cfg.get('dataset_type', 'Unknown')
        data_root = cfg.get('data_root', 'Unknown')
        num_classes = cfg.get('num_classes', 'Unknown')
        
        print(f"ğŸ“Š æ•°æ®é›†ç±»å‹: {dataset_type}")
        print(f"ğŸ“ æ•°æ®æ ¹ç›®å½•: {data_root}")
        print(f"ğŸ·ï¸ ç±»åˆ«æ•°é‡: {num_classes}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

def test_mmrs1m_dataset():
    """æµ‹è¯•MMRS1Mæ•°æ®é›†æ˜¯å¦å¯ä»¥æ­£å¸¸åŠ è½½"""
    print("\nğŸ” æµ‹è¯•MMRS1Mæ•°æ®é›†...")
    
    try:
        # æ£€æŸ¥æ•°æ®è·¯å¾„
        server_data_root = Path("/workspace/data/mmrs1m/data")
        local_data_root = project_root / "data"
        
        if server_data_root.exists():
            data_root = server_data_root
            print(f"âœ… ä½¿ç”¨æœåŠ¡å™¨æ•°æ®è·¯å¾„: {data_root}")
        elif local_data_root.exists():
            data_root = local_data_root
            print(f"âœ… ä½¿ç”¨æœ¬åœ°æ•°æ®è·¯å¾„: {data_root}")
        else:
            print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨:")
            print(f"   æœåŠ¡å™¨è·¯å¾„: {server_data_root}")
            print(f"   æœ¬åœ°è·¯å¾„: {local_data_root}")
            return False
        
        # å°è¯•å¯¼å…¥è‡ªå®šä¹‰æ•°æ®é›†
        from mmseg_custom.datasets import MMRS1MDataset
        print("âœ… MMRS1MDatasetå¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºç®€å•çš„æ•°æ®ç®¡é“
        pipeline = [
            dict(type='CustomLoadImageFromFile'),
            dict(type='CustomLoadAnnotations'),
            dict(type='CustomResize', img_scale=(512, 512), keep_ratio=True),
            dict(type='CustomNormalize', 
                 mean=[123.675, 116.28, 103.53], 
                 std=[58.395, 57.12, 57.375], 
                 to_rgb=True),
            dict(type='CustomDefaultFormatBundle'),
            dict(type='CustomCollect', keys=['img', 'gt_semantic_seg'])
        ]
        
        # åˆ›å»ºæ•°æ®é›†å®ä¾‹
        dataset = MMRS1MDataset(
            data_root=str(data_root),
            task_type='classification',
            modality='optical',
            instruction_format=True,
            pipeline=pipeline
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°é‡: {len(dataset)}")
        
        # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
        if len(dataset) > 0:
            sample = dataset[0]
            print(f"âœ… æ ·æœ¬åŠ è½½æˆåŠŸ")
            print(f"   å›¾åƒå½¢çŠ¶: {sample.get('img', 'N/A')}")
            print(f"   æ ‡ç­¾ä¿¡æ¯: {sample.get('gt_semantic_seg', 'N/A')}")
        else:
            print("âš ï¸ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸åˆ›å»º"""
    print("\nğŸ” æµ‹è¯•DINOv3æ¨¡å‹åˆ›å»º...")
    
    try:
        from mmengine.config import Config
        from mmseg.models import build_segmentor
        
        # åŠ è½½é…ç½®
        config_path = project_root / "configs" / "train_dinov3_mmrs1m_t20_gcu_8card.py"
        cfg = Config.fromfile(str(config_path))
        
        # ä¿®æ”¹é…ç½®ä»¥é€‚åº”å•å¡æµ‹è¯•
        cfg.model.train_cfg = dict()
        cfg.model.test_cfg = dict(mode='whole')
        
        # åˆ›å»ºæ¨¡å‹
        model = build_segmentor(cfg.model)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        print(f"   æ€»å‚æ•°æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        model.eval()
        dummy_input = torch.randn(1, 3, 512, 512)
        
        with torch.no_grad():
            # æµ‹è¯•æ¨ç†æ¨¡å¼
            output = model(dummy_input, mode='predict')
            print(f"âœ… æ¨¡å‹æ¨ç†æµ‹è¯•æˆåŠŸ")
            print(f"   è¾“å‡ºç±»å‹: {type(output)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_training_components():
    """æµ‹è¯•è®­ç»ƒç»„ä»¶ï¼ˆä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ç­‰ï¼‰"""
    print("\nğŸ” æµ‹è¯•è®­ç»ƒç»„ä»¶...")
    
    try:
        from mmengine.config import Config
        from mmengine.optim import build_optim_wrapper
        from mmseg.models import build_segmentor
        
        # åŠ è½½é…ç½®
        config_path = project_root / "configs" / "train_dinov3_mmrs1m_t20_gcu_8card.py"
        cfg = Config.fromfile(str(config_path))
        
        # åˆ›å»ºæ¨¡å‹
        model = build_segmentor(cfg.model)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optim_wrapper = build_optim_wrapper(model, cfg.optim_wrapper)
        print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   ä¼˜åŒ–å™¨ç±»å‹: {type(optim_wrapper.optimizer).__name__}")
        print(f"   å­¦ä¹ ç‡: {optim_wrapper.optimizer.param_groups[0]['lr']}")
        
        # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä½¿ç”¨build_param_scheduler
        print(f"âœ… å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®æ£€æŸ¥é€šè¿‡ï¼Œæ•°é‡: {len(cfg.param_scheduler)}")
        for i, scheduler_cfg in enumerate(cfg.param_scheduler):
            print(f"   è°ƒåº¦å™¨ {i+1}: {scheduler_cfg.get('type', 'Unknown')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MMRS1Må•å¡æµ‹è¯•è„šæœ¬')
    parser.add_argument('--test-all', action='store_true', help='è¿è¡Œæ‰€æœ‰æµ‹è¯•')
    parser.add_argument('--test-config', action='store_true', help='æµ‹è¯•é…ç½®æ–‡ä»¶')
    parser.add_argument('--test-dataset', action='store_true', help='æµ‹è¯•æ•°æ®é›†')
    parser.add_argument('--test-model', action='store_true', help='æµ‹è¯•æ¨¡å‹')
    parser.add_argument('--test-training', action='store_true', help='æµ‹è¯•è®­ç»ƒç»„ä»¶')
    
    args = parser.parse_args()
    
    print("ğŸš€ MMRS-1M DINOv3 å•å¡æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    test_results = []
    
    if args.test_all or args.test_config:
        test_results.append(("é…ç½®æ–‡ä»¶æµ‹è¯•", test_mmrs1m_config()))
    
    if args.test_all or args.test_dataset:
        test_results.append(("æ•°æ®é›†æµ‹è¯•", test_mmrs1m_dataset()))
    
    if args.test_all or args.test_model:
        test_results.append(("æ¨¡å‹æµ‹è¯•", test_model_creation()))
    
    if args.test_all or args.test_training:
        test_results.append(("è®­ç»ƒç»„ä»¶æµ‹è¯•", test_training_components()))
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æµ‹è¯•ï¼Œé»˜è®¤è¿è¡Œæ‰€æœ‰æµ‹è¯•
    if not any([args.test_config, args.test_dataset, args.test_model, args.test_training]):
        test_results = [
            ("é…ç½®æ–‡ä»¶æµ‹è¯•", test_mmrs1m_config()),
            ("æ•°æ®é›†æµ‹è¯•", test_mmrs1m_dataset()),
            ("æ¨¡å‹æµ‹è¯•", test_model_creation()),
            ("è®­ç»ƒç»„ä»¶æµ‹è¯•", test_training_components())
        ]
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    all_passed = True
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if not result:
            all_passed = False
    
    print("=" * 60)
    
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿›è¡Œ8å¡åˆ†å¸ƒå¼è®­ç»ƒ")
        print("ğŸš€ å¯åŠ¨8å¡è®­ç»ƒå‘½ä»¤:")
        print("   ./start_8card_mmrs1m_training.sh")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç¯å¢ƒ")
        return 1

if __name__ == "__main__":
    sys.exit(main())