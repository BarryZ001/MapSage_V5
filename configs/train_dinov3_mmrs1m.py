# DINOv3 + MMRS-1M è®­ç»ƒé…ç½®æ–‡ä»¶
# é˜¶æ®µä¸€ï¼šåŸºç¡€æ¨¡å‹è®­ç»ƒï¼Œä½¿ç”¨DINOv3-ViT-L/16ä½œä¸ºbackbone
# é’ˆå¯¹MMRS-1Må¤šæ¨¡æ€é¥æ„Ÿæ•°æ®é›†è¿›è¡Œä¼˜åŒ–

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
custom_imports = dict(
    imports=[
        'mmseg_custom.datasets',
        'mmseg_custom.transforms',
        'mmseg',
        'mmseg.models',
        'mmseg.datasets'
    ],
    allow_failed_imports=False
)

# åŸºç¡€é…ç½®
work_dir = './work_dirs/dinov3_mmrs1m_stage1'
exp_name = 'dinov3_mmrs1m_stage1'

# æ•°æ®é›†é…ç½®
dataset_type = 'MMRS1MDataset'
data_root = '/workspace/data/mmrs1m/data'  # T20æœåŠ¡å™¨è·¯å¾„ - ä¿®æ­£ä¸ºæ­£ç¡®è·¯å¾„
local_data_root = '/Users/barryzhang/myDev3/MapSage_V5/data'  # æœ¬åœ°å¼€å‘è·¯å¾„

# å›¾åƒé…ç½®
img_size = (512, 512)
crop_size = (512, 512)
num_classes = 7  # MMRS-1Mçš„ç±»åˆ«æ•°

# æ•°æ®é¢„å¤„ç†å™¨
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[123.675, 116.28, 103.53],  # ImageNetç»Ÿè®¡å€¼
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255,
    size=crop_size
)

# DINOv3-ViT-L/16 æ¨¡å‹é…ç½®
model = dict(
    type='EncoderDecoder',
    data_preprocessor=data_preprocessor,
    
    # DINOv3 ViT-Large/16 backbone
    backbone=dict(
        type='DINOv3ViT',
        arch='large',
        img_size=img_size,
        patch_size=16,
        in_channels=3,
        with_cls_token=True,
        output_cls_token=False,
        interpolate_mode='bicubic',
        out_indices=(23,),  # è¾“å‡ºæœ€åä¸€å±‚
        final_norm=True,
        drop_path_rate=0.1,
        init_cfg=dict(
            type='Pretrained',
            checkpoint='/weights/pretrained/dinov3/dinov3_vitl16_pretrain_sat493m-eadcf0ff.pth',  # ä¿®æ­£ä¸ºæ­£ç¡®æƒé‡è·¯å¾„
            prefix='backbone.'
        )
    ),
    
    # è§£ç å¤´ - ä½¿ç”¨ç®€å•çš„çº¿æ€§åˆ†ç±»å¤´
    decode_head=dict(
        type='VisionTransformerUpHead',
        in_channels=1024,
        channels=512,
        in_index=-1,
        img_size=img_size,
        embed_dims=1024,
        num_classes=num_classes,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        num_conv=2,
        upsampling_method='bilinear',
        num_upsampe_layer=2,
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=1.0,
            class_weight=None  # å¯ä»¥æ ¹æ®æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒè°ƒæ•´
        )
    ),
    
    # è¾…åŠ©å¤´ï¼ˆå¯é€‰ï¼‰
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=1024,
        in_index=-1,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=num_classes,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=0.4
        )
    ),
    
    # è®­ç»ƒé…ç½®
    train_cfg=dict(),
    test_cfg=dict(mode='whole')
)

# è®­ç»ƒæ•°æ®ç®¡é“
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='MultiModalResize',
        scale=img_size,
        modality='optical',  # é»˜è®¤å…‰å­¦æ¨¡æ€
        keep_ratio=True
    ),
    dict(
        type='MultiModalRandomCrop',
        crop_size=crop_size,
        modality='optical'
    ),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='MultiModalNormalize',
        modality='optical',
        to_rgb=True
    ),
    dict(
        type='PackSegInputs',
        meta_keys=('img_path', 'seg_map_path', 'ori_shape', 'img_shape',
                  'pad_shape', 'scale_factor', 'flip', 'flip_direction',
                  'modality', 'task_type')
    )
]

# éªŒè¯æ•°æ®ç®¡é“
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='MultiModalResize',
        scale=img_size,
        modality='optical',
        keep_ratio=True
    ),
    dict(
        type='MultiModalNormalize',
        modality='optical',
        to_rgb=True
    ),
    dict(
        type='PackSegInputs',
        meta_keys=('img_path', 'seg_map_path', 'ori_shape', 'img_shape',
                  'pad_shape', 'scale_factor', 'flip', 'flip_direction',
                  'modality', 'task_type')
    )
]

# æµ‹è¯•æ•°æ®ç®¡é“
test_pipeline = val_pipeline

# æ•°æ®é›†é…ç½®
train_dataloader = dict(
    batch_size=8,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        data_root=data_root,
        task_type='classification',  # å¼€å§‹æ—¶ä½¿ç”¨åˆ†ç±»ä»»åŠ¡
        modality='optical',
        instruction_format=True,
        pipeline=train_pipeline
    )
)

val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        data_root=data_root,
        task_type='classification',
        modality='optical',
        instruction_format=True,
        pipeline=val_pipeline
    )
)

test_dataloader = val_dataloader

# è¯„ä¼°é…ç½®
val_evaluator = dict(
    type='IoUMetric',
    iou_metrics=['mIoU', 'mDice', 'mFscore']
)
test_evaluator = val_evaluator

# ä¼˜åŒ–å™¨é…ç½® - ä½¿ç”¨AdamWï¼Œé€‚åˆViT
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW',
        lr=1e-4,  # åŸºç¡€å­¦ä¹ ç‡
        betas=(0.9, 0.999),
        weight_decay=0.05
    ),
    paramwise_cfg=dict(
        custom_keys={
            'backbone': dict(lr_mult=0.1),  # backboneä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
            'norm': dict(decay_mult=0.0),   # ä¸å¯¹normå±‚è¿›è¡Œæƒé‡è¡°å‡
            'bias': dict(decay_mult=0.0),   # ä¸å¯¹biasè¿›è¡Œæƒé‡è¡°å‡
        }
    )
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
param_scheduler = [
    dict(
        type='LinearLR',
        start_factor=1e-6,
        by_epoch=False,
        begin=0,
        end=1500  # warmupæ­¥æ•°
    ),
    dict(
        type='PolyLR',
        eta_min=1e-6,
        power=1.0,
        begin=1500,
        end=80000,  # æ€»è®­ç»ƒæ­¥æ•°
        by_epoch=False
    )
]

# è®­ç»ƒé…ç½®
train_cfg = dict(
    type='IterBasedTrainLoop',
    max_iters=80000,  # æ€»è®­ç»ƒè¿­ä»£æ•°
    val_interval=2000  # éªŒè¯é—´éš”
)

val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

# é»˜è®¤é’©å­
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(
        type='CheckpointHook',
        by_epoch=False,
        interval=2000,
        max_keep_ckpts=3,
        save_best='mIoU',
        rule='greater'
    ),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(
        type='SegVisualizationHook',
        draw=True,
        interval=1000,
        show=False,
        wait_time=0.01,
        backend_args=None
    )
)

# ç¯å¢ƒé…ç½®
env_cfg = dict(
    cudnn_benchmark=True,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl')
)

# å¯è§†åŒ–é…ç½®
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(
        type='TensorboardVisBackend',
        save_dir='./work_dirs/dinov3_mmrs1m_stage1/tf_logs'
    )
]
visualizer = dict(
    type='SegLocalVisualizer',
    vis_backends=vis_backends,
    name='visualizer'
)

# æ—¥å¿—é…ç½®
log_processor = dict(by_epoch=False)
log_level = 'INFO'
load_from = None  # ä»å¤´å¼€å§‹è®­ç»ƒ
resume = False

# éšæœºç§å­
randomness = dict(seed=42)

# è‡ªåŠ¨ç¼©æ”¾å­¦ä¹ ç‡
auto_scale_lr = dict(
    enable=True,
    base_batch_size=64  # 8 GPUs * 8 batch_size
)

# ç¼–è¯‘é…ç½®ï¼ˆPyTorch 2.0+ï¼‰
compile_cfg = dict(
    backend='inductor',
    mode='reduce-overhead'
)

# å¤šæ¨¡æ€è®­ç»ƒé…ç½®
multimodal_config = dict(
    modalities=['optical', 'sar', 'infrared'],
    modality_weights=[0.6, 0.3, 0.1],  # ä¸åŒæ¨¡æ€çš„æƒé‡
    cross_modal_learning=True,
    modal_specific_augmentation=True
)

# æŒ‡ä»¤è·Ÿéšè®­ç»ƒé…ç½®
instruction_config = dict(
    enable_instruction_tuning=True,
    instruction_templates=[
        "What is the category of this remote sensing image?",
        "Classify this satellite image.",
        "Identify the land cover type in this image.",
        "What type of terrain is shown in this remote sensing data?"
    ],
    response_format='single_word'
)

# çŸ¥è¯†è’¸é¦é…ç½®ï¼ˆå¯é€‰ï¼‰
distillation_config = dict(
    enable=False,  # ç¬¬ä¸€é˜¶æ®µä¸ä½¿ç”¨è’¸é¦
    teacher_model=None,
    distill_loss_weight=0.5,
    temperature=4.0
)

# æ¨¡å‹EMAé…ç½®
model_ema_config = dict(
    enable=True,
    momentum=0.9999,
    device='cuda'
)

# æ··åˆç²¾åº¦è®­ç»ƒ
fp16 = dict(loss_scale=512.0)

# æ¢¯åº¦ç´¯ç§¯
accumulative_counts = 2  # ç­‰æ•ˆbatch_size = 8 * 8 * 2 = 128

print(f"ğŸš€ DINOv3 + MMRS-1M è®­ç»ƒé…ç½®å·²åŠ è½½")
print(f"ğŸ“Š æ•°æ®é›†: {dataset_type}")
print(f"ğŸ—ï¸ æ¨¡å‹: DINOv3-ViT-L/16 + VisionTransformerUpHead")
print(f"ğŸ’¾ å·¥ä½œç›®å½•: {work_dir}")
print(f"ğŸ”„ æœ€å¤§è¿­ä»£æ•°: {train_cfg['max_iters']}")
batch_size = 8  # ä»train_dataloaderé…ç½®ä¸­è·å–
print(f"ğŸ“ˆ æ‰¹æ¬¡å¤§å°: {batch_size} x {accumulative_counts} = {batch_size * accumulative_counts}")