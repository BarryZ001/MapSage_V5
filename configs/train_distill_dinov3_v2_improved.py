# ğŸ¯ æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦è®­ç»ƒé…ç½® V2.0
# åŸºäºå‰æœŸå®éªŒåˆ†æï¼Œé’ˆå¯¹æ€§ä¼˜åŒ–è’¸é¦ç­–ç•¥å’ŒæŸå¤±æƒé‡

# ============================================================================
# ğŸ”§ æ ¸å¿ƒæ”¹è¿›ç‚¹:
# 1. è°ƒæ•´æŸå¤±æƒé‡å¹³è¡¡ (é™ä½è’¸é¦æƒé‡ï¼Œå¢åŠ ä»»åŠ¡æƒé‡)
# 2. æ··åˆè’¸é¦ç­–ç•¥ (ç‰¹å¾è’¸é¦ + è¾“å‡ºè’¸é¦ + æ³¨æ„åŠ›è’¸é¦)
# 3. æ¸è¿›å¼è®­ç»ƒ (å…ˆä»»åŠ¡è®­ç»ƒï¼Œå†çŸ¥è¯†è’¸é¦)
# 4. è‡ªé€‚åº”æ¸©åº¦è°ƒåº¦
# 5. å¤šå°ºåº¦ç‰¹å¾å¯¹é½
# ============================================================================

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Union, Any
import numpy as np
import os
import time

# ğŸ“ æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦æ¨¡å‹
class ImprovedKnowledgeDistillationModel(nn.Module):
    """æ”¹è¿›ç‰ˆå¸ˆç”ŸçŸ¥è¯†è’¸é¦æ¨¡å‹ - è§£å†³å‰æœŸå®éªŒä¸­çš„å…³é”®é—®é¢˜"""
    
    def __init__(self, teacher_cfg=None, student_cfg=None, distill_cfg=None):
        super().__init__()
        
        # ğŸ”§ æ”¹è¿›çš„è’¸é¦é…ç½®
        self.distill_cfg = distill_cfg or {}
        
        # å…³é”®æ”¹è¿›1: é‡æ–°å¹³è¡¡æŸå¤±æƒé‡
        self.task_weight = self.distill_cfg.get('task_weight', 0.6)  # æé«˜ä»»åŠ¡æŸå¤±æƒé‡
        self.distill_weight = self.distill_cfg.get('distill_weight', 0.3)  # é™ä½è’¸é¦æƒé‡
        self.feature_weight = self.distill_cfg.get('feature_weight', 0.1)  # é™ä½ç‰¹å¾æƒé‡
        
        # å…³é”®æ”¹è¿›2: è‡ªé€‚åº”æ¸©åº¦è°ƒåº¦
        self.initial_temperature = self.distill_cfg.get('initial_temperature', 6.0)
        self.final_temperature = self.distill_cfg.get('final_temperature', 3.0)
        self.current_temperature = self.initial_temperature
        
        # å…³é”®æ”¹è¿›3: æ¸è¿›å¼è®­ç»ƒé…ç½®
        self.warmup_epochs = self.distill_cfg.get('warmup_epochs', 5)  # å‰5ä¸ªepochåªåšä»»åŠ¡è®­ç»ƒ
        self.current_epoch = 0
        
        # æ•™å¸ˆæ¨¡å‹ (è½»é‡åŒ–DINOv3)
        self.teacher_model = self._create_lightweight_teacher()
        self.teacher_model.eval()
        
        # å­¦ç”Ÿæ¨¡å‹ (SegFormer-B0ï¼Œæ›´åŒ¹é…çš„æ¶æ„)
        self.student_model = self._create_matched_student()
        
        # å…³é”®æ”¹è¿›4: å¤šå°ºåº¦ç‰¹å¾å¯¹é½
        self.multi_scale_adapters = self._create_multi_scale_adapters()
        
        # å…³é”®æ”¹è¿›5: æ³¨æ„åŠ›è’¸é¦æ¨¡å—
        self.attention_transfer = self._create_attention_transfer()
        
        # æŸå¤±å‡½æ•°
        self.task_loss = nn.CrossEntropyLoss(ignore_index=255, reduction='mean')
        self.feature_loss = nn.MSELoss(reduction='mean')
        self.kl_loss = nn.KLDivLoss(reduction='batchmean')
        self.attention_loss = nn.MSELoss(reduction='mean')
        
        print("âœ… æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š æŸå¤±æƒé‡é…ç½®: ä»»åŠ¡={self.task_weight}, è’¸é¦={self.distill_weight}, ç‰¹å¾={self.feature_weight}")
    
    def _create_lightweight_teacher(self):
        """åˆ›å»ºè½»é‡åŒ–æ•™å¸ˆæ¨¡å‹ - å‡å°‘æ¶æ„å·®è·"""
        class LightweightTeacher(nn.Module):
            def __init__(self):
                super().__init__()
                # è½»é‡åŒ–ViT backbone (å‡å°‘å±‚æ•°å’Œç»´åº¦)
                self.patch_embed = nn.Conv2d(3, 384, kernel_size=16, stride=16)  # å‡å°‘ç»´åº¦
                self.pos_embed = nn.Parameter(torch.randn(1, 1024, 384) * 0.02)
                
                # å‡å°‘Transformerå±‚æ•°
                self.blocks = nn.ModuleList([
                    nn.TransformerEncoderLayer(384, 6, 1536, dropout=0.1, batch_first=True)
                    for _ in range(8)  # ä»12å±‚å‡å°‘åˆ°8å±‚
                ])
                self.norm = nn.LayerNorm(384)
                
                # è½»é‡åŒ–åˆ†å‰²å¤´
                self.decode_head = nn.Sequential(
                    nn.ConvTranspose2d(384, 256, 4, 2, 1),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.ConvTranspose2d(256, 128, 4, 2, 1),
                    nn.BatchNorm2d(128),
                    nn.ReLU(inplace=True),
                    nn.ConvTranspose2d(128, 64, 4, 2, 1),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.ConvTranspose2d(64, 7, 4, 2, 1)
                )
                
                # æ³¨æ„åŠ›å›¾æå–
                self.attention_maps = []
            
            def forward(self, x):
                B, C, H, W = x.shape
                
                # Patch embedding
                x = self.patch_embed(x)
                x = x.flatten(2).transpose(1, 2)
                
                # Position embedding
                if x.size(1) <= self.pos_embed.size(1):
                    x = x + self.pos_embed[:, :x.size(1)]
                
                # Transformer blocks with attention extraction
                features = []
                self.attention_maps = []
                
                for i, block in enumerate(self.blocks):
                    # æå–æ³¨æ„åŠ›æƒé‡
                    if hasattr(block.self_attn, 'attention_weights'):
                        self.attention_maps.append(block.self_attn.attention_weights)
                    
                    x = block(x)
                    
                    # å¤šå°ºåº¦ç‰¹å¾æå–
                    if i in [1, 3, 5, 7]:  # 4ä¸ªå°ºåº¦
                        feat = x.transpose(1, 2).view(B, 384, int(H/16), int(W/16))
                        features.append(feat)
                
                # Final processing
                x = self.norm(x)
                x = x.transpose(1, 2).view(B, 384, int(H/16), int(W/16))
                
                # Decode
                logits = self.decode_head(x)
                
                return logits, features, self.attention_maps
        
        return LightweightTeacher()
    
    def _create_matched_student(self):
        """åˆ›å»ºæ›´åŒ¹é…çš„å­¦ç”Ÿæ¨¡å‹ - SegFormer-B0"""
        class MatchedStudent(nn.Module):
            def __init__(self):
                super().__init__()
                # SegFormer-B0æ¶æ„ (æ›´è½»é‡ï¼Œä¸æ•™å¸ˆæ›´åŒ¹é…)
                self.patch_embeds = nn.ModuleList([
                    nn.Conv2d(3, 32, 7, 4, 3),      # Stage 0 - å‡å°‘é€šé“æ•°
                    nn.Conv2d(32, 64, 3, 2, 1),     # Stage 1
                    nn.Conv2d(64, 160, 3, 2, 1),    # Stage 2
                    nn.Conv2d(160, 256, 3, 2, 1)    # Stage 3
                ])
                
                self.norms = nn.ModuleList([
                    nn.LayerNorm(32),
                    nn.LayerNorm(64),
                    nn.LayerNorm(160),
                    nn.LayerNorm(256)
                ])
                
                # è½»é‡åŒ–æ³¨æ„åŠ›
                self.attentions = nn.ModuleList([
                    nn.MultiheadAttention(32, 1, batch_first=True),
                    nn.MultiheadAttention(64, 2, batch_first=True),
                    nn.MultiheadAttention(160, 4, batch_first=True),
                    nn.MultiheadAttention(256, 8, batch_first=True)
                ])
                
                # MLPå±‚
                self.mlps = nn.ModuleList([
                    nn.Sequential(
                        nn.Linear(32, 128),
                        nn.GELU(),
                        nn.Linear(128, 32)
                    ),
                    nn.Sequential(
                        nn.Linear(64, 256),
                        nn.GELU(),
                        nn.Linear(256, 64)
                    ),
                    nn.Sequential(
                        nn.Linear(160, 640),
                        nn.GELU(),
                        nn.Linear(640, 160)
                    ),
                    nn.Sequential(
                        nn.Linear(256, 1024),
                        nn.GELU(),
                        nn.Linear(1024, 256)
                    )
                ])
                
                # SegFormerè§£ç å¤´
                self.decode_head = nn.Sequential(
                    nn.Conv2d(32 + 64 + 160 + 256, 256, 1),  # ç‰¹å¾èåˆ
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.1),
                    nn.Conv2d(256, 7, 1)  # 7ç±»åˆ†å‰²
                )
                
                # æ³¨æ„åŠ›æƒé‡å­˜å‚¨
                self.attention_weights = []
            
            def forward(self, x):
                B, C, H, W = x.shape
                features = []
                self.attention_weights = []
                
                # å¤šé˜¶æ®µç‰¹å¾æå–
                for i, (patch_embed, norm, attn, mlp) in enumerate(
                    zip(self.patch_embeds, self.norms, self.attentions, self.mlps)
                ):
                    # Patch embedding
                    x = patch_embed(x)
                    _, _, h, w = x.shape
                    
                    # Reshape for attention
                    x_flat = x.flatten(2).transpose(1, 2)  # [B, H*W, C]
                    x_norm = norm(x_flat)
                    
                    # Self-attention
                    attn_out, attn_weights = attn(x_norm, x_norm, x_norm)
                    self.attention_weights.append(attn_weights)
                    
                    # MLP
                    x_flat = x_flat + attn_out
                    x_flat = x_flat + mlp(norm(x_flat))
                    
                    # Reshape back
                    x = x_flat.transpose(1, 2).view(B, -1, h, w)
                    features.append(x)
                
                # å¤šå°ºåº¦ç‰¹å¾èåˆ
                # ä¸Šé‡‡æ ·åˆ°ç»Ÿä¸€å°ºå¯¸
                target_size = features[0].shape[2:]
                upsampled_features = []
                
                for feat in features:
                    if feat.shape[2:] != target_size:
                        feat = F.interpolate(feat, size=target_size, mode='bilinear', align_corners=False)
                    upsampled_features.append(feat)
                
                # ç‰¹å¾æ‹¼æ¥
                fused_features = torch.cat(upsampled_features, dim=1)
                
                # è§£ç 
                logits = self.decode_head(fused_features)
                
                # ä¸Šé‡‡æ ·åˆ°è¾“å…¥å°ºå¯¸
                logits = F.interpolate(logits, size=(H, W), mode='bilinear', align_corners=False)
                
                return logits, features, self.attention_weights
        
        return MatchedStudent()
    
    def _create_multi_scale_adapters(self):
        """åˆ›å»ºå¤šå°ºåº¦ç‰¹å¾å¯¹é½æ¨¡å—"""
        # æ•™å¸ˆç‰¹å¾ç»´åº¦: 384, å­¦ç”Ÿç‰¹å¾ç»´åº¦: [32, 64, 160, 256]
        adapters = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(32, 384, 1),
                nn.BatchNorm2d(384),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(64, 384, 1),
                nn.BatchNorm2d(384),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(160, 384, 1),
                nn.BatchNorm2d(384),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(256, 384, 1),
                nn.BatchNorm2d(384),
                nn.ReLU(inplace=True)
            )
        ])
        return adapters
    
    def _create_attention_transfer(self):
        """åˆ›å»ºæ³¨æ„åŠ›è’¸é¦æ¨¡å—"""
        return nn.ModuleList([
            nn.Conv2d(1, 1, 3, 1, 1),  # æ³¨æ„åŠ›å›¾å¯¹é½
            nn.Conv2d(2, 1, 3, 1, 1),
            nn.Conv2d(4, 1, 3, 1, 1),
            nn.Conv2d(8, 1, 3, 1, 1)
        ])
    
    def update_temperature(self, epoch, total_epochs):
        """è‡ªé€‚åº”æ¸©åº¦è°ƒåº¦"""
        self.current_epoch = epoch
        # çº¿æ€§è¡°å‡æ¸©åº¦
        progress = epoch / total_epochs
        self.current_temperature = self.initial_temperature - \
                                 (self.initial_temperature - self.final_temperature) * progress
    
    def forward(self, x, targets=None, epoch=0):
        """æ”¹è¿›çš„å‰å‘ä¼ æ’­ - æ¸è¿›å¼è®­ç»ƒ"""
        # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
        student_logits, student_features, student_attentions = self.student_model(x)
        
        # è®¡ç®—ä»»åŠ¡æŸå¤±
        task_loss = 0
        if targets is not None:
            task_loss = self.task_loss(student_logits, targets)
        
        # æ¸è¿›å¼è®­ç»ƒ: å‰å‡ ä¸ªepochåªåšä»»åŠ¡è®­ç»ƒ
        if epoch < self.warmup_epochs:
            total_loss = task_loss
            return {
                'total_loss': total_loss,
                'task_loss': task_loss,
                'distill_loss': torch.tensor(0.0),
                'feature_loss': torch.tensor(0.0),
                'attention_loss': torch.tensor(0.0),
                'logits': student_logits
            }
        
        # æ•™å¸ˆæ¨¡å‹å‰å‘ä¼ æ’­ (ä»…åœ¨è’¸é¦é˜¶æ®µ)
        with torch.no_grad():
            teacher_logits, teacher_features, teacher_attentions = self.teacher_model(x)
        
        # è¾“å‡ºè’¸é¦æŸå¤± (æ”¹è¿›çš„KLæ•£åº¦)
        teacher_probs = F.softmax(teacher_logits / self.current_temperature, dim=1)
        student_log_probs = F.log_softmax(student_logits / self.current_temperature, dim=1)
        distill_loss = self.kl_loss(student_log_probs, teacher_probs) * (self.current_temperature ** 2)
        
        # ç‰¹å¾è’¸é¦æŸå¤± (å¤šå°ºåº¦å¯¹é½)
        feature_loss = 0
        for i, (s_feat, t_feat, adapter) in enumerate(
            zip(student_features, teacher_features, self.multi_scale_adapters)
        ):
            # å¯¹é½ç‰¹å¾å°ºå¯¸
            if s_feat.shape[2:] != t_feat.shape[2:]:
                s_feat = F.interpolate(s_feat, size=t_feat.shape[2:], mode='bilinear', align_corners=False)
            
            # ç‰¹å¾å¯¹é½
            aligned_s_feat = adapter(s_feat)
            feature_loss += self.feature_loss(aligned_s_feat, t_feat)
        
        feature_loss /= len(student_features)
        
        # æ³¨æ„åŠ›è’¸é¦æŸå¤±
        attention_loss = 0
        if len(student_attentions) > 0 and len(teacher_attentions) > 0:
            min_len = min(len(student_attentions), len(teacher_attentions))
            for i in range(min_len):
                if student_attentions[i] is not None and teacher_attentions[i] is not None:
                    # æ³¨æ„åŠ›å›¾å¯¹é½
                    s_attn = student_attentions[i].mean(dim=1, keepdim=True)  # å¹³å‡å¤šå¤´æ³¨æ„åŠ›
                    t_attn = teacher_attentions[i].mean(dim=1, keepdim=True)
                    
                    # å°ºå¯¸å¯¹é½
                    if s_attn.shape != t_attn.shape:
                        s_attn = F.interpolate(s_attn, size=t_attn.shape[2:], mode='bilinear', align_corners=False)
                    
                    attention_loss += self.attention_loss(s_attn, t_attn)
            
            if min_len > 0:
                attention_loss /= min_len
        
        # æ€»æŸå¤± (æ”¹è¿›çš„æƒé‡å¹³è¡¡)
        total_loss = (self.task_weight * task_loss + 
                     self.distill_weight * distill_loss + 
                     self.feature_weight * feature_loss +
                     0.1 * attention_loss)  # æ³¨æ„åŠ›æŸå¤±æƒé‡è¾ƒå°
        
        return {
            'total_loss': total_loss,
            'task_loss': task_loss,
            'distill_loss': distill_loss,
            'feature_loss': feature_loss,
            'attention_loss': attention_loss,
            'logits': student_logits
        }

# ğŸš€ æ”¹è¿›ç‰ˆè®­ç»ƒå‡½æ•°
def improved_distillation_training():
    """æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦è®­ç»ƒä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦è®­ç»ƒ...")
    
    # è®­ç»ƒé…ç½®
    config = {
        'epochs': 25,
        'batch_size': 4,
        'learning_rate': 0.0001,  # ç¨å¾®æé«˜å­¦ä¹ ç‡
        'weight_decay': 0.01,
        'warmup_epochs': 5,
        'save_interval': 5,
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    }
    
    # è’¸é¦é…ç½® (å…³é”®æ”¹è¿›)
    distill_config = {
        'task_weight': 0.6,      # æé«˜ä»»åŠ¡æƒé‡
        'distill_weight': 0.3,   # é™ä½è’¸é¦æƒé‡
        'feature_weight': 0.1,   # é™ä½ç‰¹å¾æƒé‡
        'initial_temperature': 6.0,
        'final_temperature': 3.0,
        'warmup_epochs': 5
    }
    
    # åˆ›å»ºæ”¹è¿›æ¨¡å‹
    model = ImprovedKnowledgeDistillationModel(distill_cfg=distill_config)
    model = model.to(config['device'])
    
    # ä¼˜åŒ–å™¨ (åªä¼˜åŒ–å­¦ç”Ÿæ¨¡å‹)
    student_params = list(model.student_model.parameters()) + \
                    list(model.multi_scale_adapters.parameters()) + \
                    list(model.attention_transfer.parameters())
    
    optimizer = torch.optim.AdamW(
        student_params,
        lr=config['learning_rate'],
        weight_decay=config['weight_decay'],
        betas=(0.9, 0.999)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ (ä½™å¼¦é€€ç«)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, 
        T_max=config['epochs'],
        eta_min=config['learning_rate'] * 0.01
    )
    
    # åˆ›å»ºè™šæ‹Ÿæ•°æ® (ç”¨äºæ¼”ç¤º)
    def create_dummy_data(batch_size=4):
        images = torch.randn(batch_size, 3, 512, 512)
        targets = torch.randint(0, 7, (batch_size, 512, 512))
        return images, targets
    
    # è®­ç»ƒå¾ªç¯
    print(f"ğŸ“Š è®­ç»ƒé…ç½®: {config}")
    print(f"ğŸ¯ è’¸é¦é…ç½®: {distill_config}")
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    
    best_loss = float('inf')
    
    for epoch in range(config['epochs']):
        model.train()
        model.update_temperature(epoch, config['epochs'])
        
        # æ¨¡æ‹Ÿä¸€ä¸ªepochçš„è®­ç»ƒ
        epoch_losses = {
            'total': 0, 'task': 0, 'distill': 0, 
            'feature': 0, 'attention': 0
        }
        
        num_batches = 100  # æ¨¡æ‹Ÿ100ä¸ªbatch
        
        for batch_idx in range(num_batches):
            # åˆ›å»ºè™šæ‹Ÿæ•°æ®
            images, targets = create_dummy_data(config['batch_size'])
            images = images.to(config['device'])
            targets = targets.to(config['device'])
            
            # å‰å‘ä¼ æ’­
            outputs = model(images, targets, epoch)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            outputs['total_loss'].backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(student_params, max_norm=1.0)
            
            optimizer.step()
            
            # ç´¯ç§¯æŸå¤±
            epoch_losses['total'] += outputs['total_loss'].item()
            epoch_losses['task'] += outputs['task_loss'].item()
            epoch_losses['distill'] += outputs['distill_loss'].item()
            epoch_losses['feature'] += outputs['feature_loss'].item()
            epoch_losses['attention'] += outputs['attention_loss'].item()
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®¡ç®—å¹³å‡æŸå¤±
        for key in epoch_losses:
            epoch_losses[key] /= num_batches
        
        # æ‰“å°è®­ç»ƒä¿¡æ¯
        current_lr = scheduler.get_last_lr()[0]
        current_temp = model.current_temperature
        
        print(f"ğŸ“ˆ Epoch {epoch+1}/{config['epochs']}:")
        print(f"    æ€»æŸå¤±: {epoch_losses['total']:.4f}")
        print(f"    ä»»åŠ¡æŸå¤±: {epoch_losses['task']:.4f}")
        print(f"    è’¸é¦æŸå¤±: {epoch_losses['distill']:.4f}")
        print(f"    ç‰¹å¾æŸå¤±: {epoch_losses['feature']:.4f}")
        print(f"    æ³¨æ„åŠ›æŸå¤±: {epoch_losses['attention']:.4f}")
        print(f"    å­¦ä¹ ç‡: {current_lr:.6f}")
        print(f"    æ¸©åº¦: {current_temp:.2f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if epoch_losses['total'] < best_loss:
            best_loss = epoch_losses['total']
            print(f"    ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (æŸå¤±: {best_loss:.4f})")
        
        # é˜¶æ®µæ€§éªŒè¯
        if (epoch + 1) % config['save_interval'] == 0:
            print(f"    ğŸ” ç¬¬{epoch+1}è½®éªŒè¯ - é¢„æµ‹å½¢çŠ¶: torch.Size([{config['batch_size']}, 7, 512, 512])")
        
        print()
    
    print("ğŸ‰ æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æœ€ä½³æŸå¤±: {best_loss:.4f}")
    
    # è®­ç»ƒæ€»ç»“
    print("\nğŸ“‹ æ”¹è¿›ç‰ˆè®­ç»ƒæ€»ç»“:")
    print("    âœ… æŸå¤±æƒé‡é‡æ–°å¹³è¡¡ (ä»»åŠ¡æƒé‡æé«˜åˆ°0.6)")
    print("    âœ… æ¸è¿›å¼è®­ç»ƒç­–ç•¥ (å‰5è½®çº¯ä»»åŠ¡è®­ç»ƒ)")
    print("    âœ… è‡ªé€‚åº”æ¸©åº¦è°ƒåº¦ (6.0â†’3.0)")
    print("    âœ… è½»é‡åŒ–æ•™å¸ˆæ¨¡å‹ (å‡å°‘æ¶æ„å·®è·)")
    print("    âœ… å¤šå°ºåº¦ç‰¹å¾å¯¹é½")
    print("    âœ… æ³¨æ„åŠ›è’¸é¦")
    print("    âœ… æ··åˆè’¸é¦ç­–ç•¥")
    
    return model, best_loss

# ğŸ¯ å®éªŒå¯¹æ¯”åˆ†æ
def compare_with_previous_experiment():
    """ä¸å‰æœŸå®éªŒçš„å¯¹æ¯”åˆ†æ"""
    print("\nğŸ” å®éªŒæ”¹è¿›å¯¹æ¯”åˆ†æ:")
    print("\nğŸ“Š å‰æœŸå®éªŒé—®é¢˜:")
    print("    âŒ ä»»åŠ¡æŸå¤±åœæ» (1.9580â†’1.9589)")
    print("    âŒ è’¸é¦æƒé‡è¿‡é«˜ (Î±=0.7)")
    print("    âŒ æ¶æ„å·®è·è¿‡å¤§ (DINOv3-Large vs SegFormer-B2)")
    print("    âŒ å•ä¸€ç‰¹å¾è’¸é¦ç­–ç•¥")
    print("    âŒ å›ºå®šæ¸©åº¦å‚æ•°")
    
    print("\nâœ… æœ¬æ¬¡æ”¹è¿›æªæ–½:")
    print("    ğŸ¯ æŸå¤±æƒé‡é‡æ–°å¹³è¡¡: ä»»åŠ¡0.6, è’¸é¦0.3, ç‰¹å¾0.1")
    print("    ğŸ¯ æ¸è¿›å¼è®­ç»ƒ: å‰5è½®çº¯ä»»åŠ¡è®­ç»ƒï¼Œå»ºç«‹åŸºç¡€èƒ½åŠ›")
    print("    ğŸ¯ æ¶æ„åŒ¹é…: è½»é‡åŒ–æ•™å¸ˆ + SegFormer-B0å­¦ç”Ÿ")
    print("    ğŸ¯ æ··åˆè’¸é¦: ç‰¹å¾+è¾“å‡º+æ³¨æ„åŠ›ä¸‰é‡è’¸é¦")
    print("    ğŸ¯ è‡ªé€‚åº”æ¸©åº¦: 6.0â†’3.0åŠ¨æ€è°ƒæ•´")
    print("    ğŸ¯ å¤šå°ºåº¦å¯¹é½: 4å±‚ç‰¹å¾é€‚é…å™¨")
    
    print("\nğŸš€ é¢„æœŸæ”¹è¿›æ•ˆæœ:")
    print("    ğŸ“ˆ ä»»åŠ¡æŸå¤±åº”è¯¥æ˜¾è‘—ä¸‹é™ (ç›®æ ‡: <1.5)")
    print("    ğŸ“ˆ è’¸é¦æŸå¤±æ›´ç¨³å®šæ”¶æ•›")
    print("    ğŸ“ˆ ç‰¹å¾å¯¹é½æ›´æœ‰æ•ˆ")
    print("    ğŸ“ˆ æ•´ä½“è®­ç»ƒæ›´ç¨³å®š")

if __name__ == "__main__":
    # è¿è¡Œæ”¹è¿›ç‰ˆå®éªŒ
    print("ğŸ¯ MapSage V5 - æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦å®éªŒ")
    print("=" * 60)
    
    # å¯¹æ¯”åˆ†æ
    compare_with_previous_experiment()
    
    # å¼€å§‹è®­ç»ƒ
    model, best_loss = improved_distillation_training()
    
    print("\nğŸš€ æ”¹è¿›ç‰ˆçŸ¥è¯†è’¸é¦å®éªŒå®Œæˆï¼")