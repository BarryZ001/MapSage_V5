# DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒé…ç½®æ–‡ä»¶ - ç‡§åŸT20 GCUç‰ˆæœ¬
# é˜¶æ®µä¸€ï¼šåŸºç¡€æ¨¡å‹è®­ç»ƒï¼Œä½¿ç”¨DINOv3-ViT-L/16ä½œä¸ºbackbone
# é’ˆå¯¹MMRS-1Må¤šæ¨¡æ€é¥æ„Ÿæ•°æ®é›†è¿›è¡Œä¼˜åŒ–
# ä¸“é—¨é€‚é…ç‡§åŸT20 GCUè®¡ç®—ç¯å¢ƒ - 8å¡åˆ†å¸ƒå¼è®­ç»ƒ

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
custom_imports = dict(
    imports=[
        'mmseg_custom.datasets',
        'mmseg_custom.transforms',
        'mmseg',
        'mmseg.models',
        'mmseg.datasets'
    ],
    allow_failed_imports=False
)

# åŸºç¡€é…ç½®
work_dir = './work_dirs/dinov3_mmrs1m_t20_gcu_8card'
exp_name = 'dinov3_mmrs1m_t20_gcu_8card'

# æ•°æ®é›†é…ç½®
dataset_type = 'MMRS1MDataset'
data_root = '/workspace/data/mmrs1m/data'  # T20æœåŠ¡å™¨è·¯å¾„
local_data_root = '/Users/barryzhang/myDev3/MapSage_V5/data'  # æœ¬åœ°å¼€å‘è·¯å¾„

# å›¾åƒé…ç½®
img_size = (512, 512)
crop_size = (512, 512)
num_classes = 7  # MMRS-1Mçš„ç±»åˆ«æ•°

# å›¾åƒå½’ä¸€åŒ–é…ç½®
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], 
    std=[58.395, 57.12, 57.375], 
    to_rgb=True
)

# æ•°æ®é¢„å¤„ç†å™¨
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[123.675, 116.28, 103.53],  # ImageNetç»Ÿè®¡å€¼
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255,
    size=crop_size
)

# DINOv3-ViT-L/16 æ¨¡å‹é…ç½®
model = dict(
    type='EncoderDecoder',
    data_preprocessor=data_preprocessor,
    
    # DINOv3 backbone
    backbone=dict(
        type='DINOv3ViT',
        arch='large',
        img_size=img_size,
        patch_size=16,
        in_channels=3,
        with_cls_token=True,
        output_cls_token=False,
        interpolate_mode='bicubic',
        out_indices=(23,),  # è¾“å‡ºæœ€åä¸€å±‚
        final_norm=True,
        drop_path_rate=0.1,
        init_cfg=None  # ç§»é™¤é¢„è®­ç»ƒæƒé‡é…ç½®ï¼Œä½¿ç”¨é»˜è®¤åˆå§‹åŒ–
    ),
    
    # è§£ç å¤´
    decode_head=dict(
        type='VisionTransformerUpHead',
        in_channels=1024,
        channels=512,
        in_index=-1,
        img_size=img_size,
        embed_dims=1024,
        num_classes=num_classes,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        num_conv=2,
        upsampling_method='bilinear',
        num_upsampe_layer=2,
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=1.0,
            class_weight=None  # å¯ä»¥æ ¹æ®æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒè°ƒæ•´
        )
    ),
    
    # è¾…åŠ©å¤´
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=1024,
        in_index=-1,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=num_classes,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=0.4
        )
    ),
    
    # è®­ç»ƒå’Œæµ‹è¯•é…ç½®
    train_cfg=dict(),
    test_cfg=dict(mode='whole')
)

# æ•°æ®å¤„ç†ç®¡é“
train_pipeline = [
    dict(type='CustomLoadImageFromFile'),
    dict(type='CustomLoadAnnotations'),
    dict(
        type='CustomResize',
        img_scale=img_size,
        keep_ratio=True
    ),
    dict(
        type='RandomCrop',
        crop_size=crop_size,
        cat_max_ratio=0.75
    ),
    dict(type='CustomRandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='CustomNormalize', **img_norm_cfg),
    dict(type='CustomPad', size=crop_size, pad_val=0, seg_pad_val=255),
    dict(type='CustomDefaultFormatBundle'),
    dict(type='CustomCollect', keys=['img', 'gt_semantic_seg'])
]

# éªŒè¯ç®¡é“
val_pipeline = [
    dict(type='CustomLoadImageFromFile'),
    dict(type='CustomLoadAnnotations'),
    dict(
        type='CustomResize',
        img_scale=img_size,
        keep_ratio=True
    ),
    dict(type='CustomNormalize', **img_norm_cfg),
    dict(type='CustomDefaultFormatBundle'),
    dict(type='CustomCollect', keys=['img', 'gt_semantic_seg'])
]

# æµ‹è¯•ç®¡é“
test_pipeline = val_pipeline

# æ•°æ®åŠ è½½å™¨é…ç½® - 8å¡åˆ†å¸ƒå¼è®­ç»ƒ
train_dataloader = dict(
    batch_size=2,  # æ¯å¡batch_sizeï¼Œæ€»batch_size = 2 * 8 = 16
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        data_root=data_root,
        task_type='classification',  # å¼€å§‹æ—¶ä½¿ç”¨åˆ†ç±»ä»»åŠ¡
        modality='optical',
        instruction_format=True,
        pipeline=train_pipeline
    )
)

# éªŒè¯æ•°æ®åŠ è½½å™¨
val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        data_root=data_root,
        task_type='classification',
        modality='optical',
        instruction_format=True,
        pipeline=val_pipeline
    )
)

# æµ‹è¯•æ•°æ®åŠ è½½å™¨
test_dataloader = val_dataloader

# è¯„ä¼°å™¨
val_evaluator = dict(
    type='IoUMetric',
    iou_metrics=['mIoU', 'mDice', 'mFscore']
)
test_evaluator = val_evaluator

# ä¼˜åŒ–å™¨é…ç½® - 8å¡åˆ†å¸ƒå¼è®­ç»ƒ
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW',
        lr=1e-4,  # 8å¡è®­ç»ƒä½¿ç”¨æ›´é«˜å­¦ä¹ ç‡
        betas=(0.9, 0.999),
        weight_decay=0.05
    ),
    paramwise_cfg=dict(
        custom_keys={
            'backbone': dict(lr_mult=0.1),  # backboneä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
            'norm': dict(decay_mult=0.0),   # ä¸å¯¹normå±‚è¿›è¡Œæƒé‡è¡°å‡
            'bias': dict(decay_mult=0.0),   # ä¸å¯¹biasè¿›è¡Œæƒé‡è¡°å‡
        }
    )
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
param_scheduler = [
    dict(
        type='LinearLR',
        start_factor=1e-6,
        by_epoch=False,
        begin=0,
        end=1000  # warmupæ­¥æ•°
    ),
    dict(
        type='PolyLR',
        eta_min=1e-6,
        power=1.0,
        begin=1000,
        end=40000,  # 8å¡è®­ç»ƒå‡å°‘æ€»æ­¥æ•°
        by_epoch=False
    )
]

# è®­ç»ƒé…ç½®
train_cfg = dict(
    type='IterBasedTrainLoop',
    max_iters=40000,  # 8å¡è®­ç»ƒå‡å°‘æ€»è¿­ä»£æ•°
    val_interval=1000  # éªŒè¯é—´éš”
)

val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

# é»˜è®¤é’©å­
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(
        type='CheckpointHook',
        by_epoch=False,
        interval=1000,
        max_keep_ckpts=3,
        save_best='mIoU',
        rule='greater'
    ),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(
        type='SegVisualizationHook',
        draw=True,
        interval=500,
        show=False,
        wait_time=0.01,
        backend_args=None
    )
)

# ç¯å¢ƒé…ç½® - é€‚é…GCUåˆ†å¸ƒå¼è®­ç»ƒï¼Œç§»é™¤è®¾å¤‡ç›¸å…³é…ç½®
env_cfg = dict(
    cudnn_benchmark=False,  # GCUç¯å¢ƒå…³é—­cudnn
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='gloo')  # ä½¿ç”¨glooåç«¯é€‚é…GCUï¼Œè®¾å¤‡é…ç½®ç”±è®­ç»ƒè„šæœ¬å¤„ç†
)

# ç§»é™¤device_cfgé…ç½®ï¼Œé¿å…ä¸è„šæœ¬ä¸­çš„è®¾å¤‡ç®¡ç†å†²çª
# æ‰€æœ‰è®¾å¤‡é…ç½®éƒ½ç”±è®­ç»ƒè„šæœ¬åŠ¨æ€å¤„ç†ï¼Œç¡®ä¿æ¨¡å‹æ­£ç¡®ç§»åŠ¨åˆ°GCUè®¾å¤‡
# device_cfg = dict(
#     type='gcu',  # æŒ‡å®šä½¿ç”¨GCUè®¾å¤‡
#     device_ids=[0, 1, 2, 3, 4, 5, 6, 7],  # ä½¿ç”¨æ‰€æœ‰8ä¸ªGCUè®¾å¤‡
# )

# å¯è§†åŒ–é…ç½®
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(
        type='TensorboardVisBackend',
        save_dir='./work_dirs/dinov3_mmrs1m_t20_gcu_8card/tf_logs'
    )
]
visualizer = dict(
    type='SegLocalVisualizer',
    vis_backends=vis_backends,
    name='visualizer'
)

# æ—¥å¿—é…ç½®
log_processor = dict(by_epoch=False)
log_level = 'INFO'
load_from = None  # ä»å¤´å¼€å§‹è®­ç»ƒ
resume = False

# éšæœºæ€§é…ç½®
randomness = dict(seed=42)

# è‡ªåŠ¨å­¦ä¹ ç‡ç¼©æ”¾ - 8å¡åˆ†å¸ƒå¼è®­ç»ƒ
auto_scale_lr = dict(
    enable=True,
    base_batch_size=16  # 8 GCUs * 2 batch_size = 16
)

# å¤šæ¨¡æ€é…ç½®
multimodal_config = dict(
    modalities=['optical', 'sar', 'infrared'],
    modality_weights=[0.6, 0.3, 0.1],  # ä¸åŒæ¨¡æ€çš„æƒé‡
    cross_modal_learning=True,
    modal_specific_augmentation=True
)

# æŒ‡ä»¤é…ç½®
instruction_config = dict(
    enable_instruction_tuning=True,
    instruction_templates=[
        "What is the category of this remote sensing image?",
        "Classify this satellite image.",
        "Identify the land cover type in this image.",
        "What type of terrain is shown in this remote sensing data?"
    ],
    response_format='single_word'
)

# è’¸é¦é…ç½®
distillation_config = dict(
    enable=False,  # ç¬¬ä¸€é˜¶æ®µä¸ä½¿ç”¨è’¸é¦
    teacher_model=None,
    distill_loss_weight=0.5,
    temperature=4.0
)

# EMAé…ç½® - ç§»é™¤ç¡¬ç¼–ç è®¾å¤‡é…ç½®ï¼Œè®©è®­ç»ƒè„šæœ¬åŠ¨æ€è®¾ç½®
model_ema_config = dict(
    enable=False,  # æš‚æ—¶ç¦ç”¨EMAä»¥é¿å…è®¾å¤‡å†²çª
    momentum=0.9999
    # deviceé…ç½®ç”±è®­ç»ƒè„šæœ¬åŠ¨æ€è®¾ç½®
)

# æ··åˆç²¾åº¦è®­ç»ƒ
fp16 = dict(loss_scale=512.0)

# æ¢¯åº¦ç´¯ç§¯
accumulative_counts = 1  # 8å¡è®­ç»ƒä¸éœ€è¦æ¢¯åº¦ç´¯ç§¯

print(f"ğŸš€ DINOv3 + MMRS-1M ç‡§åŸT20 GCU 8å¡åˆ†å¸ƒå¼è®­ç»ƒé…ç½®å·²åŠ è½½")
print(f"ğŸ“Š æ•°æ®é›†: {dataset_type}")
print(f"ğŸ—ï¸ æ¨¡å‹: DINOv3-ViT-L/16 + VisionTransformerUpHead")
print(f"ğŸ’¾ å·¥ä½œç›®å½•: {work_dir}")
print(f"ğŸ”„ æœ€å¤§è¿­ä»£æ•°: {train_cfg['max_iters']}")
batch_size = 2  # ä»train_dataloaderé…ç½®ä¸­è·å–
print(f"ğŸ“ˆ æ‰¹æ¬¡å¤§å°: {batch_size} x 8 cards = {batch_size * 8}")
print(f"ğŸ”¥ è®¡ç®—ç¯å¢ƒ: ç‡§åŸT20 GCU - 8å¡åˆ†å¸ƒå¼è®­ç»ƒ")
print(f"âš™ï¸ è®¾å¤‡é…ç½®: ç”±è®­ç»ƒè„šæœ¬åŠ¨æ€å¤„ç†ï¼Œç¡®ä¿æ¨¡å‹æ­£ç¡®ç§»åŠ¨åˆ°GCUè®¾å¤‡")