# DINOv3 + LoveDA è®­ç»ƒé…ç½®æ–‡ä»¶ - ç‡§åŸT20 GCUç‰ˆæœ¬
# é˜¶æ®µäºŒï¼šåœ¨LoveDAæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒ
# ä½¿ç”¨DINOv3-ViT-L/16ä½œä¸ºbackbone
# ä¸“é—¨é€‚é…ç‡§åŸT20 GCUè®¡ç®—ç¯å¢ƒ

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
custom_imports = dict(
    imports=[
        'mmseg_custom.datasets',
        'mmseg_custom.transforms',
        'mmseg',
        'mmseg.models',
        'mmseg.datasets',
        'mmseg.visualization'  # æ·»åŠ å¯è§†åŒ–æ¨¡å—å¯¼å…¥
    ],
    allow_failed_imports=False
)

# åŸºç¡€é…ç½®
work_dir = './work_dirs/dinov3_loveda_t20_gcu'
exp_name = 'dinov3_loveda_t20_gcu'

# æ•°æ®é›†é…ç½®
dataset_type = 'LoveDADataset'
data_root = '/workspace/data/loveda'  # T20æœåŠ¡å™¨è·¯å¾„
local_data_root = '/Users/barryzhang/myDev3/MapSage_V5/data'  # æœ¬åœ°å¼€å‘è·¯å¾„

# å›¾åƒé…ç½®
img_size = (512, 512)
crop_size = (512, 512)
num_classes = 7  # LoveDAçš„ç±»åˆ«æ•°

# æ•°æ®é¢„å¤„ç†å™¨
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[123.675, 116.28, 103.53],  # ImageNetç»Ÿè®¡å€¼
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255,
    size=crop_size
)

# DINOv3-ViT-L/16 æ¨¡å‹é…ç½®
model = dict(
    type='EncoderDecoder',
    data_preprocessor=data_preprocessor,
    
    # DINOv3 ViT-Large/16 backbone
    backbone=dict(
        type='DINOv3ViT',
        arch='large',
        img_size=img_size,
        patch_size=16,
        in_channels=3,
        with_cls_token=True,
        output_cls_token=False,
        interpolate_mode='bicubic',
        out_indices=(23,),  # è¾“å‡ºæœ€åä¸€å±‚
        final_norm=True,
        drop_path_rate=0.1,
        init_cfg=dict(
            type='Pretrained',
            checkpoint='/workspace/weights/best_mIoU_iter_6000.pth',  # ä½¿ç”¨MMRS1Mè®­ç»ƒçš„æœ€ä½³æƒé‡
            prefix='backbone.'
        )
    ),
    
    # è§£ç å¤´
    decode_head=dict(
        type='VisionTransformerUpHead',
        in_channels=1024,
        channels=512,
        in_index=-1,
        img_size=img_size,
        embed_dims=1024,
        num_classes=num_classes,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        num_conv=2,
        upsampling_method='bilinear',
        num_upsampe_layer=2,
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=1.0,
            class_weight=None  # å¯ä»¥æ ¹æ®æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒè°ƒæ•´
        )
    ),
    
    # è¾…åŠ©å¤´
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=1024,
        in_index=-1,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=num_classes,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=0.4
        )
    ),
    
    # è®­ç»ƒé…ç½®
    train_cfg=dict(),
    test_cfg=dict(mode='whole')
)

# è®­ç»ƒæ•°æ®ç®¡é“
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        scale=img_size,
        keep_ratio=True
    ),
    dict(
        type='RandomCrop',
        crop_size=crop_size,
        cat_max_ratio=0.75
    ),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs')
]

# éªŒè¯æ•°æ®ç®¡é“
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        scale=img_size,
        keep_ratio=True
    ),
    dict(type='PackSegInputs')
]

# æµ‹è¯•æ•°æ®ç®¡é“
test_pipeline = val_pipeline

# æ•°æ®é›†é…ç½®
train_dataloader = dict(
    batch_size=4,  # é€‚é…T20 GCUå†…å­˜é™åˆ¶
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type='ConcatDataset',
        datasets=[
            dict(
                type=dataset_type,
                data_root=data_root,
                data_prefix=dict(
                    img_path='Train/Rural/images_png',
                    seg_map_path='Train/Rural/masks_png'
                ),
                pipeline=train_pipeline
            ),
            dict(
                type=dataset_type,
                data_root=data_root,
                data_prefix=dict(
                    img_path='Train/Urban/images_png',
                    seg_map_path='Train/Urban/masks_png'
                ),
                pipeline=train_pipeline
            )
        ]
    )
)

val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='ConcatDataset',
        datasets=[
            dict(
                type=dataset_type,
                data_root=data_root,
                data_prefix=dict(
                    img_path='Val/Rural/images_png',
                    seg_map_path='Val/Rural/masks_png'
                ),
                pipeline=val_pipeline
            ),
            dict(
                type=dataset_type,
                data_root=data_root,
                data_prefix=dict(
                    img_path='Val/Urban/images_png',
                    seg_map_path='Val/Urban/masks_png'
                ),
                pipeline=val_pipeline
            )
        ]
    )
)

test_dataloader = val_dataloader

# è¯„ä¼°é…ç½®
val_evaluator = dict(
    type='IoUMetric',
    iou_metrics=['mIoU', 'mDice', 'mFscore']
)
test_evaluator = val_evaluator

# ä¼˜åŒ–å™¨é…ç½® - å¾®è°ƒä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW',
        lr=2e-5,  # å¾®è°ƒä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
        betas=(0.9, 0.999),
        weight_decay=0.01
    ),
    paramwise_cfg=dict(
        custom_keys={
            'backbone': dict(lr_mult=0.1),  # backboneä½¿ç”¨æ›´å°å­¦ä¹ ç‡
            'norm': dict(decay_mult=0.0),   # ä¸å¯¹normå±‚è¿›è¡Œæƒé‡è¡°å‡
            'bias': dict(decay_mult=0.0),   # ä¸å¯¹biasè¿›è¡Œæƒé‡è¡°å‡
        }
    )
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
param_scheduler = [
    dict(
        type='LinearLR',
        start_factor=1e-6,
        by_epoch=False,
        begin=0,
        end=500  # warmupæ­¥æ•°
    ),
    dict(
        type='PolyLR',
        eta_min=1e-6,
        power=1.0,
        begin=500,
        end=40000,  # æ€»è®­ç»ƒæ­¥æ•°
        by_epoch=False
    )
]

# è®­ç»ƒé…ç½®
train_cfg = dict(
    type='IterBasedTrainLoop',
    max_iters=40000,  # å¾®è°ƒè®­ç»ƒè¿­ä»£æ•°
    val_interval=2000  # éªŒè¯é—´éš”
)

val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

# é»˜è®¤é’©å­
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(
        type='CheckpointHook',
        by_epoch=False,
        interval=2000,
        max_keep_ckpts=3,
        save_best='mIoU',
        rule='greater'
    ),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(
        type='SegVisualizationHook',
        draw=True,
        interval=1000,
        show=False,
        wait_time=0.01,
        backend_args=None
    )
)

# ç¯å¢ƒé…ç½®
env_cfg = dict(
    cudnn_benchmark=False,  # GCUç¯å¢ƒå…³é—­cudnn
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='gloo')  # ä½¿ç”¨glooåç«¯é€‚é…GCU
)

# å¯è§†åŒ–é…ç½®
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(
        type='TensorboardVisBackend',
        save_dir='./work_dirs/dinov3_loveda_t20_gcu/tf_logs'
    )
]
visualizer = dict(
    type='SegLocalVisualizer',
    vis_backends=vis_backends,
    name='visualizer'
)

# æ—¥å¿—é…ç½®
log_processor = dict(by_epoch=False)
log_level = 'INFO'
load_from = None  # æƒé‡é€šè¿‡backboneçš„init_cfgåŠ è½½
resume = False

# éšæœºç§å­
randomness = dict(seed=42)

# è‡ªåŠ¨ç¼©æ”¾å­¦ä¹ ç‡
auto_scale_lr = dict(
    enable=True,
    base_batch_size=32  # 4 GCUs * 4 batch_size * 2 accumulative
)

# æ··åˆç²¾åº¦è®­ç»ƒ
fp16 = dict(loss_scale=512.0)

# æ¢¯åº¦ç´¯ç§¯
accumulative_counts = 2  # ç­‰æ•ˆbatch_size = 4 * 4 * 2 = 32

print(f"ğŸš€ DINOv3 + LoveDA ç‡§åŸT20 GCUå¾®è°ƒé…ç½®å·²åŠ è½½")
print(f"ğŸ“Š æ•°æ®é›†: {dataset_type}")
print(f"ğŸ—ï¸ æ¨¡å‹: DINOv3-ViT-L/16 + VisionTransformerUpHead")
print(f"ğŸ’¾ å·¥ä½œç›®å½•: {work_dir}")
print(f"ğŸ”„ æœ€å¤§è¿­ä»£æ•°: {train_cfg['max_iters']}")
batch_size = 4  # ä»train_dataloaderé…ç½®ä¸­è·å–
print(f"ğŸ“ˆ æ‰¹æ¬¡å¤§å°: {batch_size} x {accumulative_counts} = {batch_size * accumulative_counts}")
print(f"ğŸ”¥ è®¡ç®—ç¯å¢ƒ: ç‡§åŸT20 GCU")