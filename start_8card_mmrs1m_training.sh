#!/bin/bash

# MMRS-1M DINOv3 8å¡åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨è„šæœ¬
# ä¸“é—¨é€‚é…ç‡§åŸT20 GCUè®¡ç®—ç¯å¢ƒ
# åŸºäºPyTorchåˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶

echo "ğŸš€ å¯åŠ¨ MMRS-1M DINOv3 8å¡åˆ†å¸ƒå¼è®­ç»ƒ"
echo "ğŸ”¥ è®¡ç®—ç¯å¢ƒ: ç‡§åŸT20 GCU"
echo "ğŸ“Š æ•°æ®é›†: MMRS-1M å¤šæ¨¡æ€é¥æ„Ÿæ•°æ®é›†"
echo "ğŸ—ï¸ æ¨¡å‹: DINOv3-ViT-L/16 + VisionTransformerUpHead"

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7  # 8å¡GCUè®¾å¤‡
export MASTER_PORT=29500
export WORLD_SIZE=8
export RANK=0

# è®¾ç½®GCUç›¸å…³ç¯å¢ƒå˜é‡
export TOPS_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export TOPS_LAUNCH_MODE=pytorch
export ECCL_DEBUG=INFO
export ECCL_TIMEOUT=1800

# è®¾ç½®MMSegmentationç¯å¢ƒå˜é‡
export MMCV_WITH_OPS=1
export MAX_JOBS=8

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE="configs/train_dinov3_mmrs1m_t20_gcu_8card.py"
WORK_DIR="./work_dirs/dinov3_mmrs1m_t20_gcu_8card"

# æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$CONFIG_FILE" ]; then
    echo "âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ $CONFIG_FILE ä¸å­˜åœ¨"
    exit 1
fi

# åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p "$WORK_DIR"
mkdir -p "$WORK_DIR/tf_logs"

# æ£€æŸ¥æ•°æ®é›†è·¯å¾„
DATA_ROOT="/workspace/data/mmrs1m/data"
LOCAL_DATA_ROOT="./data"

if [ -d "$DATA_ROOT" ]; then
    echo "âœ… ä½¿ç”¨æœåŠ¡å™¨æ•°æ®è·¯å¾„: $DATA_ROOT"
    ACTUAL_DATA_ROOT="$DATA_ROOT"
elif [ -d "$LOCAL_DATA_ROOT" ]; then
    echo "âœ… ä½¿ç”¨æœ¬åœ°æ•°æ®è·¯å¾„: $LOCAL_DATA_ROOT"
    ACTUAL_DATA_ROOT="$LOCAL_DATA_ROOT"
else
    echo "âŒ é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†é…ç½®"
    echo "   æœåŠ¡å™¨è·¯å¾„: $DATA_ROOT"
    echo "   æœ¬åœ°è·¯å¾„: $LOCAL_DATA_ROOT"
    exit 1
fi

# æ‰“å°è®­ç»ƒé…ç½®ä¿¡æ¯
echo ""
echo "ğŸ“‹ è®­ç»ƒé…ç½®ä¿¡æ¯:"
echo "   é…ç½®æ–‡ä»¶: $CONFIG_FILE"
echo "   å·¥ä½œç›®å½•: $WORK_DIR"
echo "   æ•°æ®è·¯å¾„: $ACTUAL_DATA_ROOT"
echo "   è®¾å¤‡æ•°é‡: 8 GCUs"
echo "   æ‰¹æ¬¡å¤§å°: 2 x 8 = 16"
echo "   æœ€å¤§è¿­ä»£: 40000"
echo ""

# å¯åŠ¨8å¡åˆ†å¸ƒå¼è®­ç»ƒ
echo "ğŸ”„ å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ..."

# ä½¿ç”¨torchrunå¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ
torchrun \
    --nnodes=1 \
    --nproc_per_node=8 \
    --rdzv_id=100 \
    --rdzv_backend=c10d \
    --rdzv_endpoint=localhost:29500 \
    scripts/train.py \
    "$CONFIG_FILE" \
    --work-dir "$WORK_DIR" \
    --launcher pytorch \
    --seed 42 \
    --deterministic \
    --diff-seed \
    --cfg-options \
        data_root="$ACTUAL_DATA_ROOT" \
        train_dataloader.dataset.data_root="$ACTUAL_DATA_ROOT" \
        val_dataloader.dataset.data_root="$ACTUAL_DATA_ROOT" \
        test_dataloader.dataset.data_root="$ACTUAL_DATA_ROOT" \
    2>&1 | tee "$WORK_DIR/training.log"

# æ£€æŸ¥è®­ç»ƒç»“æœ
if [ $? -eq 0 ]; then
    echo ""
    echo "âœ… 8å¡åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆ!"
    echo "ğŸ“ è®­ç»ƒæ—¥å¿—: $WORK_DIR/training.log"
    echo "ğŸ“ æ£€æŸ¥ç‚¹: $WORK_DIR/"
    echo "ğŸ“Š TensorBoardæ—¥å¿—: $WORK_DIR/tf_logs/"
    echo ""
    echo "ğŸ” æŸ¥çœ‹è®­ç»ƒæ—¥å¿—:"
    echo "   tail -f $WORK_DIR/training.log"
    echo ""
    echo "ğŸ“ˆ å¯åŠ¨TensorBoard:"
    echo "   tensorboard --logdir=$WORK_DIR/tf_logs --port=6006"
else
    echo ""
    echo "âŒ 8å¡åˆ†å¸ƒå¼è®­ç»ƒå¤±è´¥!"
    echo "ğŸ“ æ£€æŸ¥è®­ç»ƒæ—¥å¿—: $WORK_DIR/training.log"
    echo "ğŸ” æŸ¥çœ‹é”™è¯¯ä¿¡æ¯:"
    echo "   tail -50 $WORK_DIR/training.log"
    exit 1
fi