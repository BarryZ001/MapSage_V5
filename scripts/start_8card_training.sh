#!/bin/bash
# 8å¡åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨è„šæœ¬ - ç‡§åŸT20 GCUç‰ˆæœ¬

set -e

echo "ğŸš€ å¯åŠ¨8å¡åˆ†å¸ƒå¼è®­ç»ƒ"
echo "ğŸ“… æ—¶é—´: $(date)"

# è®¾ç½®ç¯å¢ƒå˜é‡
export WORLD_SIZE=8
export MASTER_ADDR=localhost
export MASTER_PORT=29500

# è®¾ç½®GCUç›¸å…³ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=""  # ç¦ç”¨CUDA
export GCU_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE="configs/train_dinov3_mmrs1m_t20_gcu_8card.py"
SCRIPT_FILE="scripts/train_distributed_8card_gcu.py"

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$CONFIG_FILE" ]; then
    echo "âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $CONFIG_FILE"
    exit 1
fi

if [ ! -f "$SCRIPT_FILE" ]; then
    echo "âŒ è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: $SCRIPT_FILE"
    exit 1
fi

echo "ğŸ“„ é…ç½®æ–‡ä»¶: $CONFIG_FILE"
echo "ğŸ“œ è®­ç»ƒè„šæœ¬: $SCRIPT_FILE"
echo "ğŸ”¢ ä½¿ç”¨è®¾å¤‡æ•°: $WORLD_SIZE"

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="./work_dirs/dinov3_mmrs1m_t20_gcu_8card/logs"
mkdir -p "$LOG_DIR"

# å¯åŠ¨8å¡åˆ†å¸ƒå¼è®­ç»ƒ
echo "ğŸ”¥ å¯åŠ¨8ä¸ªè®­ç»ƒè¿›ç¨‹..."

for i in {0..7}; do
    export RANK=$i
    export LOCAL_RANK=$i
    
    echo "ğŸš€ å¯åŠ¨è¿›ç¨‹ $i/8"
    
    # æ¯ä¸ªè¿›ç¨‹çš„æ—¥å¿—æ–‡ä»¶
    LOG_FILE="$LOG_DIR/train_rank_${i}.log"
    
    # å¯åŠ¨è®­ç»ƒè¿›ç¨‹ï¼ˆåå°è¿è¡Œï¼‰
    python "$SCRIPT_FILE" "$CONFIG_FILE" --launcher pytorch --local_rank $i > "$LOG_FILE" 2>&1 &
    
    # è®°å½•è¿›ç¨‹ID
    PID=$!
    echo "ğŸ“ è¿›ç¨‹ $i PID: $PID"
    echo $PID > "$LOG_DIR/train_rank_${i}.pid"
    
    # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…åŒæ—¶å¯åŠ¨é€ æˆå†²çª
    sleep 2
done

echo "âœ… æ‰€æœ‰è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨"
echo "ğŸ“Š ç›‘æ§è®­ç»ƒè¿›åº¦:"
echo "  - æ—¥å¿—ç›®å½•: $LOG_DIR"
echo "  - ä¸»è¿›ç¨‹æ—¥å¿—: $LOG_DIR/train_rank_0.log"
echo "  - å·¥ä½œç›®å½•: ./work_dirs/dinov3_mmrs1m_t20_gcu_8card"

echo ""
echo "ğŸ” å®æ—¶ç›‘æ§å‘½ä»¤:"
echo "  tail -f $LOG_DIR/train_rank_0.log"
echo ""
echo "ğŸ›‘ åœæ­¢è®­ç»ƒå‘½ä»¤:"
echo "  pkill -f train_distributed_8card_gcu.py"
echo ""

# ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
wait

echo "ğŸ‰ 8å¡åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆ!"