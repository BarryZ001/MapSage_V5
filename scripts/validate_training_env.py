#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""è®­ç»ƒç¯å¢ƒéªŒè¯è„šæœ¬

éªŒè¯DINOv3+MMRS-1Mè®­ç»ƒæ‰€éœ€çš„ç¯å¢ƒã€æ•°æ®å’Œé…ç½®ã€‚
é€‚ç”¨äºT20æœåŠ¡å™¨å’Œæœ¬åœ°å¼€å‘ç¯å¢ƒã€‚
"""

import os
import sys
import torch
import importlib
import importlib.util
import subprocess
from pathlib import Path
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def print_success(message):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"âœ… {message}")

def print_error(message):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"âŒ {message}")

def print_warning(message):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(f"âš ï¸  {message}")

def print_info(message):
    """æ‰“å°ä¿¡æ¯"""
    print(f"â„¹ï¸  {message}")


def check_python_version() -> Tuple[bool, str]:
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    version = sys.version_info
    if version.major == 3 and version.minor >= 8:
        return True, f"âœ… Python {version.major}.{version.minor}.{version.micro}"
    else:
        return False, f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {version.major}.{version.minor}.{version.micro} (éœ€è¦>=3.8)"


def check_t20_gcu_environment() -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºç‡§åŸT20 GCUç¯å¢ƒ"""
    # æ£€æŸ¥GCUç›¸å…³ç¯å¢ƒå˜é‡å’Œæ–‡ä»¶
    gcu_indicators = [
        os.path.exists('/usr/local/gcu'),
        os.path.exists('/opt/gcu'),
        'GCU' in os.environ.get('PATH', ''),
        os.path.exists('/proc/driver/gcu')
    ]
    return any(gcu_indicators)


def check_pytorch() -> Tuple[bool, str]:
    """æ£€æŸ¥PyTorchå®‰è£…"""
    try:
        import torch
        version = torch.__version__
        
        # ä¼˜å…ˆæ£€æŸ¥GCUç¯å¢ƒ
        gcu_available = False
        gcu_count = 0
        try:
            import torch_gcu  # type: ignore
            if hasattr(torch, 'gcu'):
                gcu_available = torch.gcu.is_available()  # type: ignore
                gcu_count = torch.gcu.device_count() if gcu_available else 0  # type: ignore
        except (ImportError, AttributeError):
            pass
        
        # æ£€æŸ¥CUDAç¯å¢ƒï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        cuda_available = torch.cuda.is_available()
        gpu_count = torch.cuda.device_count() if cuda_available else 0
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç‡§åŸT20 GCUç¯å¢ƒ
        is_t20_gcu = check_t20_gcu_environment()
        
        if gcu_available:
            return True, f"âœ… PyTorch {version}, GCUå¯ç”¨, {gcu_count}ä¸ªGCUè®¾å¤‡"
        elif cuda_available:
            return True, f"âœ… PyTorch {version}, CUDAå¯ç”¨, {gpu_count}ä¸ªGPU"
        elif is_t20_gcu:
            return True, f"âœ… PyTorch {version}, ç‡§åŸT20 GCUç¯å¢ƒ"
        else:
            return True, f"âœ… PyTorch {version}, CPUç¯å¢ƒ (é€‚é…T20 GCU)"
    except ImportError:
        return False, "âŒ PyTorchæœªå®‰è£…"


def check_torch_gcu() -> Tuple[bool, str]:
    """æ£€æŸ¥torch-gcuæ¡†æ¶"""
    try:
        import torch
        if hasattr(torch, 'gcu'):
            return True, "âœ… torch-gcuæ¡†æ¶å¯ç”¨"
        else:
            return False, "âŒ torch-gcuæ¡†æ¶ä¸å¯ç”¨"
    except ImportError:
        return False, "âŒ PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥torch-gcu"


def check_ptex() -> Tuple[bool, str]:
    """æ£€æŸ¥ptexæ¨¡å—"""
    try:
        # ä½¿ç”¨importlibåŠ¨æ€å¯¼å…¥ptexä»¥é¿å…é™æ€åˆ†æé”™è¯¯
        ptex_spec = importlib.util.find_spec('ptex')
        if ptex_spec is None:
            return False, "âŒ ptexæ¨¡å—æœªå®‰è£…"
        
        ptex = importlib.import_module('ptex')
        # å°è¯•åˆ›å»ºXLAè®¾å¤‡æ¥éªŒè¯å¯ç”¨æ€§
        device = ptex.device('xla')
        return True, f"âœ… ptexæ¨¡å—å¯ç”¨, XLAè®¾å¤‡: {device}"
    except ImportError:
        return False, "âŒ ptexæ¨¡å—æœªå®‰è£…"
    except Exception as e:
        return False, f"âŒ ptexæ¨¡å—é”™è¯¯: {e}"


def check_mmseg() -> Tuple[bool, str]:
    """æ£€æŸ¥MMSegmentation"""
    try:
        import mmseg
        version = mmseg.__version__
        return True, f"âœ… MMSegmentation {version}"
    except ImportError:
        return False, "âŒ MMSegmentationæœªå®‰è£…"


def check_custom_modules() -> List[Tuple[bool, str]]:
    """æ£€æŸ¥è‡ªå®šä¹‰æ¨¡å—"""
    results = []
    
    # å…ˆè¿è¡ŒQuantStubå…¼å®¹æ€§ä¿®å¤
    try:
        import subprocess
        result = subprocess.run([sys.executable, 'scripts/fix_quantstub_compatibility.py'], 
                              capture_output=True, text=True, cwd='/workspace/code/MapSage_V5')
        if result.returncode == 0:
            results.append((True, "âœ… QuantStubå…¼å®¹æ€§ä¿®å¤å®Œæˆ"))
        else:
            results.append((False, f"âš ï¸ QuantStubä¿®å¤è­¦å‘Š: {result.stderr}"))
    except Exception as e:
        results.append((False, f"âš ï¸ QuantStubä¿®å¤å¤±è´¥: {e}"))
    
    # æ£€æŸ¥è‡ªå®šä¹‰æ•°æ®é›†
    try:
        from mmseg_custom.datasets import MMRS1MDataset
        results.append((True, "âœ… MMRS1MDatasetå¯¼å…¥æˆåŠŸ"))
    except ImportError as e:
        results.append((False, f"âŒ MMRS1MDatasetå¯¼å…¥å¤±è´¥: {e}"))
    
    # æ£€æŸ¥è‡ªå®šä¹‰å˜æ¢
    try:
        from mmseg_custom.transforms import MultiModalNormalize
        results.append((True, "âœ… MultiModalTransformså¯¼å…¥æˆåŠŸ"))
    except ImportError as e:
        results.append((False, f"âŒ MultiModalTransformså¯¼å…¥å¤±è´¥: {e}"))
    
    # æ£€æŸ¥DINOv3æ¨¡å‹
    try:
        from mmseg_custom.models import DINOv3ViT
        results.append((True, "âœ… DINOv3ViTå¯¼å…¥æˆåŠŸ"))
    except ImportError as e:
        results.append((False, f"âŒ DINOv3ViTå¯¼å…¥å¤±è´¥: {e}"))
    
    return results


def check_data_paths() -> List[Tuple[bool, str]]:
    """æ£€æŸ¥æ•°æ®è·¯å¾„"""
    results = []
    
    # T20æœåŠ¡å™¨è·¯å¾„ - ä¿®æ­£ä¸ºæ­£ç¡®çš„æ•°æ®è·¯å¾„
    t20_data_path = Path("/workspace/data/mmrs1m/data")
    if t20_data_path.exists():
        results.append((True, f"âœ… T20æ•°æ®è·¯å¾„å­˜åœ¨: {t20_data_path}"))
        
        # æ£€æŸ¥å­ç›®å½•
        subdirs = ['caption', 'classification', 'detection', 'json', 'RSVG', 'VQA']
        for subdir in subdirs:
            subpath = t20_data_path / subdir
            if subpath.exists():
                results.append((True, f"âœ… å­ç›®å½•å­˜åœ¨: {subdir}"))
            else:
                results.append((False, f"âŒ å­ç›®å½•ç¼ºå¤±: {subdir}"))
    else:
        results.append((False, f"âŒ T20æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {t20_data_path}"))
    
    # æœ¬åœ°æµ‹è¯•æ•°æ®è·¯å¾„
    local_data_path = Path("./data/test_data")
    if local_data_path.exists():
        results.append((True, f"âœ… æœ¬åœ°æµ‹è¯•æ•°æ®å­˜åœ¨: {local_data_path}"))
    else:
        results.append((False, f"âŒ æœ¬åœ°æµ‹è¯•æ•°æ®ä¸å­˜åœ¨: {local_data_path}"))
    
    return results


def check_pretrained_weights() -> List[Tuple[bool, str]]:
    """æ£€æŸ¥é¢„è®­ç»ƒæƒé‡"""
    results = []
    
    # T20æœåŠ¡å™¨æƒé‡è·¯å¾„ - ç”¨æˆ·æä¾›çš„æ­£ç¡®è·¯å¾„
    t20_weights_path = Path("/workspace/weights/pretrained/dinov3/dinov3_vitl16_pretrain_sat493m-eadcf0ff.pth")
    if t20_weights_path.exists():
        results.append((True, f"âœ… T20é¢„è®­ç»ƒæƒé‡å­˜åœ¨: {t20_weights_path}"))
    else:
        results.append((False, f"âŒ T20é¢„è®­ç»ƒæƒé‡ä¸å­˜åœ¨: {t20_weights_path}"))
    
    return results


def check_config_file() -> Tuple[bool, str]:
    """æ£€æŸ¥è®­ç»ƒé…ç½®æ–‡ä»¶"""
    config_path = Path("configs/train_dinov3_mmrs1m.py")
    if config_path.exists():
        try:
            # å°è¯•å¯¼å…¥é…ç½®
            sys.path.insert(0, str(config_path.parent))
            spec = importlib.util.spec_from_file_location("config", config_path)
            if spec is not None and spec.loader is not None:
                config = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(config)
                return True, f"âœ… é…ç½®æ–‡ä»¶æœ‰æ•ˆ: {config_path}"
            else:
                return False, f"âŒ é…ç½®æ–‡ä»¶å¯¼å…¥å¤±è´¥: {config_path}"
        except Exception as e:
            return False, f"âŒ é…ç½®æ–‡ä»¶æœ‰è¯¯: {e}"
    else:
        return False, f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}"


def check_work_directory() -> Tuple[bool, str]:
    """æ£€æŸ¥å·¥ä½œç›®å½•"""
    work_dir = Path("./work_dirs/dinov3_mmrs1m_stage1")
    try:
        work_dir.mkdir(parents=True, exist_ok=True)
        return True, f"âœ… å·¥ä½œç›®å½•å°±ç»ª: {work_dir}"
    except Exception as e:
        return False, f"âŒ å·¥ä½œç›®å½•åˆ›å»ºå¤±è´¥: {e}"


def check_gpu_environment():
    """æ£€æŸ¥GPU/GCUç¯å¢ƒ"""
    print("\nğŸ” æ£€æŸ¥GPU/GCUç¯å¢ƒ...")
    
    try:
        import torch
        
        # ä¼˜å…ˆæ£€æŸ¥GCUç¯å¢ƒ
        gcu_available = False
        try:
            import torch_gcu  # type: ignore
            if hasattr(torch, 'gcu'):
                gcu_available = torch.gcu.is_available()  # type: ignore
                if gcu_available:
                    gcu_count = torch.gcu.device_count()  # type: ignore
                    print_success(f"å¯ç”¨GCUæ•°é‡: {gcu_count}")
                    for i in range(gcu_count):
                        gcu_name = torch.gcu.get_device_name(i)  # type: ignore
                        print_info(f"  GCU {i}: {gcu_name}")
                    return True
        except (ImportError, AttributeError):
            pass
        
        # æ£€æŸ¥CUDAç¯å¢ƒï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        if torch.cuda.is_available():
            print_success(f"å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print_info(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            return True
        else:
            print_warning("æœªæ£€æµ‹åˆ°GPU/GCUè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
            return False
            
    except Exception as e:
        print_error(f"æ£€æŸ¥GPU/GCUç¯å¢ƒæ—¶å‡ºé”™: {e}")
        return False


def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ğŸ” DINOv3 + MMRS-1M è®­ç»ƒç¯å¢ƒéªŒè¯")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºT20 GCUç¯å¢ƒ
    is_t20_gcu = check_t20_gcu_environment()
    if is_t20_gcu:
        print("ğŸ”¥ æ£€æµ‹åˆ°ç‡§åŸT20 GCUç¯å¢ƒ")
    else:
        print("ğŸ’» æ ‡å‡†ç¯å¢ƒ")
    
    print("=" * 50)
    
    all_passed = True
    
    # åŸºç¡€ç¯å¢ƒæ£€æŸ¥
    print("\nğŸ“‹ åŸºç¡€ç¯å¢ƒæ£€æŸ¥:")
    checks = [
        check_python_version(),
        check_pytorch(),
        check_mmseg(),
        check_config_file(),
        check_work_directory()
    ]
    
    # å¦‚æœæ˜¯T20 GCUç¯å¢ƒï¼Œæ·»åŠ GCUç›¸å…³æ£€æŸ¥
    if is_t20_gcu:
        checks.extend([
            check_torch_gcu(),
            check_ptex()
        ])
    
    for passed, message in checks:
        print(f"  {message}")
        if not passed:
            all_passed = False
    
    # è‡ªå®šä¹‰æ¨¡å—æ£€æŸ¥
    print("\nğŸ”§ è‡ªå®šä¹‰æ¨¡å—æ£€æŸ¥:")
    custom_checks = check_custom_modules()
    for passed, message in custom_checks:
        print(f"  {message}")
        if not passed:
            all_passed = False
    
    # æ•°æ®è·¯å¾„æ£€æŸ¥
    print("\nğŸ“ æ•°æ®è·¯å¾„æ£€æŸ¥:")
    data_checks = check_data_paths()
    for passed, message in data_checks:
        print(f"  {message}")
        if not passed:
            all_passed = False
    
    # é¢„è®­ç»ƒæƒé‡æ£€æŸ¥
    print("\nâš–ï¸  é¢„è®­ç»ƒæƒé‡æ£€æŸ¥:")
    weight_checks = check_pretrained_weights()
    for passed, message in weight_checks:
        print(f"  {message}")
        if not passed:
            all_passed = False
    
    # GPU/XLAè®¾å¤‡ä¿¡æ¯
    if is_t20_gcu:
        print("\nğŸ–¥ï¸  XLAè®¾å¤‡ä¿¡æ¯:")
        try:
            # ä½¿ç”¨importlibåŠ¨æ€å¯¼å…¥ptexä»¥é¿å…é™æ€åˆ†æé”™è¯¯
            ptex_spec = importlib.util.find_spec('ptex')
            if ptex_spec is None:
                print("  âŒ ptexæ¨¡å—æœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥XLAè®¾å¤‡")
            else:
                ptex = importlib.import_module('ptex')
                # å°è¯•åˆ›å»ºXLAè®¾å¤‡æ¥éªŒè¯å¯ç”¨æ€§
                device = ptex.device('xla')
                print(f"  âœ… XLAè®¾å¤‡å¯ç”¨: {device}")
        except Exception as e:
            print(f"  âŒ XLAè®¾å¤‡æ£€æŸ¥é”™è¯¯: {e}")
    else:
        print("\nğŸ–¥ï¸  GPUä¿¡æ¯:")
        if torch.cuda.is_available():
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        else:
            print("  âŒ æ— å¯ç”¨GPU")
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    if all_passed:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
        print("\nğŸš€ å¯åŠ¨è®­ç»ƒå‘½ä»¤:")
        print("  bash scripts/train_dinov3_mmrs1m.sh")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·ä¿®å¤åå†å¼€å§‹è®­ç»ƒã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())