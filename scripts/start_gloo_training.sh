#!/bin/bash
# glooåç«¯åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨è„šæœ¬

echo "ğŸš€ å¯åŠ¨glooåç«¯åˆ†å¸ƒå¼è®­ç»ƒ..."

# è®¾ç½®ç¯å¢ƒå˜é‡
source scripts/setup_eccl_env.sh

# æ£€æŸ¥å‚æ•°
SCRIPT_PATH=${1:-"scripts/train_distributed_gcu_fixed.py"}
NUM_GPUS=${2:-8}

echo "ğŸ“‹ è®­ç»ƒå‚æ•°:"
echo "  - è®­ç»ƒè„šæœ¬: $SCRIPT_PATH"
echo "  - GPUæ•°é‡: $NUM_GPUS"

# ä½¿ç”¨torchrunå¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒï¼ˆå¼ºåˆ¶ä½¿ç”¨glooåç«¯ï¼‰
export TORCH_DISTRIBUTED_BACKEND=gloo

torchrun \
    --nproc_per_node=$NUM_GPUS \
    --master_addr=127.0.0.1 \
    --master_port=29500 \
    $SCRIPT_PATH \
    --backend=gloo \
    --launcher=pytorch

echo "ğŸ¯ åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆï¼"
