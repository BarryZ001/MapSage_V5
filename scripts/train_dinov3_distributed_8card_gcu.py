#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ - ç‡§åŸT20 GCUç‰ˆæœ¬
åŸºäºæˆåŠŸçš„demo_deepspeed_xla.pyç»éªŒï¼Œé€‚é…MMSegmentationæ¡†æ¶

ä½¿ç”¨æ–¹æ³•:
torchrun --nproc_per_node=8 --master_port=29500 scripts/train_dinov3_distributed_8card_gcu.py configs/train_dinov3_mmrs1m_t20_gcu_8card.py
"""

import argparse
import os
import sys
import time
import warnings
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®ç¯å¢ƒå˜é‡ - åŸºäºæˆåŠŸçš„demo_deepspeed_xla.pyç»éªŒ
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'backend:topsMallocAsync')
os.environ.setdefault('TORCH_ECCL_AVOID_RECORD_STREAMS', 'false')
os.environ.setdefault('TORCH_ECCL_ASYNC_ERROR_HANDLING', '3')

# å¯¼å…¥å¿…è¦çš„åº“
try:
    import torch
    import torch_gcu  # ç‡§åŸGCUæ”¯æŒ
    print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"âœ… torch_gcuå¯ç”¨: {torch_gcu.is_available()}")
    if torch_gcu.is_available():
        print(f"âœ… GCUè®¾å¤‡æ•°: {torch_gcu.device_count()}")
    else:
        raise RuntimeError("torch_gcuä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
except ImportError as e:
    print(f"âŒ å¯¼å…¥torch_gcuå¤±è´¥: {e}")
    sys.exit(1)

# å¯¼å…¥MMEngineå’ŒMMSegmentation
try:
    from mmengine.config import Config
    from mmengine.runner import Runner
    from mmengine.dist import init_dist, get_rank, get_world_size
    print("âœ… MMEngineå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ MMEngineå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    import mmseg
    from mmseg.models import *
    from mmseg.datasets import *
    print("âœ… MMSegmentationå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ MMSegmentationå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    import mmseg_custom.models
    import mmseg_custom.datasets
    import mmseg_custom.transforms
    print("âœ… è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

def setup_gcu_environment():
    """è®¾ç½®GCUç¯å¢ƒ - åŸºäºdemo_deepspeed_xla.pyçš„æˆåŠŸç»éªŒ"""
    
    # è·å–åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°
    local_rank = int(os.environ.get('LOCAL_RANK', 0))
    world_size = int(os.environ.get('WORLD_SIZE', 1))
    rank = int(os.environ.get('RANK', 0))
    
    print(f"ğŸš€ [PID {os.getpid()}] åˆ†å¸ƒå¼å‚æ•°:")
    print(f"   - local_rank: {local_rank}")
    print(f"   - world_size: {world_size}")
    print(f"   - rank: {rank}")
    
    # è®¾ç½®è®¾å¤‡ - ä½¿ç”¨xlaè®¾å¤‡åç§°ï¼ˆåŸºäºdemo_deepspeed_xla.pyï¼‰
    device_name = f"xla:{local_rank}"
    torch_gcu.set_device(local_rank)  # è®¾ç½®å½“å‰GCUè®¾å¤‡
    
    print(f"ğŸ”§ è®¾å¤‡é…ç½®: {device_name}")
    
    # éªŒè¯è®¾å¤‡å¯ç”¨æ€§
    try:
        test_tensor = torch.randn(2, 2).to(device_name)
        print(f"âœ… è®¾å¤‡ {device_name} éªŒè¯æˆåŠŸ")
        del test_tensor
    except Exception as e:
        print(f"âŒ è®¾å¤‡ {device_name} éªŒè¯å¤±è´¥: {e}")
        raise
    
    return local_rank, world_size, rank, device_name

def init_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ"""
    try:
        # ç›´æ¥ä½¿ç”¨torch.distributedåˆå§‹åŒ–ï¼Œé¿å…MMEngineçš„init_distå¯èƒ½çš„CUDAä¾èµ–
        import torch.distributed as dist
        
        # è·å–ç¯å¢ƒå˜é‡
        rank = int(os.environ.get('RANK', 0))
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        world_size = int(os.environ.get('WORLD_SIZE', 1))
        master_addr = os.environ.get('MASTER_ADDR', 'localhost')
        master_port = os.environ.get('MASTER_PORT', '29500')
        
        print(f"ğŸ”§ åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡:")
        print(f"   - RANK: {rank}")
        print(f"   - LOCAL_RANK: {local_rank}")
        print(f"   - WORLD_SIZE: {world_size}")
        print(f"   - MASTER_ADDR: {master_addr}")
        print(f"   - MASTER_PORT: {master_port}")
        
        # æ£€æŸ¥å¯ç”¨çš„åç«¯
        print(f"ğŸ” æ£€æŸ¥åˆ†å¸ƒå¼åç«¯å¯ç”¨æ€§:")
        print(f"   - NCCL: {dist.is_nccl_available()}")
        print(f"   - MPI: {dist.is_mpi_available()}")
        print(f"   - Gloo: {dist.is_gloo_available()}")
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„ï¼Œä¼˜å…ˆä½¿ç”¨glooåç«¯ï¼ˆåœ¨GCUç¯å¢ƒä¸‹æ›´ç¨³å®šï¼‰
        if not dist.is_initialized():
            backend = 'gloo'  # ä½¿ç”¨glooåç«¯ï¼Œå› ä¸ºecclä¸è¢«æ”¯æŒ
            dist.init_process_group(
                backend=backend,
                init_method=f'tcp://{master_addr}:{master_port}',
                rank=rank,
                world_size=world_size
            )
            print(f"âœ… åˆ†å¸ƒå¼åˆå§‹åŒ–æˆåŠŸ - åç«¯: {backend}")
            print(f"   - rank: {dist.get_rank()}")
            print(f"   - world_size: {dist.get_world_size()}")
        else:
            print("âœ… åˆ†å¸ƒå¼å·²åˆå§‹åŒ–")
        
        return True
    except Exception as e:
        print(f"âŒ åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def load_and_validate_config(config_path, work_dir=None):
    """åŠ è½½å’ŒéªŒè¯é…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    print(f"ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    cfg = Config.fromfile(config_path)
    
    # è®¾ç½®å·¥ä½œç›®å½•
    if work_dir is not None:
        cfg.work_dir = work_dir
    elif cfg.get('work_dir', None) is None:
        cfg.work_dir = './work_dirs/dinov3_mmrs1m_8card_gcu'
    
    print(f"ğŸ“ å·¥ä½œç›®å½•: {cfg.work_dir}")
    
    # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
    os.makedirs(cfg.work_dir, exist_ok=True)
    
    # éªŒè¯å…³é”®é…ç½®
    if not hasattr(cfg, 'model'):
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘modelé…ç½®")
    
    if not hasattr(cfg, 'train_dataloader'):
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘train_dataloaderé…ç½®")
    
    print("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
    return cfg

def main():
    parser = argparse.ArgumentParser(description='DINOv3 8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='å·¥ä½œç›®å½•')
    parser.add_argument('--launcher', 
                        choices=['none', 'pytorch', 'slurm', 'mpi'],
                        default='pytorch',
                        help='åˆ†å¸ƒå¼å¯åŠ¨å™¨')
    parser.add_argument('--local_rank', type=int, default=-1,
                        help='æœ¬åœ°rankï¼ˆç”±torchrunè‡ªåŠ¨è®¾ç½®ï¼‰')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­')
    parser.add_argument('--deterministic', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨ç¡®å®šæ€§è®­ç»ƒ')
    parser.add_argument('--resume', type=str, default=None,
                        help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    args = parser.parse_args()

    print("ğŸš€ DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨")
    print("=" * 60)
    
    # 1. è®¾ç½®GCUç¯å¢ƒ
    local_rank, world_size, rank, device_name = setup_gcu_environment()
    
    # 2. åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ
    if args.launcher != 'none' and world_size > 1:
        if not init_distributed():
            print("âŒ åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºè®­ç»ƒ")
            sys.exit(1)
    
    # 3. åŠ è½½é…ç½®
    cfg = load_and_validate_config(args.config, args.work_dir)
    
    # 4. è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        cfg.randomness = dict(seed=args.seed, deterministic=args.deterministic)
        print(f"ğŸ² éšæœºç§å­: {args.seed}, ç¡®å®šæ€§: {args.deterministic}")
    
    # 5. è®¾ç½®å¯åŠ¨å™¨
    if args.launcher != 'none':
        cfg.launcher = args.launcher
        print(f"ğŸš€ å¯åŠ¨å™¨: {args.launcher}")
    
    # 6. è®¾ç½®æ¢å¤è®­ç»ƒ
    if args.resume:
        cfg.resume = True
        cfg.load_from = args.resume
        print(f"ğŸ”„ æ¢å¤è®­ç»ƒ: {args.resume}")
    
    # 7. æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
    print(f"ğŸ“Š è®­ç»ƒä¿¡æ¯:")
    print(f"   - é…ç½®æ–‡ä»¶: {args.config}")
    print(f"   - å·¥ä½œç›®å½•: {cfg.work_dir}")
    print(f"   - è®¾å¤‡: {device_name}")
    print(f"   - ä¸–ç•Œå¤§å°: {world_size}")
    print(f"   - æœ¬åœ°rank: {local_rank}")
    
    # 8. åˆ›å»ºRunnerå¹¶å¼€å§‹è®­ç»ƒ
    try:
        print("ğŸ—ï¸ åˆ›å»ºè®­ç»ƒRunner...")
        runner = Runner.from_cfg(cfg)
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("=" * 60)
        
        # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # å¼€å§‹è®­ç»ƒ
        runner.train()
        
        # è®¡ç®—è®­ç»ƒæ—¶é—´
        end_time = time.time()
        training_time = end_time - start_time
        
        print("=" * 60)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ ({training_time/3600:.2f}å°æ—¶)")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {cfg.work_dir}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()