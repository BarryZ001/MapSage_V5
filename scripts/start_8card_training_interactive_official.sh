#!/bin/bash
# -*- coding: utf-8 -*-
# T20æœåŠ¡å™¨8å¡è®­ç»ƒäº¤äº’å¼å¯åŠ¨è„šæœ¬ - åŸºäºç‡§åŸå®˜æ–¹æ–‡æ¡£

echo "ğŸš€ T20æœåŠ¡å™¨8å¡è®­ç»ƒäº¤äº’å¼å¯åŠ¨ (ç‡§åŸå®˜æ–¹é…ç½®)"
echo "=================================================="

# 1. æ£€æŸ¥torch_gcuç¯å¢ƒ
echo "ğŸ“‹ æ£€æŸ¥torch_gcuç¯å¢ƒ..."
python3 -c "
import torch
import torch_gcu
print('âœ… PyTorchç‰ˆæœ¬:', torch.__version__)
print('âœ… torch_gcuå¯ç”¨:', torch_gcu.is_available())
if torch_gcu.is_available():
    print('âœ… GCUè®¾å¤‡æ•°:', torch_gcu.device_count())
else:
    print('âŒ torch_gcuä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…')
    exit(1)
" || {
    echo "âŒ torch_gcuç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆè¿è¡Œç¯å¢ƒä¿®å¤è„šæœ¬"
    exit 1
}

# 2. è®¾ç½®ç¯å¢ƒå˜é‡ (æ ¹æ®å®˜æ–¹æ–‡æ¡£)
echo ""
echo "ğŸ”§ è®¾ç½®è®­ç»ƒç¯å¢ƒå˜é‡..."

# åŸºç¡€åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡
export MASTER_ADDR=${MASTER_ADDR:-"127.0.0.1"}
export MASTER_PORT=${MASTER_PORT:-"29500"}
export WORLD_SIZE=${WORLD_SIZE:-"8"}

# ç‡§åŸä¸“ç”¨ç¯å¢ƒå˜é‡ (æ ¹æ®å®˜æ–¹æ–‡æ¡£)
export PYTORCH_GCU_ALLOC_CONF=${PYTORCH_GCU_ALLOC_CONF:-"backend:topsMallocAsync"}
export TORCH_ECCL_AVOID_RECORD_STREAMS=${TORCH_ECCL_AVOID_RECORD_STREAMS:-"false"}
export TORCH_ECCL_ASYNC_ERROR_HANDLING=${TORCH_ECCL_ASYNC_ERROR_HANDLING:-"3"}

# è°ƒè¯•ä¿¡æ¯ (å¯é€‰)
# export ENFLAME_LOG_DEBUG_LEVEL="DEBUG"
# export ENFLAME_LOG_DEBUG_MOD="TORCH_GCU/OP,TORCH_GCU/FALLBACK"

echo "  - MASTER_ADDR: $MASTER_ADDR"
echo "  - MASTER_PORT: $MASTER_PORT"
echo "  - WORLD_SIZE: $WORLD_SIZE"
echo "  - PYTORCH_GCU_ALLOC_CONF: $PYTORCH_GCU_ALLOC_CONF"

# 3. é€‰æ‹©é…ç½®æ–‡ä»¶
echo ""
echo "ğŸ“ é€‰æ‹©è®­ç»ƒé…ç½®:"
echo "1. DINOv3 + LoveDA (æ¨è)"
echo "2. DINOv3 + MMRS1M"
echo "3. è‡ªå®šä¹‰é…ç½®æ–‡ä»¶"
echo ""
read -p "è¯·é€‰æ‹©é…ç½® (1-3): " config_choice

case $config_choice in
    1)
        CONFIG_FILE="configs/train_dinov3_loveda_t20_gcu.py"
        echo "âœ… é€‰æ‹©é…ç½®: DINOv3 + LoveDA"
        ;;
    2)
        CONFIG_FILE="configs/train_dinov3_mmrs1m_t20_gcu_8card.py"
        echo "âœ… é€‰æ‹©é…ç½®: DINOv3 + MMRS1M"
        ;;
    3)
        echo ""
        echo "å¯ç”¨é…ç½®æ–‡ä»¶:"
        ls -1 configs/*t20*gcu*.py 2>/dev/null || echo "  (æœªæ‰¾åˆ°T20 GCUé…ç½®æ–‡ä»¶)"
        echo ""
        read -p "è¯·è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„: " CONFIG_FILE
        ;;
    *)
        echo "âŒ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
        CONFIG_FILE="configs/train_dinov3_loveda_t20_gcu.py"
        ;;
esac

# æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$CONFIG_FILE" ]; then
    echo "âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $CONFIG_FILE"
    exit 1
fi

echo "ğŸ“„ ä½¿ç”¨é…ç½®æ–‡ä»¶: $CONFIG_FILE"

# 4. è®¾ç½®å·¥ä½œç›®å½•
WORK_DIR="test_work_dir/$(basename $CONFIG_FILE .py)_$(date +%Y%m%d_%H%M%S)"
echo "ğŸ“ å·¥ä½œç›®å½•: $WORK_DIR"

# 5. é€‰æ‹©å¯åŠ¨æ–¹å¼
echo ""
echo "ğŸ¯ é€‰æ‹©å¯åŠ¨æ–¹å¼:"
echo "1. äº¤äº’å¼å¯åŠ¨ (æ¨èï¼Œå¯å®æ—¶æŸ¥çœ‹è¾“å‡º)"
echo "2. åå°å¯åŠ¨ (æ—¥å¿—ä¿å­˜åˆ°æ–‡ä»¶)"
echo ""
read -p "è¯·é€‰æ‹©å¯åŠ¨æ–¹å¼ (1-2): " start_choice

# 6. æ„å»ºè®­ç»ƒå‘½ä»¤
TRAIN_CMD="python3 scripts/train_distributed_8card_gcu.py \\
    --config $CONFIG_FILE \\
    --work-dir $WORK_DIR \\
    --launcher pytorch"

echo ""
echo "ğŸš€ å‡†å¤‡å¯åŠ¨8å¡åˆ†å¸ƒå¼è®­ç»ƒ..."
echo "å‘½ä»¤: $TRAIN_CMD"
echo ""

case $start_choice in
    1)
        echo "ğŸ“º äº¤äº’å¼å¯åŠ¨ - æŒ‰Ctrl+Cåœæ­¢è®­ç»ƒ"
        echo "=================================="
        sleep 2
        
        # äº¤äº’å¼å¯åŠ¨
        eval $TRAIN_CMD
        ;;
    2)
        LOG_FILE="$WORK_DIR/training.log"
        mkdir -p $(dirname $LOG_FILE)
        
        echo "ğŸ“ åå°å¯åŠ¨ - æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
        echo "ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ—¥å¿—:"
        echo "  tail -f $LOG_FILE"
        echo ""
        
        # åå°å¯åŠ¨
        nohup bash -c "$TRAIN_CMD" > $LOG_FILE 2>&1 &
        TRAIN_PID=$!
        
        echo "âœ… è®­ç»ƒå·²å¯åŠ¨ï¼Œè¿›ç¨‹ID: $TRAIN_PID"
        echo "ğŸ“Š å®æ—¶ç›‘æ§æ—¥å¿—:"
        echo "=================================="
        
        # æ˜¾ç¤ºå‰å‡ è¡Œæ—¥å¿—
        sleep 3
        tail -f $LOG_FILE
        ;;
    *)
        echo "âŒ æ— æ•ˆé€‰æ‹©"
        exit 1
        ;;
esac

echo ""
echo "ğŸ‰ è®­ç»ƒå¯åŠ¨å®Œæˆï¼"

# 7. è®­ç»ƒåæ“ä½œæç¤º
echo ""
echo "ğŸ’¡ è®­ç»ƒç®¡ç†å‘½ä»¤:"
echo "  - æŸ¥çœ‹è¿›ç¨‹: ps aux | grep train_distributed"
echo "  - åœæ­¢è®­ç»ƒ: pkill -f train_distributed"
echo "  - æŸ¥çœ‹GPUä½¿ç”¨: watch -n 1 'python3 -c \"import torch_gcu; print(torch_gcu.device_count())\"'"
echo "  - æŸ¥çœ‹æ—¥å¿—: tail -f $WORK_DIR/training.log"