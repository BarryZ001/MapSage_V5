#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„è®­ç»ƒç¯å¢ƒè®¾ç½®
éªŒè¯é…ç½®æ–‡ä»¶ä¿®å¤å’Œç¯å¢ƒå…¼å®¹æ€§
"""

import os
import sys
import importlib.util
import subprocess

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½")
    print("=" * 50)
    
    config_path = "configs/train_dinov3_mmrs1m_t20_gcu_8card_fixed.py"
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    try:
        # åŠ¨æ€åŠ è½½é…ç½®æ–‡ä»¶
        spec = importlib.util.spec_from_file_location("config", config_path)
        if spec is None or spec.loader is None:
            print(f"âŒ æ— æ³•åˆ›å»ºé…ç½®æ–‡ä»¶è§„èŒƒ: {config_path}")
            return False
            
        config_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(config_module)
        
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        if hasattr(config_module, 'model'):
            print("âœ… model é…ç½®å­˜åœ¨")
        if hasattr(config_module, 'train_dataloader'):
            print("âœ… train_dataloader é…ç½®å­˜åœ¨")
        if hasattr(config_module, 'optim_wrapper'):
            print("âœ… optim_wrapper é…ç½®å­˜åœ¨")
            
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

def test_distributed_backend_fallback():
    """æµ‹è¯•åˆ†å¸ƒå¼backend fallbacké€»è¾‘"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•åˆ†å¸ƒå¼backend fallback")
    print("=" * 50)
    
    try:
        import torch.distributed as dist
        
        # è·å–å¯ç”¨çš„backend
        available_backends = []
        if hasattr(dist, 'Backend'):
            for backend_name in ['nccl', 'gloo', 'mpi']:
                if hasattr(dist.Backend, backend_name.upper()):
                    available_backends.append(backend_name)
        
        print(f"âœ… å¯ç”¨çš„åˆ†å¸ƒå¼backend: {available_backends}")
        
        # æµ‹è¯•backendé€‰æ‹©é€»è¾‘
        if 'nccl' in available_backends:
            print("âœ… NCCL backend å¯ç”¨ (æ¨èç”¨äºGPU)")
        if 'gloo' in available_backends:
            print("âœ… Gloo backend å¯ç”¨ (CPU fallback)")
            
        return len(available_backends) > 0
        
    except ImportError as e:
        print(f"âŒ torch.distributed å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_torch_gcu_integration():
    """æµ‹è¯•torch_gcué›†æˆ"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•torch_gcué›†æˆ")
    print("=" * 50)
    
    try:
        # å°è¯•å¯¼å…¥torch_gcu
        torch_gcu = __import__('torch_gcu')
        print("âœ… torch_gcu å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥åŸºæœ¬åŠŸèƒ½
        if hasattr(torch_gcu, 'device_count'):
            device_count = torch_gcu.device_count()
            print(f"âœ… GCUè®¾å¤‡æ•°é‡: {device_count}")
        
        return True
        
    except ImportError:
        print("âš ï¸  torch_gcu æœªå®‰è£… (åœ¨T20æœåŠ¡å™¨ä¸Šåº”è¯¥å¯ç”¨)")
        return True  # åœ¨æœ¬åœ°ç¯å¢ƒè¿™æ˜¯æ­£å¸¸çš„

def test_environment_detection():
    """æµ‹è¯•ç¯å¢ƒæ£€æµ‹è„šæœ¬"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•ç¯å¢ƒæ£€æµ‹è„šæœ¬")
    print("=" * 50)
    
    script_path = "scripts/check_torch_gcu_environment.py"
    
    if not os.path.exists(script_path):
        print(f"âŒ ç¯å¢ƒæ£€æµ‹è„šæœ¬ä¸å­˜åœ¨: {script_path}")
        return False
    
    try:
        # åŠ¨æ€åŠ è½½ç¯å¢ƒæ£€æµ‹è„šæœ¬
        spec = importlib.util.spec_from_file_location("env_check", script_path)
        if spec is None or spec.loader is None:
            print(f"âŒ æ— æ³•åˆ›å»ºç¯å¢ƒæ£€æµ‹è„šæœ¬è§„èŒƒ: {script_path}")
            return False
            
        env_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(env_module)
        
        print("âœ… ç¯å¢ƒæ£€æµ‹è„šæœ¬åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥å…³é”®å‡½æ•°
        if hasattr(env_module, 'check_torch_gcu_environment'):
            print("âœ… check_torch_gcu_environment å‡½æ•°å­˜åœ¨")
        if hasattr(env_module, 'check_topsrider_installation'):
            print("âœ… check_topsrider_installation å‡½æ•°å­˜åœ¨")
            
        return True
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒæ£€æµ‹è„šæœ¬åŠ è½½å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¿®å¤åçš„è®­ç»ƒç¯å¢ƒè®¾ç½®")
    print("=" * 60)
    
    tests = [
        ("é…ç½®æ–‡ä»¶åŠ è½½", test_config_loading),
        ("åˆ†å¸ƒå¼backend fallback", test_distributed_backend_fallback),
        ("torch_gcué›†æˆ", test_torch_gcu_integration),
        ("ç¯å¢ƒæ£€æµ‹è„šæœ¬", test_environment_detection),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            if result:
                passed += 1
                print(f"âœ… {test_name}: é€šè¿‡")
            else:
                print(f"âŒ {test_name}: å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name}: å¼‚å¸¸ - {e}")
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒä¿®å¤æˆåŠŸ")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶")
        return 1

if __name__ == "__main__":
    sys.exit(main())