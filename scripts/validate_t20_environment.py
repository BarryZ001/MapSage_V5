#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
T20ç¯å¢ƒéªŒè¯è„šæœ¬
éªŒè¯æ•°æ®é›†è·¯å¾„ã€æƒé‡æ–‡ä»¶å’Œè®­ç»ƒç¯å¢ƒé…ç½®
"""

import os
import sys
import subprocess
from pathlib import Path
from datetime import datetime

# å°è¯•å¯¼å…¥torchï¼Œå¦‚æœå¤±è´¥åˆ™è®¾ç½®ä¸ºNone
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    torch = None
    TORCH_AVAILABLE = False

def print_header(title):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ” {title}")
    print(f"{'='*60}")

def print_success(message):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"âœ… {message}")

def print_error(message):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"âŒ {message}")

def print_warning(message):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(f"âš ï¸  {message}")

def check_python_environment():
    """æ£€æŸ¥Pythonç¯å¢ƒ"""
    print_header("Pythonç¯å¢ƒæ£€æŸ¥")
    
    # Pythonç‰ˆæœ¬
    python_version = sys.version
    print(f"Pythonç‰ˆæœ¬: {python_version}")
    
    # æ£€æŸ¥å…³é”®åŒ…
    packages = [
        'torch',
        'torchvision', 
        'mmcv',
        'mmsegmentation',
        'numpy',
        'opencv-python'
    ]
    
    for package in packages:
        try:
            __import__(package.replace('-', '_'))
            print_success(f"{package} å·²å®‰è£…")
        except ImportError:
            print_error(f"{package} æœªå®‰è£…")
    
    # PyTorchç‰ˆæœ¬å’ŒCUDAæ”¯æŒ
    if TORCH_AVAILABLE and torch is not None:
        print_success(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        if torch.cuda.is_available():
            try:
                # å°è¯•è·å–CUDAç‰ˆæœ¬ä¿¡æ¯
                cuda_version = "æœªçŸ¥"
                try:
                    # æ–¹æ³•1: å°è¯•é€šè¿‡torchå†…ç½®æ–¹æ³•è·å–
                    import torch.version as tv
                    if hasattr(tv, 'cuda') and tv.cuda is not None:
                        cuda_version = tv.cuda
                except (ImportError, AttributeError):
                    # æ–¹æ³•2: é€šè¿‡nvidia-smiè·å–é©±åŠ¨ç‰ˆæœ¬
                    try:
                        result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'], 
                                              capture_output=True, text=True, timeout=10)
                        if result.returncode == 0:
                            cuda_version = f"Driver: {result.stdout.strip()}"
                    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
                        pass
                
                print_success(f"CUDAç‰ˆæœ¬: {cuda_version}")
            except Exception:
                print_warning("æ— æ³•è·å–CUDAç‰ˆæœ¬ä¿¡æ¯")
            
            print_success(f"å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                print_success(f"GPU {i}: {gpu_name}")
        else:
            print_warning("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    else:
        print_error("PyTorchæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")

def check_dataset_paths():
    """æ£€æŸ¥æ•°æ®é›†è·¯å¾„"""
    print_header("æ•°æ®é›†è·¯å¾„æ£€æŸ¥")
    
    # LoveDAæ•°æ®é›†
    loveda_root = Path('/workspace/data/loveda')
    if loveda_root.exists():
        print_success(f"LoveDAæ•°æ®é›†æ ¹ç›®å½•å­˜åœ¨: {loveda_root}")
        
        # æ£€æŸ¥å­ç›®å½•ç»“æ„
        expected_dirs = [
            'Train/Rural/images_png',
            'Train/Rural/masks_png',
            'Train/Urban/images_png', 
            'Train/Urban/masks_png',
            'Val/Rural/images_png',
            'Val/Rural/masks_png',
            'Val/Urban/images_png',
            'Val/Urban/masks_png',
            'Test/Rural/images_png',
            'Test/Urban/images_png'
        ]
        
        for dir_path in expected_dirs:
            full_path = loveda_root / dir_path
            if full_path.exists():
                file_count = len(list(full_path.glob('*.png')))
                print_success(f"{dir_path}: {file_count} ä¸ªæ–‡ä»¶")
            else:
                print_error(f"{dir_path}: ç›®å½•ä¸å­˜åœ¨")
    else:
        print_error(f"LoveDAæ•°æ®é›†æ ¹ç›®å½•ä¸å­˜åœ¨: {loveda_root}")
    
    # MMRS1Mæ•°æ®é›†
    mmrs1m_root = Path('/workspace/data/mmrs1m/data')
    if mmrs1m_root.exists():
        print_success(f"MMRS1Mæ•°æ®é›†æ ¹ç›®å½•å­˜åœ¨: {mmrs1m_root}")
        
        # æ£€æŸ¥ä¸»è¦å­ç›®å½•
        main_dirs = ['classification', 'detection', 'caption', 'VQA', 'RSVG', 'json']
        for dir_name in main_dirs:
            dir_path = mmrs1m_root / dir_name
            if dir_path.exists():
                print_success(f"MMRS1M/{dir_name}: ç›®å½•å­˜åœ¨")
            else:
                print_warning(f"MMRS1M/{dir_name}: ç›®å½•ä¸å­˜åœ¨")
    else:
        print_error(f"MMRS1Mæ•°æ®é›†æ ¹ç›®å½•ä¸å­˜åœ¨: {mmrs1m_root}")

def check_pretrained_weights():
    """æ£€æŸ¥é¢„è®­ç»ƒæƒé‡"""
    print_header("é¢„è®­ç»ƒæƒé‡æ£€æŸ¥")
    
    weights_dir = Path('/workspace/weights')
    if not weights_dir.exists():
        print_error(f"æƒé‡ç›®å½•ä¸å­˜åœ¨: {weights_dir}")
        return
    
    print_success(f"æƒé‡ç›®å½•å­˜åœ¨: {weights_dir}")
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    weight_files = [
        'dinov3_vitl16_pretrain_sat493m-eadcf0ff.pth',
        'best_mIoU_iter_6000.pth'
    ]
    
    for weight_file in weight_files:
        weight_path = weights_dir / weight_file
        if weight_path.exists():
            file_size = weight_path.stat().st_size / (1024 * 1024)  # MB
            print_success(f"{weight_file}: å­˜åœ¨ ({file_size:.1f} MB)")
            
            # å°è¯•åŠ è½½æƒé‡æ–‡ä»¶
            if TORCH_AVAILABLE and torch is not None:
                try:
                    checkpoint = torch.load(weight_path, map_location='cpu')
                    if isinstance(checkpoint, dict):
                        keys = list(checkpoint.keys())
                        print_success(f"  æƒé‡æ–‡ä»¶ç»“æ„: {keys[:5]}...")
                    else:
                        print_success(f"  æƒé‡æ–‡ä»¶ç±»å‹: {type(checkpoint)}")
                except Exception as e:
                    print_error(f"  æ— æ³•åŠ è½½æƒé‡æ–‡ä»¶: {e}")
            else:
                print_warning("  PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡æƒé‡æ–‡ä»¶åŠ è½½æµ‹è¯•")
        else:
            print_error(f"{weight_file}: ä¸å­˜åœ¨")

def check_project_structure():
    """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
    print_header("é¡¹ç›®ç»“æ„æ£€æŸ¥")
    
    project_root = Path('/workspace/code/MapSage_V5')
    if not project_root.exists():
        print_error(f"é¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨: {project_root}")
        return
    
    print_success(f"é¡¹ç›®æ ¹ç›®å½•å­˜åœ¨: {project_root}")
    
    # æ£€æŸ¥å…³é”®ç›®å½•å’Œæ–‡ä»¶
    important_paths = [
        'configs',
        'mmseg_custom',
        'scripts',
        'scripts/train.py',
        'configs/train_dinov3_mmrs1m_t20_gcu.py',
        'configs/train_dinov3_loveda_t20_gcu.py'
    ]
    
    for path_str in important_paths:
        path = project_root / path_str
        if path.exists():
            if path.is_dir():
                file_count = len(list(path.iterdir()))
                print_success(f"{path_str}/: ç›®å½•å­˜åœ¨ ({file_count} ä¸ªé¡¹ç›®)")
            else:
                print_success(f"{path_str}: æ–‡ä»¶å­˜åœ¨")
        else:
            print_error(f"{path_str}: ä¸å­˜åœ¨")

def check_training_configs():
    """æ£€æŸ¥è®­ç»ƒé…ç½®æ–‡ä»¶"""
    print_header("è®­ç»ƒé…ç½®æ–‡ä»¶æ£€æŸ¥")
    
    config_files = [
        '/workspace/code/MapSage_V5/configs/train_dinov3_mmrs1m_t20_gcu.py',
        '/workspace/code/MapSage_V5/configs/train_dinov3_loveda_t20_gcu.py'
    ]
    
    for config_file in config_files:
        config_path = Path(config_file)
        if config_path.exists():
            print_success(f"é…ç½®æ–‡ä»¶å­˜åœ¨: {config_path.name}")
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶å†…å®¹
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # æ£€æŸ¥å…³é”®é…ç½®
                if 'data_root' in content:
                    print_success(f"  åŒ…å«data_rooté…ç½®")
                if 'checkpoint' in content:
                    print_success(f"  åŒ…å«checkpointé…ç½®")
                if 'work_dir' in content:
                    print_success(f"  åŒ…å«work_diré…ç½®")
                    
            except Exception as e:
                print_error(f"  æ— æ³•è¯»å–é…ç½®æ–‡ä»¶: {e}")
        else:
            print_error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    print_header("ç£ç›˜ç©ºé—´æ£€æŸ¥")
    
    try:
        # æ£€æŸ¥å·¥ä½œç›®å½•ç©ºé—´
        result = subprocess.run(['df', '-h', '/workspace'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if len(lines) >= 2:
                header = lines[0]
                data = lines[1]
                print(f"å·¥ä½œç›®å½•ç£ç›˜ä½¿ç”¨æƒ…å†µ:")
                print(f"  {header}")
                print(f"  {data}")
                
                # è§£æå¯ç”¨ç©ºé—´
                parts = data.split()
                if len(parts) >= 4:
                    available = parts[3]
                    print_success(f"å¯ç”¨ç©ºé—´: {available}")
        else:
            print_warning("æ— æ³•è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯")
            
    except Exception as e:
        print_warning(f"ç£ç›˜ç©ºé—´æ£€æŸ¥å¤±è´¥: {e}")

def check_gpu_memory():
    """æ£€æŸ¥GPUå†…å­˜"""
    print_header("GPUå†…å­˜æ£€æŸ¥")
    
    if not TORCH_AVAILABLE or torch is None:
        print_warning("PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡GPUå†…å­˜æ£€æŸ¥")
        return
    
    if not torch.cuda.is_available():
        print_warning("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUå†…å­˜æ£€æŸ¥")
        return
    
    try:
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            total_memory = torch.cuda.get_device_properties(i).total_memory
            total_memory_gb = total_memory / (1024**3)
            
            # è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
            torch.cuda.set_device(i)
            allocated = torch.cuda.memory_allocated(i)
            cached = torch.cuda.memory_reserved(i)
            
            allocated_gb = allocated / (1024**3)
            cached_gb = cached / (1024**3)
            
            print_success(f"GPU {i} ({gpu_name}):")
            print_success(f"  æ€»å†…å­˜: {total_memory_gb:.1f} GB")
            print_success(f"  å·²åˆ†é…: {allocated_gb:.1f} GB")
            print_success(f"  å·²ç¼“å­˜: {cached_gb:.1f} GB")
            
    except Exception as e:
        print_error(f"GPUå†…å­˜æ£€æŸ¥å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("T20ç¯å¢ƒéªŒè¯å¼€å§‹")
    print(f"éªŒè¯æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    check_python_environment()
    check_dataset_paths()
    check_pretrained_weights()
    check_project_structure()
    check_training_configs()
    check_disk_space()
    check_gpu_memory()
    
    print_header("éªŒè¯å®Œæˆ")
    print("T20ç¯å¢ƒéªŒè¯å®Œæˆï¼")
    print("è¯·æ ¹æ®ä¸Šè¿°æ£€æŸ¥ç»“æœä¿®å¤ä»»ä½•å‘ç°çš„é—®é¢˜")
    print("ç¯å¢ƒå°±ç»ªåå³å¯å¼€å§‹è®­ç»ƒ")

if __name__ == '__main__':
    main()