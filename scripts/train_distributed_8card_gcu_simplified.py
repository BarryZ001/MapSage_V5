#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ - ç‡§åŸT20 GCUæœ€ç»ˆä¿®æ­£ç‰ˆ V3
é€šè¿‡åœ¨Runneråˆå§‹åŒ–å‰æ³¨å…¥æ­£ç¡®é…ç½®ï¼Œå¼•å¯¼MMEngineä½¿ç”¨æ­£ç¡®çš„DDPå‚æ•°ã€‚
"""

import argparse
import os
import sys
import torch
import torch.distributed as dist

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '.')

from mmengine.config import Config
from mmengine.runner import Runner

try:
    import torch_gcu
    print(f"âœ… torch_gcu å¯¼å…¥æˆåŠŸï¼Œè®¾å¤‡æ•°é‡: {torch_gcu.device_count()}")
except ImportError as e:
    print(f"âŒ é”™è¯¯: torch_gcu å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description='8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬-ç‡§åŸT20 GCUæœ€ç»ˆä¿®æ­£ç‰ˆ V3')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='å·¥ä½œç›®å½•è·¯å¾„')
    parser.add_argument('--launcher', choices=['pytorch'], default='pytorch', help='åˆ†å¸ƒå¼å¯åŠ¨å™¨')
    args = parser.parse_args()

    # --- æ­¥éª¤ 1: åŠ è½½é…ç½®æ–‡ä»¶ ---
    cfg = Config.fromfile(args.config)
    if args.work_dir:
        cfg.work_dir = args.work_dir
    if hasattr(cfg, 'work_dir') and cfg.work_dir:
        os.makedirs(cfg.work_dir, exist_ok=True)

    # --- æ­¥éª¤ 2: åˆå§‹åŒ–åˆ†å¸ƒå¼åç«¯ ---
    # è¿™æ˜¯æ‰€æœ‰åˆ†å¸ƒå¼æ“ä½œçš„ç¬¬ä¸€æ­¥ï¼Œå¹¶ä¸”å¿…é¡»åœ¨MMEngineçš„ä»»ä½•æ“ä½œä¹‹å‰å®Œæˆã€‚
    if 'RANK' in os.environ:
        print("ğŸ”§ åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„ï¼Œä½¿ç”¨ç‡§åŸå®˜æ–¹æ¨èçš„ 'eccl' åç«¯...")
        dist.init_process_group(backend='eccl', init_method='env://')
        rank = dist.get_rank()
        local_rank = int(os.environ.get('LOCAL_RANK', rank))
        print(f"âœ… [Rank {rank}] ECCL åç«¯åˆå§‹åŒ–æˆåŠŸã€‚")
    else:
        local_rank = 0
        
    # --- æ­¥éª¤ 3: å…³é”®ä¿®å¤ - åœ¨Runneråˆ›å»ºå‰ï¼Œå‘é…ç½®ä¸­æ³¨å…¥GCUé€‚é…ä¿¡æ¯ ---
    # è¿™æ˜¯è§£å†³æ‰€æœ‰é—®é¢˜çš„æ ¸å¿ƒæ‰€åœ¨
    
    # 3.1 å¼ºåˆ¶æŒ‡å®šè®¾å¤‡ä¸º 'gcu'ï¼ŒMMEngineä¼šä½¿ç”¨æ­¤é…ç½®å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
    cfg.device = 'gcu'
    
    # 3.2 å¼ºåˆ¶æŒ‡å®šåˆ†å¸ƒå¼åç«¯ä¸º 'eccl'
    if not hasattr(cfg, 'env_cfg'):
        cfg.env_cfg = {}
    cfg.env_cfg['dist_cfg'] = {'backend': 'eccl'}
    
    # 3.3 å¼ºåˆ¶æŒ‡å®šDDPåŒ…è£…å™¨çš„å‚æ•°ï¼Œç¦ç”¨device_idsè‡ªåŠ¨åˆ†é…
    # MMEngineä¼šä½¿ç”¨è¿™ä¸ªé…ç½®æ¥åˆ›å»ºMMDistributedDataParallel
    cfg.model_wrapper_cfg = dict(
        type='MMDistributedDataParallel',
        find_unused_parameters=False,
        device_ids=None,  # å…³é”®ï¼šè®¾ç½®ä¸ºNoneï¼Œè®©DDPä½¿ç”¨å½“å‰è¿›ç¨‹çš„è®¾å¤‡
        output_device=None # å…³é”®ï¼šåŒæ ·è®¾ç½®ä¸ºNone
    )
    
    # 3.4 ç¦ç”¨SyncBN (å¯é€‰ï¼Œä½†æ¨èç”¨äºè§£å†³æ½œåœ¨çš„SyncBNé—®é¢˜)
    # å¦‚æœæ‚¨ä»ç„¶é‡åˆ°SyncBatchNormç›¸å…³é”™è¯¯ï¼Œè¯·å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    # from mmengine.model import revert_sync_batchnorm
    # cfg.model = revert_sync_batchnorm(cfg.model)
    # print("ğŸ”§ å·²å°†æ¨¡å‹ä¸­çš„SyncBatchNormè½¬æ¢ä¸ºæ™®é€šBatchNorm")

    print(f"ğŸ”§ [Rank {local_rank}] æ‰€æœ‰GCUé€‚é…é…ç½®å·²æ³¨å…¥ã€‚")

    # --- æ­¥éª¤ 4: åˆ›å»ºå¹¶è¿è¡Œ Runner ---
    # ç°åœ¨cfgå¯¹è±¡å·²ç»åŒ…å«äº†æ‰€æœ‰æ­£ç¡®çš„GCUé€‚é…ä¿¡æ¯
    # Runner.from_cfg() ä¼šè¯»å–è¿™äº›ä¿¡æ¯å¹¶æ‰§è¡Œæ­£ç¡®çš„åˆå§‹åŒ–æµç¨‹
    print("ğŸš€ åˆ›å»º MMEngine Runner...")
    runner = Runner.from_cfg(cfg)
    
    # éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
    model_device = next(runner.model.parameters()).device
    print(f"âœ… [Rank {local_rank}] Runneråˆ›å»ºæˆåŠŸï¼Œæ¨¡å‹ä½äºè®¾å¤‡: {model_device}")
    
    if 'cpu' in str(model_device):
        print(f"âŒ [Rank {local_rank}] è‡´å‘½é”™è¯¯: æ¨¡å‹ä»ç„¶åœ¨CPUä¸Šï¼è¯·æ£€æŸ¥MMEngineç‰ˆæœ¬å…¼å®¹æ€§ã€‚")
        sys.exit(1)

    print(f"ğŸ‰ [Rank {local_rank}] æ‰€æœ‰å‡†å¤‡å·¥ä½œå®Œæˆï¼Œå³å°†å¼€å§‹è®­ç»ƒï¼")
    runner.train()

    # --- æ­¥éª¤ 5: æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ ---
    if dist.is_initialized():
        dist.destroy_process_group()

if __name__ == '__main__':
    main()