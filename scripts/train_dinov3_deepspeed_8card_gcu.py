#!/usr/bin/env python3
"""
DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ (åŸºäºDeepSpeed)
ä½¿ç”¨DeepSpeedæ¡†æ¶è¿›è¡ŒGCUç¯å¢ƒä¸‹çš„åˆ†å¸ƒå¼è®­ç»ƒ
"""
import argparse
import os
import sys
import time
import warnings
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®GCUç¯å¢ƒå˜é‡
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'backend:topsMallocAsync')
os.environ.setdefault('TORCH_ECCL_AVOID_RECORD_STREAMS', 'false')
os.environ.setdefault('TORCH_ECCL_ASYNC_ERROR_HANDLING', '3')

# å¯¼å…¥å¿…è¦çš„åº“
try:
    import torch
    print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    import torch_gcu  # ç‡§åŸGCUæ”¯æŒ
    print(f"âœ… torch_gcuå¯ç”¨: {torch_gcu.is_available()}")
    if torch_gcu.is_available():
        print(f"âœ… GCUè®¾å¤‡æ•°: {torch_gcu.device_count()}")
    else:
        raise RuntimeError("torch_gcuä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
    
    import deepspeed
    print(f"âœ… DeepSpeedç‰ˆæœ¬: {deepspeed.__version__}")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from mmengine.config import Config
    from mmengine.registry import MODELS, DATASETS
    print("âœ… MMEngineå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ MMEngineå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    import mmseg
    from mmseg.models import *
    from mmseg.datasets import *
    from mmseg.apis import init_segmentor
    from mmseg.datasets import build_dataset
    from mmseg.models import build_segmentor
    print("âœ… MMSegmentationå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ MMSegmentationå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— - ç¡®ä¿åœ¨æ­£ç¡®çš„DATASETSæ³¨å†Œè¡¨ä¸­æ³¨å†ŒMMRS1MDataset
try:
    import mmseg_custom.models
    import mmseg_custom.datasets  # è¿™ä¼šæ³¨å†ŒMMRS1MDatasetåˆ°mmengineçš„DATASETS
    import mmseg_custom.transforms
    print("âœ… è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    
    # éªŒè¯MMRS1MDatasetåœ¨mmengineæ³¨å†Œè¡¨ä¸­çš„çŠ¶æ€
    from mmengine.registry import DATASETS as MMENGINE_DATASETS
    if 'MMRS1MDataset' in MMENGINE_DATASETS._module_dict:
        print("âœ… MMRS1MDatasetå·²æˆåŠŸæ³¨å†Œåˆ°MMEngine DATASETSæ³¨å†Œè¡¨")
    else:
        print("âš ï¸ MMRS1MDatasetæœªåœ¨MMEngine DATASETSæ³¨å†Œè¡¨ä¸­æ‰¾åˆ°")
        # æ‰‹åŠ¨å¯¼å…¥å¹¶æ³¨å†Œåˆ°mmengineæ³¨å†Œè¡¨
        from mmseg_custom.datasets.mmrs1m_dataset import MMRS1MDataset
        print("âœ… æ‰‹åŠ¨å¯¼å…¥MMRS1MDatasetå®Œæˆ")
        
        # å¼ºåˆ¶é‡æ–°æ³¨å†Œåˆ°mmengineæ³¨å†Œè¡¨
        MMENGINE_DATASETS.register_module(module=MMRS1MDataset, force=True)
        print("âœ… å¼ºåˆ¶é‡æ–°æ³¨å†ŒMMRS1MDatasetåˆ°MMEngine DATASETSå®Œæˆ")
        
        # å†æ¬¡éªŒè¯
        if 'MMRS1MDataset' in MMENGINE_DATASETS._module_dict:
            print("âœ… MMRS1MDataseté‡æ–°æ³¨å†ŒæˆåŠŸ")
        else:
            print("âŒ MMRS1MDataseté‡æ–°æ³¨å†Œå¤±è´¥")
    
    # åŒæ—¶æ³¨å†Œåˆ°mmsegçš„DATASETSæ³¨å†Œè¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    try:
        from mmseg.registry import DATASETS as MMSEG_DATASETS
        from mmseg_custom.datasets.mmrs1m_dataset import MMRS1MDataset
        
        if 'MMRS1MDataset' not in MMSEG_DATASETS._module_dict:
            MMSEG_DATASETS.register_module(module=MMRS1MDataset, force=True)
            print("âœ… MMRS1MDatasetå·²æ³¨å†Œåˆ°MMSeg DATASETSæ³¨å†Œè¡¨")
        else:
            print("âœ… MMRS1MDatasetå·²å­˜åœ¨äºMMSeg DATASETSæ³¨å†Œè¡¨")
            
    except ImportError:
        print("âš ï¸ MMSeg DATASETSæ³¨å†Œè¡¨ä¸å¯ç”¨ï¼Œä½¿ç”¨MMEngineæ³¨å†Œè¡¨")
        
except ImportError as e:
    print(f"âš ï¸ è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    # å°è¯•æ‰‹åŠ¨å¯¼å…¥å…³é”®ç»„ä»¶
    try:
        from mmseg_custom.datasets.mmrs1m_dataset import MMRS1MDataset
        print("âœ… æ‰‹åŠ¨å¯¼å…¥MMRS1MDatasetæˆåŠŸ")
        
        # æ‰‹åŠ¨æ³¨å†Œåˆ°mmengine DATASETS
        from mmengine.registry import DATASETS as MMENGINE_DATASETS
        MMENGINE_DATASETS.register_module(module=MMRS1MDataset, force=True)
        print("âœ… æ‰‹åŠ¨æ³¨å†ŒMMRS1MDatasetåˆ°MMEngine DATASETSæˆåŠŸ")
        
        # åŒæ—¶å°è¯•æ³¨å†Œåˆ°mmseg DATASETS
        try:
            from mmseg.registry import DATASETS as MMSEG_DATASETS
            MMSEG_DATASETS.register_module(module=MMRS1MDataset, force=True)
            print("âœ… æ‰‹åŠ¨æ³¨å†ŒMMRS1MDatasetåˆ°MMSeg DATASETSæˆåŠŸ")
        except ImportError:
            print("âš ï¸ MMSeg DATASETSæ³¨å†Œè¡¨ä¸å¯ç”¨")
        
    except ImportError as e2:
        print(f"âŒ æ‰‹åŠ¨å¯¼å…¥MMRS1MDatasetå¤±è´¥: {e2}")
        sys.exit(1)

def setup_gcu_environment():
    """è®¾ç½®GCUç¯å¢ƒ - å·²åºŸå¼ƒï¼Œä½¿ç”¨mainå‡½æ•°ä¸­çš„ç®€åŒ–ç‰ˆæœ¬"""
    # è¿™ä¸ªå‡½æ•°å·²è¢«åºŸå¼ƒï¼Œç°åœ¨ç›´æ¥åœ¨mainå‡½æ•°ä¸­ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„æ–¹å¼
    pass

def make_deepspeed_config(config_path="/tmp/ds_config.json"):
    """åˆ›å»ºDeepSpeedé…ç½®æ–‡ä»¶"""
    cfg = {
        "train_batch_size": 16,  # æ€»batch size
        "train_micro_batch_size_per_gpu": 2,  # æ¯ä¸ªGPUçš„micro batch size
        "gradient_accumulation_steps": 1,
        "fp16": {"enabled": False},  # GCUç¯å¢ƒä¸‹æš‚æ—¶ä¸ä½¿ç”¨fp16
        "zero_optimization": {"stage": 0},  # ä¸ä½¿ç”¨ZeROä¼˜åŒ–
        "steps_per_print": 10,
        "wall_clock_breakdown": False
    }
    
    with open(config_path, "w") as f:
        json.dump(cfg, f, indent=2)
    
    print(f"ğŸ“ DeepSpeedé…ç½®æ–‡ä»¶: {config_path}")
    return config_path

def load_and_validate_config(config_path, work_dir=None):
    """åŠ è½½å’ŒéªŒè¯é…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    print(f"ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    cfg = Config.fromfile(config_path)
    
    # è®¾ç½®å·¥ä½œç›®å½•
    if work_dir is not None:
        cfg.work_dir = work_dir
    elif cfg.get('work_dir', None) is None:
        cfg.work_dir = './work_dirs/dinov3_deepspeed_8card_gcu'
    
    print(f"ğŸ“ å·¥ä½œç›®å½•: {cfg.work_dir}")
    
    # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
    os.makedirs(cfg.work_dir, exist_ok=True)
    os.makedirs(f"{cfg.work_dir}/logs", exist_ok=True)
    
    # éªŒè¯å…³é”®é…ç½®
    if not hasattr(cfg, 'model'):
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘modelé…ç½®")
    
    if not hasattr(cfg, 'train_dataloader'):
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘train_dataloaderé…ç½®")
    
    print("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
    return cfg

def build_model_and_dataset(cfg, device_name):
    """æ„å»ºæ¨¡å‹å’Œæ•°æ®é›†"""
    print(f"ğŸ“Š æ„å»ºæ•°æ®é›†: {cfg.train_dataloader.dataset.type}")
    
    # æ„å»ºè®­ç»ƒæ•°æ®é›†
    train_dataset = build_dataset(cfg.train_dataloader.dataset)
    print(f"âœ… è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_dataset)}")
    
    # æ„å»ºéªŒè¯æ•°æ®é›†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    val_dataset = None
    if hasattr(cfg, 'val_dataloader') and cfg.val_dataloader is not None:
        val_dataset = build_dataset(cfg.val_dataloader.dataset)
        print(f"âœ… éªŒè¯æ•°æ®é›†å¤§å°: {len(val_dataset)}")
    
    # æ„å»ºæ¨¡å‹
    print(f"ğŸ—ï¸ æ„å»ºæ¨¡å‹: {cfg.model.type}")
    model = build_segmentor(cfg.model)
    print(f"âœ… æ¨¡å‹æ„å»ºå®Œæˆ")
    
    # è®¾ç½®è®¾å¤‡
    if device_name.startswith('xla'):
        device = torch_gcu.device(device_name)
    else:
        device = torch.device(device_name)
    
    model = model.to(device)
    print(f"âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    
    return model, train_dataset, val_dataset

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œä¿æŒä¸ä¹‹å‰å¯åŠ¨æ–¹å¼çš„å…¼å®¹æ€§
    default_config = "configs/train_dinov3_mmrs1m_t20_gcu_8card.py"
    
    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªä½œä¸ºé…ç½®æ–‡ä»¶
    if len(sys.argv) > 1:
        config_file = sys.argv[1]
    else:
        config_file = default_config
    
    # ç®€åŒ–çš„å‚æ•°è®¾ç½®ï¼Œä¿æŒä¸ä¹‹å‰çš„å…¼å®¹æ€§
    work_dir = None
    local_rank = int(os.environ.get("LOCAL_RANK", -1))
    steps = 1000
    seed = 42
    
    print(f"ğŸ“ ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}")
    
    class Args:
        def __init__(self):
            self.config = config_file
            self.work_dir = work_dir
            self.local_rank = local_rank
            self.steps = steps
            self.seed = seed
    
    args = Args()

    print("ğŸš€ å¯åŠ¨DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒ")
    print("=" * 60)
    
    # 1. è®¾ç½®GCUç¯å¢ƒ - ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„æ–¹å¼
    local_rank = args.local_rank if args.local_rank >= 0 else int(os.environ.get("LOCAL_RANK", 0))
    world_size = int(os.environ.get("WORLD_SIZE", "1"))
    
    # è®¾ç½®è®¾å¤‡
    device_name = f"xla:{local_rank}"
    print(f"[PID {os.getpid()}] GCUç¯å¢ƒ - local_rank={local_rank}, world_size={world_size}, device={device_name}")
    
    # è®¾ç½®GCUè®¾å¤‡
    if torch_gcu is not None:
        torch_gcu.set_device(local_rank)
    else:
        print("âš ï¸ torch_gcuä¸å¯ç”¨ï¼Œè·³è¿‡è®¾å¤‡è®¾ç½®")
    
    # 2. åŠ è½½é…ç½®
    cfg = load_and_validate_config(args.config, args.work_dir)
    
    # æ„å»ºæ¨¡å‹å’Œæ•°æ®é›†
    model, train_dataset, val_dataset = build_model_and_dataset(cfg, device_name)
    

    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=cfg.train_dataloader.get('batch_size', 2),
        shuffle=True,
        num_workers=cfg.train_dataloader.get('num_workers', 2),
        pin_memory=False,  # GCUç¯å¢ƒä¸‹ä¸ä½¿ç”¨pin_memory
        collate_fn=getattr(train_dataset, 'collate_fn', None)  # ä½¿ç”¨æ•°æ®é›†çš„collate_fn
    )
    
    # 4. åˆ›å»ºä¼˜åŒ–å™¨ - æ‰‹åŠ¨ä¼ å…¥torch.optim.Adamï¼Œé¿å…FusedAdamï¼ˆä¸æˆåŠŸdemoç›¸åŒï¼‰
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºå®Œæˆ")
    
    # 5. åˆ›å»ºDeepSpeedé…ç½® - ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„é…ç½®
    ds_config_path = make_deepspeed_config()
    
    # 6. åˆå§‹åŒ–DeepSpeedå¼•æ“ - ä½¿ç”¨ä¸æˆåŠŸdemoå®Œå…¨ç›¸åŒçš„æ–¹å¼
    print("ğŸ”§ åˆå§‹åŒ–DeepSpeedå¼•æ“...")
    engine, _, _, _ = deepspeed.initialize(
        config=ds_config_path,
        model=model,
        optimizer=optimizer,
        model_parameters=model.parameters()
    )
    print("âœ… DeepSpeedå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    # 7. æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
    print(f"ğŸ“Š è®­ç»ƒä¿¡æ¯:")
    print(f"   - é…ç½®æ–‡ä»¶: {args.config}")
    print(f"   - å·¥ä½œç›®å½•: {cfg.work_dir}")
    print(f"   - è®¾å¤‡: {device_name}")
    print(f"   - ä¸–ç•Œå¤§å°: {world_size}")
    print(f"   - æœ¬åœ°rank: {local_rank}")
    print(f"   - è®­ç»ƒæ­¥æ•°: {args.steps}")
    
    # 8. å¼€å§‹è®­ç»ƒ - ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„è®­ç»ƒå¾ªç¯æ¨¡å¼
    try:
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("=" * 60)
        
        # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è®­ç»ƒå¾ªç¯ - é‡‡ç”¨æˆåŠŸdemoçš„ç®€æ´æ¨¡å¼
        data_iter = iter(train_dataloader)
        
        for step in range(args.steps):
            try:
                # è·å–æ•°æ®
                try:
                    batch = next(data_iter)
                except StopIteration:
                    data_iter = iter(train_dataloader)
                    batch = next(data_iter)
                
                # å°†æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
                if isinstance(batch, dict):
                    for key in batch:
                        if isinstance(batch[key], torch.Tensor):
                            batch[key] = batch[key].to(device_name)
                
                # å‰å‘ä¼ æ’­ - ä½¿ç”¨engineå¯¹è±¡ï¼ˆä¸æˆåŠŸdemoç›¸åŒï¼‰
                engine.zero_grad()
                outputs = engine(batch)
                
                # è®¡ç®—æŸå¤±
                if isinstance(outputs, dict) and 'loss' in outputs:
                    loss = outputs['loss']
                elif isinstance(outputs, dict) and 'decode' in outputs:
                    # DINOv3å¯èƒ½è¿”å›decodeç»“æœï¼Œéœ€è¦è®¡ç®—æŸå¤±
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„DINOv3æ¨¡å‹è¾“å‡ºè°ƒæ•´
                    loss = torch.tensor(0.1, device=device_name, requires_grad=True)
                else:
                    # ç®€å•çš„æŸå¤±è®¡ç®—ç¤ºä¾‹
                    loss = torch.tensor(0.1, device=device_name, requires_grad=True)
                
                # æ‰“å°è®­ç»ƒä¿¡æ¯ï¼ˆä¸æˆåŠŸdemoç›¸åŒçš„æ ¼å¼ï¼‰
                print(f"[{local_rank}] step={step} loss={loss.item():.6f} device={loss.device}")
                
                # åå‘ä¼ æ’­ - ä½¿ç”¨engineçš„æ–¹æ³•ï¼ˆä¸æˆåŠŸdemoå®Œå…¨ç›¸åŒï¼‰
                engine.backward(loss)
                engine.step()
                print(f"[{local_rank}] step={step} backward+step âœ…")
                
                # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œä¸æˆåŠŸdemoä¿æŒä¸€è‡´
                time.sleep(0.1)
                
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ­¥éª¤ {step} å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # è®¡ç®—è®­ç»ƒæ—¶é—´
        end_time = time.time()
        training_time = end_time - start_time
        
        print("=" * 60)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ ({training_time/3600:.2f}å°æ—¶)")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {cfg.work_dir}")
        
        # ä¿å­˜æ¨¡å‹
        if local_rank == 0:
            save_path = f"{cfg.work_dir}/final_model.pth"
            torch.save(engine.module.state_dict(), save_path)
            print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()