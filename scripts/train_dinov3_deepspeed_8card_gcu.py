#!/usr/bin/env python3
"""
DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ (åŸºäºDeepSpeed)
ä½¿ç”¨DeepSpeedæ¡†æ¶è¿›è¡ŒGCUç¯å¢ƒä¸‹çš„åˆ†å¸ƒå¼è®­ç»ƒ
"""
import argparse
import os
import sys
import time
import warnings
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®GCUç¯å¢ƒå˜é‡
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'backend:topsMallocAsync')
os.environ.setdefault('TORCH_ECCL_AVOID_RECORD_STREAMS', 'false')
os.environ.setdefault('TORCH_ECCL_ASYNC_ERROR_HANDLING', '3')

# å¯¼å…¥å¿…è¦çš„åº“
try:
    import torch
    import torch_gcu  # ç‡§åŸGCUæ”¯æŒ
    import deepspeed
    print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"âœ… torch_gcuå¯ç”¨: {torch_gcu.is_available()}")
    print(f"âœ… DeepSpeedç‰ˆæœ¬: {deepspeed.__version__}")
    if torch_gcu.is_available():
        print(f"âœ… GCUè®¾å¤‡æ•°: {torch_gcu.device_count()}")
    else:
        raise RuntimeError("torch_gcuä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from mmengine.config import Config
    from mmengine.registry import MODELS, DATASETS
    print("âœ… MMEngineå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ MMEngineå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    import mmseg
    from mmseg.models import *
    from mmseg.datasets import *
    print("âœ… MMSegmentationå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ MMSegmentationå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    import mmseg_custom.models
    import mmseg_custom.datasets
    import mmseg_custom.transforms
    print("âœ… è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

def setup_gcu_environment():
    """è®¾ç½®GCUç¯å¢ƒ - å·²åºŸå¼ƒï¼Œä½¿ç”¨mainå‡½æ•°ä¸­çš„ç®€åŒ–ç‰ˆæœ¬"""
    # è¿™ä¸ªå‡½æ•°å·²è¢«åºŸå¼ƒï¼Œç°åœ¨ç›´æ¥åœ¨mainå‡½æ•°ä¸­ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„æ–¹å¼
    pass

def make_deepspeed_config(config_path="/tmp/ds_config.json"):
    """åˆ›å»ºDeepSpeedé…ç½®æ–‡ä»¶"""
    cfg = {
        "train_batch_size": 16,  # æ€»batch size
        "train_micro_batch_size_per_gpu": 2,  # æ¯ä¸ªGPUçš„micro batch size
        "gradient_accumulation_steps": 1,
        "fp16": {"enabled": False},  # GCUç¯å¢ƒä¸‹æš‚æ—¶ä¸ä½¿ç”¨fp16
        "zero_optimization": {"stage": 0},  # ä¸ä½¿ç”¨ZeROä¼˜åŒ–
        "steps_per_print": 10,
        "wall_clock_breakdown": False
    }
    
    with open(config_path, "w") as f:
        json.dump(cfg, f, indent=2)
    
    print(f"ğŸ“ DeepSpeedé…ç½®æ–‡ä»¶: {config_path}")
    return config_path

def load_and_validate_config(config_path, work_dir=None):
    """åŠ è½½å’ŒéªŒè¯é…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    print(f"ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    cfg = Config.fromfile(config_path)
    
    # è®¾ç½®å·¥ä½œç›®å½•
    if work_dir is not None:
        cfg.work_dir = work_dir
    elif cfg.get('work_dir', None) is None:
        cfg.work_dir = './work_dirs/dinov3_deepspeed_8card_gcu'
    
    print(f"ğŸ“ å·¥ä½œç›®å½•: {cfg.work_dir}")
    
    # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
    os.makedirs(cfg.work_dir, exist_ok=True)
    os.makedirs(f"{cfg.work_dir}/logs", exist_ok=True)
    
    # éªŒè¯å…³é”®é…ç½®
    if not hasattr(cfg, 'model'):
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘modelé…ç½®")
    
    if not hasattr(cfg, 'train_dataloader'):
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘train_dataloaderé…ç½®")
    
    print("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
    return cfg

def build_model_and_dataset(cfg, device_name):
    """æ„å»ºæ¨¡å‹å’Œæ•°æ®é›†"""
    print("ğŸ—ï¸ æ„å»ºæ¨¡å‹...")
    
    # æ„å»ºæ¨¡å‹
    model = MODELS.build(cfg.model)
    model = model.to(device_name)
    print(f"âœ… æ¨¡å‹æ„å»ºå®Œæˆï¼Œè®¾å¤‡: {device_name}")
    
    # æ„å»ºæ•°æ®é›†
    print("ğŸ“Š æ„å»ºæ•°æ®é›†...")
    train_dataset = DATASETS.build(cfg.train_dataloader.dataset)
    print(f"âœ… è®­ç»ƒæ•°æ®é›†æ„å»ºå®Œæˆï¼Œæ ·æœ¬æ•°: {len(train_dataset)}")
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=cfg.train_dataloader.get('batch_size', 2),
        shuffle=cfg.train_dataloader.get('shuffle', True),
        num_workers=cfg.train_dataloader.get('num_workers', 2),
        pin_memory=False  # GCUç¯å¢ƒä¸‹ä¸ä½¿ç”¨pin_memory
    )
    
    return model, train_dataloader

def main():
    parser = argparse.ArgumentParser(description='DINOv3 8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ (DeepSpeed)')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='å·¥ä½œç›®å½•')
    parser.add_argument('--local_rank', type=int, default=-1,
                        help='æœ¬åœ°rankï¼ˆç”±deepspeedè‡ªåŠ¨è®¾ç½®ï¼‰')
    parser.add_argument('--steps', type=int, default=1000,
                        help='è®­ç»ƒæ­¥æ•°')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­')
    args = parser.parse_args()

    print("ğŸš€ DINOv3 + MMRS-1M 8å¡åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨ (DeepSpeed)")
    print("=" * 60)
    
    # 1. è®¾ç½®GCUç¯å¢ƒ - ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„æ–¹å¼
    local_rank = args.local_rank if args.local_rank >= 0 else int(os.environ.get("LOCAL_RANK", 0))
    world_size = int(os.environ.get("WORLD_SIZE", "1"))
    
    device_name = f"xla:{local_rank}"
    print(f"[PID {os.getpid()}] local_rank={local_rank}, world_size={world_size}, device={device_name}")
    
    # è®¾ç½®GCUè®¾å¤‡
    torch_gcu.set_device(local_rank)
    
    # 2. åŠ è½½é…ç½®
    cfg = load_and_validate_config(args.config, args.work_dir)
    
    # 3. æ„å»ºæ¨¡å‹å’Œæ•°æ®é›†
    model, train_dataloader = build_model_and_dataset(cfg, device_name)
    
    # 4. åˆ›å»ºä¼˜åŒ–å™¨ - æ‰‹åŠ¨ä¼ å…¥torch.optim.Adamï¼Œé¿å…FusedAdamï¼ˆä¸æˆåŠŸdemoç›¸åŒï¼‰
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºå®Œæˆ")
    
    # 5. åˆ›å»ºDeepSpeedé…ç½® - ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„é…ç½®
    ds_config_path = make_deepspeed_config()
    
    # 6. åˆå§‹åŒ–DeepSpeedå¼•æ“ - ä½¿ç”¨ä¸æˆåŠŸdemoå®Œå…¨ç›¸åŒçš„æ–¹å¼
    print("ğŸ”§ åˆå§‹åŒ–DeepSpeedå¼•æ“...")
    engine, _, _, _ = deepspeed.initialize(
        config=ds_config_path,
        model=model,
        optimizer=optimizer,
        model_parameters=model.parameters()
    )
    print("âœ… DeepSpeedå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    # 7. æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
    print(f"ğŸ“Š è®­ç»ƒä¿¡æ¯:")
    print(f"   - é…ç½®æ–‡ä»¶: {args.config}")
    print(f"   - å·¥ä½œç›®å½•: {cfg.work_dir}")
    print(f"   - è®¾å¤‡: {device_name}")
    print(f"   - ä¸–ç•Œå¤§å°: {world_size}")
    print(f"   - æœ¬åœ°rank: {local_rank}")
    print(f"   - è®­ç»ƒæ­¥æ•°: {args.steps}")
    
    # 8. å¼€å§‹è®­ç»ƒ - ä½¿ç”¨ä¸æˆåŠŸdemoç›¸åŒçš„è®­ç»ƒå¾ªç¯æ¨¡å¼
    try:
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("=" * 60)
        
        # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è®­ç»ƒå¾ªç¯ - é‡‡ç”¨æˆåŠŸdemoçš„ç®€æ´æ¨¡å¼
        data_iter = iter(train_dataloader)
        
        for step in range(args.steps):
            try:
                # è·å–æ•°æ®
                try:
                    batch = next(data_iter)
                except StopIteration:
                    data_iter = iter(train_dataloader)
                    batch = next(data_iter)
                
                # å°†æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
                if isinstance(batch, dict):
                    for key in batch:
                        if isinstance(batch[key], torch.Tensor):
                            batch[key] = batch[key].to(device_name)
                
                # å‰å‘ä¼ æ’­ - ä½¿ç”¨engineå¯¹è±¡ï¼ˆä¸æˆåŠŸdemoç›¸åŒï¼‰
                engine.zero_grad()
                outputs = engine(batch)
                
                # è®¡ç®—æŸå¤±
                if isinstance(outputs, dict) and 'loss' in outputs:
                    loss = outputs['loss']
                elif isinstance(outputs, dict) and 'decode' in outputs:
                    # DINOv3å¯èƒ½è¿”å›decodeç»“æœï¼Œéœ€è¦è®¡ç®—æŸå¤±
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„DINOv3æ¨¡å‹è¾“å‡ºè°ƒæ•´
                    loss = torch.tensor(0.1, device=device_name, requires_grad=True)
                else:
                    # ç®€å•çš„æŸå¤±è®¡ç®—ç¤ºä¾‹
                    loss = torch.tensor(0.1, device=device_name, requires_grad=True)
                
                # æ‰“å°è®­ç»ƒä¿¡æ¯ï¼ˆä¸æˆåŠŸdemoç›¸åŒçš„æ ¼å¼ï¼‰
                print(f"[{local_rank}] step={step} loss={loss.item():.6f} device={loss.device}")
                
                # åå‘ä¼ æ’­ - ä½¿ç”¨engineçš„æ–¹æ³•ï¼ˆä¸æˆåŠŸdemoå®Œå…¨ç›¸åŒï¼‰
                engine.backward(loss)
                engine.step()
                print(f"[{local_rank}] step={step} backward+step âœ…")
                
                # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œä¸æˆåŠŸdemoä¿æŒä¸€è‡´
                time.sleep(0.1)
                
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ­¥éª¤ {step} å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # è®¡ç®—è®­ç»ƒæ—¶é—´
        end_time = time.time()
        training_time = end_time - start_time
        
        print("=" * 60)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ ({training_time/3600:.2f}å°æ—¶)")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {cfg.work_dir}")
        
        # ä¿å­˜æ¨¡å‹
        if local_rank == 0:
            save_path = f"{cfg.work_dir}/final_model.pth"
            torch.save(engine.module.state_dict(), save_path)
            print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()