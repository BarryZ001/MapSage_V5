#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MapSage V4 TTAè¯„ä¼°è„šæœ¬ (v87 - ä¿®æ­£æ‹¼å†™é”™è¯¯)
æ­¤ç‰ˆæœ¬ä¿®æ­£äº†MixVisionTransformeréª¨å¹²ç½‘ç»œä¸­çš„ sr_ratios å‚æ•°æ‹¼å†™é”™è¯¯
"""

import sys
import os
import traceback
import torch
import numpy as np
import mmcv
from mmengine.config import Config
from mmengine.runner import Runner
from mmengine.registry import TRANSFORMS

# ============================== æ§åˆ¶é¢æ¿ ==============================
CHECKPOINT_PATH = '/kaggle/input/mapsage-stage02-checkpoint-6000/best_mIoU_iter_6000.pth'
# ====================================================================

# -------- è‡ªå®šä¹‰æ•°æ®è½¬æ¢ --------
@TRANSFORMS.register_module()
class UniformMaskFormat:
    def __init__(self, palette):
        self.palette = {tuple(c[::-1]): i for i, c in enumerate(palette)}
        self.ignore_index = 255
    
    def __call__(self, results):
        gt_seg_map = results.get('gt_seg_map')
        if gt_seg_map is None: 
            return results
        
        if gt_seg_map.ndim == 3 and gt_seg_map.shape[2] == 3:
            mapped_mask = np.full(gt_seg_map.shape[:2], self.ignore_index, dtype=np.uint8)
            for bgr_val, class_id in self.palette.items():
                matches = np.all(gt_seg_map == bgr_val, axis=-1)
                mapped_mask[matches] = class_id
            results['gt_seg_map'] = mapped_mask
        
        if gt_seg_map.ndim == 3 and gt_seg_map.shape[0] == 1:
            results['gt_seg_map'] = gt_seg_map.squeeze()
        
        return results

def main():
    print("\n=== âœï¸ ç”Ÿæˆ v87 é…ç½® (ä¿®æ­£æ‹¼å†™é”™è¯¯) ===")
    
    config_text = f"""
_base_ = ['mmseg::_base_/default_runtime.py']

# åŸºæœ¬é…ç½®
dataset_type = 'LoveDADataset'
data_root = '/kaggle/input/loveda'
num_classes = 7
crop_size = (1024, 1024)
palette = [[255, 255, 255], [255, 0, 0], [255, 255, 0], [0, 0, 255], [159, 129, 183], [0, 255, 0], [255, 195, 128]]

data_preprocessor = dict(
    type='SegDataPreProcessor', 
    mean=[123.675, 116.28, 103.53], 
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True, 
    pad_val=0, 
    seg_pad_val=255
)

# TTA Pipeline
tta_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(
        type='TestTimeAug',
        transforms=[
            [
                dict(type='Resize', scale_factor=r, keep_ratio=True)
                for r in [0.75, 1.0, 1.25]
            ],
            [
                dict(type='RandomFlip', prob=1.0, direction='horizontal'),
                dict(type='RandomFlip', prob=0.0, direction='horizontal')
            ],
            [dict(type='LoadAnnotations')],
            [dict(type='UniformMaskFormat', palette=palette)],
            [dict(type='PackSegInputs', meta_keys=('img_path', 'ori_shape', 'img_shape', 'pad_shape', 'scale_factor', 'flip', 'flip_direction'))]
        ])
]

# æ¨¡å‹å°è£…
model = dict(
    type='SegTTAModel',
    module=dict(
        type='EncoderDecoder',
        data_preprocessor=data_preprocessor,
        backbone=dict(
            type='MixVisionTransformer', 
            in_channels=3, 
            embed_dims=64, 
            num_stages=4,
            num_layers=[3, 4, 6, 3], 
            num_heads=[1, 2, 5, 8], 
            patch_sizes=[7, 3, 3, 3],
            # --- æ ¸å¿ƒæ”¹åŠ¨: ä¿®æ­£æ­¤å¤„çš„æ‹¼å†™é”™è¯¯ ---
            sr_ratios=[8, 4, 2, 1],
            out_indices=(0, 1, 2, 3), 
            mlp_ratio=4, 
            qkv_bias=True
        ),
        decode_head=dict(
            type='SegformerHead', 
            in_channels=[64, 128, 320, 512], 
            in_index=[0, 1, 2, 3],
            channels=256, 
            num_classes=num_classes,
            norm_cfg=dict(type='SyncBN', requires_grad=True), 
            align_corners=False
        ),
        test_cfg=dict(mode='slide', crop_size=crop_size, stride=(768, 768))
    )
)

# è¯„ä¼°æ—¶çš„æ•°æ®åŠ è½½å™¨
val_dataloader = dict(
    batch_size=1, 
    num_workers=4, 
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type, 
        data_root=data_root,
        data_prefix=dict(img_path='Val', seg_map_path='Val'),
        pipeline=tta_pipeline
    )
)
test_dataloader = val_dataloader

# è¯„ä¼°å™¨ä¸æµç¨‹é…ç½®
val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])
test_evaluator = val_evaluator
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
"""

    cfg_dir = "configs/v87"
    os.makedirs(cfg_dir, exist_ok=True)
    cfg_path = os.path.join(cfg_dir, "v87_tta_final.py")
    
    with open(cfg_path, "w") as f:
        f.write(config_text)
    print(f"âœ… é…ç½®å†™å…¥: {cfg_path}")

    print("\n=== ğŸš€ å¯åŠ¨ v87 TTAè¯„ä¼° (æœ€ç»ˆä¿®æ­£ç‰ˆ) ===")
    work_dir = "/kaggle/working/work_dirs/v87"
    
    try:
        cfg = Config.fromfile(cfg_path)
        cfg.work_dir = work_dir
        
        runner = Runner.from_cfg(cfg)
        
        print(f"--> æ­£åœ¨æ‰‹åŠ¨ä» {CHECKPOINT_PATH} åŠ è½½æƒé‡...")
        runner.load_checkpoint(CHECKPOINT_PATH)
        print("--> æƒé‡åŠ è½½æˆåŠŸï¼")

        metrics = runner.test()
        print("\n" + "="*60)
        print("ğŸ‰ v87 TTAè¯„ä¼°å®Œæˆ!")
        print(f"æœ€ç»ˆè¯„ä¼°ç»“æœ: {metrics}")
        print("="*60)

    except Exception as e:
        print(f"\nâŒ è¯„ä¼°å¤±è´¥: {e}")
        print("="*60)
        traceback.print_exc()

if __name__ == "__main__":
    main()