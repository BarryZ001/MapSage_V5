# MapSage V4 遥感分割训练优化计划

> 基于现状盘点和资源重新评估的优化训练策略  
> 目标：从当前mIoU≈0.75提升至0.90+，建立统一高效的遥感分割优化体系

---

## 📊 现状盘点总结

### **已有资源**
✅ **预训练模型**
- DINOv3-SAT493M官方权重
- EarthVQA官方权重  
- 自训练EarthVQA-15000.pth (v2.3)

✅ **数据集**
- **LoveDA (Urban + Rural, 5987张)** - 统一使用LoveDA作为主干数据集
- （EarthVQA实际上扩展自LoveDA，但本项目统一使用LoveDA）

✅ **算力资源**
- Kaggle: P100 + T4×2 (15GB/GPU)，时间充足
- Colab: A100，时长有限

### **当前问题**
❌ **DINOv3单独训练过拟合**（mIoU ≈ 0.11）
❌ **现有pipeline分散，效率不高**

---

## 🎯 新工作计划（统一LoveDA数据集策略 + 可靠性补强）

### **阶段1：基础重建与验证（2-3天）**

#### **1.1 环境清理与重置**
```bash
# 清理过拟合的DINOv3训练
# 保存最佳权重：epoch 26 (mIoU: 0.1138)
# 重置训练环境
```

#### **1.0 健康检查（一次性排雷）**
很多"过拟合/跑不动"其实是配置或评估漏项。建议先做这7项快速核查：

1. **类别/忽略索引**
   - `num_classes=7`、`ignore_index=255`（或数据标注里实际的ignore值）在**loss与metric**中保持一致
   - 如有颜色映射到类别id的步骤，确认**没有**错把调色板值当类别id

2. **评估阈值与混淆矩阵**
   - 输出`per-class IoU`，一眼看出"拖后腿的类别"（LoveDA常见：**路网/建筑/背景**）
   - 同时记录**Boundary IoU**（2-3像素膨胀的边界评估）

3. **尺度/归一化**
   - 输入归一化（mean/std）要与所用backbone预训练一致（ImageNet vs. 自定义）
   - 简单做一轮"**不增强** + 小学习率 + 过拟合小batch"的sanity check，确保loss能快速→0.x

4. **切片与标签对齐**
   - 滑窗/裁剪必须对**影像与标签**同步裁剪 + 同步几何增强（旋转/缩放/翻转等）

5. **数据划分唯一来源**
   - LoveDA**严格用官方Train/Val/Test划分**；不要把EarthVQA的同图像再放进训练（避免泄漏）

6. **评估脚本一致性**
   - 训练时与最终评测时**用同一套resize/滑窗/TTA**，避免"训练看涨、最终偏低"的错觉

7. **度量实现**
   - 确认mIoU不是"ignore_index也参与了均值"或"背景重复计数"的实现问题

> 以上7点若全部通过，训练曲线会明显更干净，mIoU不会"卡0.11"。

#### **1.2 基线模型验证**
- **目标**：建立可靠的性能基准
- **模型**：SegFormer-B2 + ImageNet预训练
- **数据集**：LoveDA (官方Train/Val/Test划分)
- **配置**：512尺寸，CE+Dice(0.7/0.3)，50 epoch，梯度裁剪max_norm=1.0
- **训练收敛优化**：
  - AdamW + cosine + warmup，梯度裁剪max_norm=1.0
  - Layer-wise LR decay：backbone 0.65，head 1.0
  - EMA权重（decay=0.999）
  - 早停机制（patience=10-15 epoch）
  - 混合精度amp=True + 梯度累积grad_accum_steps=2-4
- **预期**：mIoU ≈ 0.70-0.74
- **资源**：Kaggle T4×2

#### **1.3 EarthVQA预训练验证**
- **目标**：验证EarthVQA权重的有效性
- **模型**：SegFormer-B2 + EarthVQA预训练
- **数据集**：LoveDA
- **策略**：前50-70%层冻结，只训高层+解码头，Layer-wise LR decay
- **预期**：mIoU ≈ 0.75-0.80
- **资源**：Kaggle T4×2

### **阶段2：核心优化实验（3-4天）**

#### **2.1 多损失函数优化**
- **目标**：提升分割精度和边界质量
- **模型**：SegFormer-B2 + EarthVQA预训练
- **损失策略**：
  - Epoch 0-20: CE 0.7 + Dice 0.3
  - Epoch 20-40: CE 0.6 + Dice 0.3 + Lovász 0.1
  - 若Val mIoU < 上一里程碑，维持旧权重再训10 epoch
- **预期**：mIoU ≈ 0.78-0.82
- **资源**：Kaggle T4×2

#### **2.2 数据增强策略**
- **目标**：解决城乡尺度差异和类别不平衡
- **输入尺寸/滑窗**：
  - 训练阶段主尺寸**512→混合512/640/768**随机多尺度（短边0.5-2.0）
  - 验证/推理阶段用**滑窗1024/768** + stride=2/3重叠，减少边缘效应
- **类别重采样**：
  - 按**类别频次**做**class-aware sampling**或为少数类设置更高采样概率
  - 使用**OHEM（在线难例挖掘）**仅计算前30-40% highest loss像素的CE
- **损失组合的权重自调**：
  - 先用CE+Dice（0.7/0.3），稳定后再加Lovász（0.1-0.2）
  - 若某类IoU持续偏低，为该类单独加权（类别权重放在CE分量上更稳）
- **强增强**：
  - 几何增强：flip + rotate(±10°) + ColorJitter(0.1,0.1,0.1,0.05)
  - 小概率CutMix p=0.2（仅相同场景Urban↔Urban、Rural↔Rural）+ MixUp（α=0.2）
- **预期**：mIoU ≈ 0.80-0.84
- **资源**：Kaggle T4×2

#### **2.3 DINOv3-SAT集成实验**
- **目标**：评估DINOv3作为backbone的效果
- **架构与预训练利用策略**：
  - **主干建议顺序**：
    1. SegFormer-B2 + ImageNet（基线）
    2. SegFormer-B2 + EarthVQA预训练（同域增益，预计+2-6 mIoU）
    3. SegFormer-B4/B5（开启gradient checkpointing控显存）
    4. **DINOv3-SAT作为特征教师** → **知识蒸馏**到SegFormer
- **蒸馏策略**：先做知识蒸馏，避免直接训练过拟合
  - Teacher: DINOv3-SAT493M(冻结)
  - Student: 当前最优SegFormer
  - 损失：**feature distillation**（L2/AT）+ **logits distillation**（KL，T=2-4）
  - 相当于"用大模型做老师，小模型收敛更快更稳"
- **冻结策略**：
  - EarthVQA/DINOv3 backbone：**前50-70%层冻结**，只训高层+解码头
  - 稳定后再"逐层解冻"（每10 epoch解一层组），收敛更顺
- **预期**：mIoU ≈ 0.82-0.86
- **资源**：Kaggle P100 (更大显存)

### **阶段3：高级优化（2-3天）**

#### **3.1 滑窗推理优化与边界处理**
- **目标**：提升大图推理稳定性和边界精度
- **滑窗推理**：
  - 滑窗：tile=1024, stride=768，重叠减少边缘效应
  - 记录TTA带来的**增益占比**（> +0.8 mIoU才建议保留上线）
- **边界与后处理**（直击业务痛点）：
  - **Boundary Loss分支**：额外加一个**边界辅助头**（监督边缘/距离变换），或在损失里加**Boundary loss/SoftDice on edges**。对**道路/建筑轮廓**收益明显
  - **小目标保护**：预测连通域后，**按类别阈值过滤**（如道路最小宽度、建筑最小面积），防止碎片/噪声；也可以引入**面积自适应阈值**（Otsu/类内统计），对复杂背景更稳
- **预期**：mIoU ≈ 0.84-0.87
- **资源**：Kaggle T4×2

#### **3.2 TTA测试时增强**
- **目标**：提升推理稳定性和鲁棒性
- **技术**：TTA（scales=[0.75,1.0,1.25], flip=True）
- **策略**：在验证集做A/B，确定是否值得默认开启
- **评估与复现**（让"提升"可证、可复刻）：
  - **指标集**：`mIoU, mAcc, per-class IoU, Boundary IoU`（采用**2-3像素膨胀的边界评估**，曲线更稳定）
  - 保留**TTA开/关**两套验证；发布结果标注清楚
  - **实验表格**：列：Backbone/Pretrain/Loss/Aug/LR sched/Size/TTA/Post/mIoU/bIoU/FPS
  - **日志与追踪**：用**W&B/MLflow**记录超参与曲线；**固定随机种子**，存**完整config + 代码Commit ID**，结果可复现
- **预期**：mIoU ≈ 0.85-0.89
- **资源**：Kaggle T4×2

### **阶段4：极致精度冲刺（2-3天）**

#### **4.1 SAM边界精修**
- **目标**：提升边界IoU
- **SAM/EfficientSAM精修**（阶段4保留，但建议前置一次A/B）：
  - 选**EfficientSAM-Ti**做默认精修
  - 点提示生成：从主模型mask**边界采样正负点**（正点在内部、负点在外部3-5px）
  - 精修后做**CRF**（小步长，迭代5-10次）对比"只SAM"的收益
  - 这条链路可先在**验证集100张**上离线试一轮，测**Boundary IoU**提升幅度，确定是否全量上线
- **预期**：mIoU ≈ 0.88-0.91
- **资源**：Colab A100 (高质量推理)

#### **4.2 模型集成**
- **目标**：EarthVQA + DINOv3最优组合
- **技术**：
  - 若存在两套效果互补的权重（EarthVQA迁移 vs 蒸馏学生）
  - 做logits加权平均（0.6/0.4先行）
- **预期**：mIoU ≈ 0.90-0.93
- **资源**：Colab A100

---

## 📊 资源分配策略

### **Kaggle T4×2 (主要训练)**
- **用途**：基线训练 + 参数调优（阶段1-3）
- **优势**：时间充足、成本低
- **适合**：基础实验、快速迭代
- **资源利用与效率**：
  - `DistributedDataParallel`或`accelerate`多卡；`amp=True`；`grad_accum`=2-4
  - 训练尺寸**512/640**主力，偶尔**768**做fine-tune

### **Kaggle P100 (大模型实验)**
- **用途**：DINOv3-SAT backbone训练（阶段2.3）
- **优势**：显存更大、适合大模型
- **适合**：复杂架构实验
- **资源利用与效率**：
  - 跑**B5/DINOv3蒸馏**；开启**checkpointing**；batch小但`accum`抵消吞吐

### **Colab A100 (精度冲刺)**
- **用途**：最终冲刺（SAM + 模型集成）
- **优势**：算力最强、适合推理优化
- **适合**：高质量推理和集成
- **资源利用与效率**：
  - 用于**最终冲刺**：TTA、滑窗、SAM精修、模型融合
  - 产出**ONNX/torchscript + INT8/FP16**推理版，便于在Mac CPU做快速演示

---

## 🎯 预期成果与里程碑

### **短期目标（1周内）**
- **必须达到**：mIoU ≥ 0.80
- **理想达到**：mIoU ≥ 0.85
- **成功标准**：超越EarthVQA基准

### **中期目标（2周内）**
- **必须达到**：mIoU ≥ 0.85
- **理想达到**：mIoU ≥ 0.90
- **成功标准**：建立完整的优化体系

### **最终目标（3周内）**
- **必须达到**：mIoU ≥ 0.90
- **理想达到**：mIoU ≥ 0.93
- **成功标准**：达到遥感分割的顶级水平

---

## 🔧 关键技术策略

### **1. 避免过拟合**
- 从可靠的基线开始
- 渐进式增加模型复杂度
- 持续监控验证性能

### **2. 预训练权重策略**
- EarthVQA：主要backbone选择
- DINOv3-SAT：特征提取器实验
- 自训练模型：作为对比基准

### **3. 数据集策略**
- **LoveDA**：统一使用LoveDA作为主干数据集
- **官方划分**：使用LoveDA的Train/Val/Test标准划分
- **语义化扩展**：EarthVQA QA部分、playground类暂不使用
- **专注目标**：仅专注地物类别分割 & 边界精度

---

## 📋 极简执行序列（直接照做）

### **🧭 最终极简执行序列（可立刻落地的优化）**

1. **跑基线**：SegFormer-B2 + ImageNet；512尺寸；CE+Dice；50 epoch；看mIoU与per-class IoU
2. **换预训**：只把backbone换成EarthVQA预训；其余不变；对比增益
3. **加Lovasz**：从20 epoch开始叠Lovasz 0.1；看Val曲线是否持续上行
   - 若Val mIoU < 上一里程碑，维持旧权重再训10 epoch，而不要直接叠加Lovasz
4. **增强升级**：开多尺度 & 轻CutMix；做一次ablation
   - `scale[0.5,2.0] + flip + rotate(±10°)`，`ColorJitter(0.1,0.1,0.1,0.05)`
   - 小概率`CutMix p=0.2`（仅相同场景Urban↔Urban、Rural↔Rural）
5. **蒸馏DINOv3**：teacher=DINOv3-SAT493M（冻结），student=当前最优SegFormer；加KL + feature L2
   - 先做**蒸馏**（teacher=DINOv3-SAT，student=SegFormer-B2/B4），再考虑"DINOv3直连分割头"的对比
   - 目标是**稳定增益**而非"孤立大模型过拟合"
6. **滑窗+TTA**：在验证集做A/B，确定是否值得默认开启
   - 滑窗：`tile=1024, stride=768`；TTA：`scales=[0.75,1.0,1.25], flip=True`
   - 记录TTA带来的**增益占比**（> +0.8 mIoU才建议保留上线）
7. **SAM精修**：100张验证集离线测试，若bIoU提升>+1.0，批量纳入；否则仅在Showcase/重点区域使用
   - 选**EfficientSAM-Ti**做默认精修
   - 点提示生成：从主模型mask**边界采样正负点**（正点在内部、负点在外部3-5px）
   - 精修后做**CRF**（小步长，迭代5-10次）对比"只SAM"的收益
8. **融合**：若存在两套效果互补的权重（EarthVQA迁移 vs 蒸馏学生），做logits加权平均（0.6/0.4先行）

> **关键原则**：健康检查先行 → 渐进式优化 → 知识蒸馏策略 → 评估一致性 → 资源优化利用

---

## 🔍 实验配置模板（统一LoveDA数据集 + 可靠性补强）

### **基础配置**
```yaml
# 通用训练配置
model: SegFormer-B2
img_size: 512
batch_size: 8
optimizer: AdamW
lr: 6e-5
weight_decay: 0.01
scheduler: cosine + warmup
epochs: 100
early_stopping: True

# 可靠性补强配置
gradient_clip: 1.0
ema_decay: 0.999
amp: True
grad_accum_steps: 2-4
layer_wise_lr_decay: True
backbone_lr_mult: 0.65
head_lr_mult: 1.0
```

### **损失函数配置**
```yaml
# 多损失函数配置
loss:
  ce_weight: 0.5
  dice_weight: 0.3
  lovasz_weight: 0.2
  ignore_index: 255
```

### **数据增强配置**
```yaml
# 数据增强策略
augmentation:
  flip: True
  rotate: True
  scale_range: [0.5, 2.0]
  mixup_alpha: 0.2
  cutmix_alpha: 1.0
  class_weights: [0.1, 2.0, 1.5, 3.0, 2.5, 1.2, 1.0]

# 可靠性补强
multi_scale: [512, 640, 768]
color_jitter: [0.1, 0.1, 0.1, 0.05]
ohem_ratio: 0.3
class_aware_sampling: True
```

---

## 📈 性能监控指标（可靠性补强版）

### **主要指标**
- **mIoU**: 主要分割质量指标
- **mAcc**: 像素级准确率
- **Boundary IoU**: 边界精度指标（2-3像素膨胀的边界评估）
- **Class-wise IoU**: 各类别详细性能，识别拖后腿类别
- **混淆矩阵**: 可视化类别间错误分布

### **训练监控**
- **Train/Val Loss**: 过拟合检测
- **Learning Rate**: 学习率调度效果
- **GPU Memory**: 资源利用率
- **Training Time**: 效率评估
- **EMA权重**: 指数滑动平均效果
- **梯度范数**: 梯度裁剪效果监控

---

## 🚨 风险控制与数据集统一策略（可靠性补强版）

### **过拟合风险**
- 设置早停机制（patience=10-15 epoch）
- 监控验证性能，EMA权重平滑
- 使用正则化技术（梯度裁剪、权重衰减）
- 渐进式增加模型复杂度

### **资源风险**
- 合理分配算力资源
- 设置时间限制
- 准备备用方案

### **技术风险**
- 渐进式实验设计
- 保持基线对比
- 及时调整策略
- 固定随机种子，确保结果可复现

### **数据集统一风险**
- **避免分散**：所有实验统一使用LoveDA，结果可横向对比
- **效率提升**：避免多数据集切换，提高实验可控性
- **结果一致性**：确保所有优化实验在同一数据基础上进行

### **评估风险**
- **训练与推理一致**：使用同一套resize/滑窗/TTA
- **指标计算正确**：避免ignore_index参与mIoU计算
- **边界评估稳定**：采用2-3像素膨胀的边界IoU

---

## 📅 时间安排（可靠性补强版）

| 阶段 | 时间 | 主要任务 | 预期成果 | 关键检查点 |
|------|------|----------|----------|-------------|
| 阶段1 | 2-3天 | 基础重建与验证 | 建立可靠基线 | 健康检查7项全部通过 |
| 阶段2 | 3-4天 | 核心优化实验 | mIoU ≥ 0.80 | 损失组合稳定，数据增强有效 |
| 阶段3 | 2-3天 | 高级优化 | mIoU ≥ 0.85 | 滑窗推理稳定，TTA增益>0.8 |
| 阶段4 | 2-3天 | 极致精度冲刺 | mIoU ≥ 0.90 | SAM精修有效，模型融合成功 |

---

## 🎉 成功标准与数据集策略优势（可靠性补强版）

### **技术成功**
- 建立完整的遥感图像分割优化体系
- 达到或超越现有基准性能
- 形成可复现的实验流程
- 建立可靠的评估与监控体系

### **应用成功**
- 模型在实际场景中的稳定性
- 边界精度的显著提升
- 计算效率的优化

### **数据集统一优势**
- **实验效率**：所有实验围绕一个数据集，避免分散
- **结果可比性**：横向对比所有优化策略的效果
- **资源集中**：专注LoveDA优化，提高成功率
- **流程简化**：统一的训练和评估流程

### **可靠性补强优势**
- **健康检查**：7项关键检查点，避免基础配置错误
- **渐进式优化**：损失函数、数据增强、模型架构逐步升级
- **知识蒸馏**：避免DINOv3直接训练过拟合，稳定增益
- **评估一致性**：训练与推理使用同一套流程，避免"训练看涨、最终偏低"

---

---

## 📝 数据集统一策略总结 + 可靠性补强要点

### **为什么选择LoveDA？**
1. **标准性**：LoveDA是遥感分割的标准数据集，包含Urban+Rural场景
2. **完整性**：5987张图像，覆盖7个地物类别，数据质量高
3. **一致性**：所有实验使用同一数据集，结果可横向对比
4. **专注性**：避免分散在多模态任务上，专注分割质量提升

### **实验流程优势**
- **阶段1-2**：在LoveDA上建立基线，验证预训练权重效果
- **阶段3-4**：在LoveDA上应用高级优化技术，逐步提升精度
- **最终目标**：在LoveDA上达到mIoU ≥ 0.90，建立完整的优化体系

### **可靠性补强要点**
- **健康检查先行**：7项关键检查点，确保基础配置正确
- **渐进式优化**：损失函数、数据增强、模型架构逐步升级，避免跳跃式失败
- **知识蒸馏策略**：用DINOv3-SAT做教师，SegFormer做学生，避免直接训练过拟合
- **评估一致性**：训练与推理使用同一套流程，确保结果可靠性
- **资源优化利用**：Kaggle T4×2做基础实验，P100做大模型，Colab A100做最终冲刺

---

---

## 🔧 实验配置检查清单

### **健康检查7项（阶段1必须通过）**
- [ ] 类别/忽略索引：`num_classes=7`、`ignore_index=255`在loss与metric中一致
- [ ] 评估阈值：输出per-class IoU，识别拖后腿类别
- [ ] 尺度/归一化：输入归一化与backbone预训练一致
- [ ] 数据对齐：滑窗/裁剪必须对影像与标签同步处理
- [ ] 数据划分：严格使用LoveDA官方Train/Val/Test划分
- [ ] 评估一致性：训练与最终评测使用同一套resize/滑窗/TTA
- [ ] 度量实现：确认mIoU计算正确，避免ignore_index参与均值

### **实验配置检查**
- [ ] 梯度裁剪：`max_norm=1.0`
- [ ] EMA：`decay=0.999`
- [ ] 混合精度：`amp=True`
- [ ] 梯度累积：`grad_accum_steps=2-4`
- [ ] Layer-wise LR：backbone 0.65，head 1.0
- [ ] 早停：`patience=10-15 epoch`

---

*本计划基于当前资源状况制定，将根据实验进展动态调整*
*数据集策略：统一使用LoveDA，专注分割质量提升*
*可靠性补强：健康检查先行，渐进式优化，知识蒸馏策略*
*最后更新：2025年1月*