好的，这是一台性能非常强大的AI训练服务器。拥有8张邃思T20（Enflame T20）加速卡，总计FP16算力高达1 PFLOPS，并且单卡显存达到32GB，这彻底改变了原先基于Kaggle/Colab资源限制的训练策略。

原有的计划非常严谨和科学，其核心的渐进式优化思想、可靠性补强措施（如健康检查）和对评估一致性的强调都应保留。我们要做的是基于新服务器的强大算力，**将原计划从“资源受限的串行优化”升级为“高吞吐的并行实验与更大胆的参数设置”**。

以下是根据新服务器规格重新制定的MapSage V4训练优化计划。

---

## MapSage V4 训练优化计划 (基于燧原AI一体机)

> **核心战略转变：** 从资源节约、串行迭代转变为**并行探索、高参训练、快速收敛**。利用强大的单机多卡能力，大幅压缩实验周期，直接挑战更高性能上限。

### **0. 前置准备：环境搭建与健康检查 (1天)**

在开始任何训练之前，必须确保新服务器的环境配置无误。

1.  **驱动与框架安装**：
    * 安装燧原AI加速卡的驱动和软件栈。
    * 配置支持邃思T20的深度学习框架（如PyTorch），确保多卡通信（类似NCCL的功能）正常工作。
    * 验证`torch.distributed.launch`或`deepspeed`等多卡启动器能够正确调用8张卡。

2.  **数据与代码迁移**：
    * 将LoveDA数据集拷贝至服务器的3.84T NVMe数据盘，确保高速I/O。
    * 部署项目代码，并准备好所有预训练模型（DINOv3, EarthVQA等）。

3.  **执行健康检查（保留原计划精髓）**：
    * 在正式开始前，严格执行原计划中的**7项健康检查**。在强大的硬件上，一个微小的配置错误（如`ignore_index`设置错误）会导致巨大的算力浪费。
    * 进行一次**单卡小批量过拟合测试**（Sanity Check），确保loss可以快速下降，验证数据加载和模型基础逻辑的正确性。

### **阶段1：并行基线与大模型探索 (2-3天)**

得益于8张GPU，我们可以并行运行多个实验，而不是像原计划那样依次进行。这会极大地缩短探索周期。

**目标**：在第一阶段就确定最有潜力的Backbone和预训练策略。

**并行实验轨道 (建议每组实验使用2-4张T20卡):**

* **轨道A: SegFormer-B5 + EarthVQA (高分辨率基线)**
    * **模型**: 直接使用SegFormer-B5，而不是B2。32GB显存完全足够。
    * **预训练**: 使用EarthVQA权重。
    * **输入尺寸**: **直接从`768×768`开始**，而不是512。高分辨率能更好地捕捉遥感影像的细节。
    * **批量大小 (Batch Size)**: 大幅增加。例如，**单卡batch size设置为8-16**，总batch size可达64-128。这将获得更稳定的梯度，可能不再需要梯度累积。
    * **预期**: 快速达到`mIoU ≈ 0.80+`。

* **轨道B: DINOv3-SAT 直接微调 (大模型能力验证)**
    * **策略**: 放弃原计划中复杂的知识蒸馏，**直接尝试端到端微调DINOv3-SAT** + 分割头。32GB显存为这一极具挑战性的任务提供了可能。
    * **优化器**: 使用AdamW，但为Backbone设置一个非常小的学习率（Layer-wise LR decay），例如`backbone_lr_mult=0.1`或更低。
    * **冻结策略**: 初期可以冻结前70-80%的层，仅微调高层和分割头，观察收敛情况后，再逐步解冻。
    * **预期**: 如果成功，这可能是性能上限最高的路线，但也伴随着过拟合风险。

* **轨道C: SegFormer-B2 + ImageNet (快速参照基线)**
    * **目的**: 保留一个与原计划可对比的参照系。
    * **配置**: 与轨道A类似，使用`768×768`尺寸和大batch size。
    * **预期**: 作为参照，验证EarthVQA预训练和大模型带来的实际增益。

**此阶段产出**: 获得三个主要方向的性能数据，明确SegFormer-B5+EarthVQA 和 DINOv3微调哪条路走得更稳、潜力更高。

### **阶段2：高级优化策略融合 (2-3天)**

从阶段1中选择表现最佳的模型（大概率是轨道A或B的产物）作为新的基线，进行集中优化。强大的算力允许我们同时融合多种优化手段。

1.  **损失函数与数据增强“全家桶”**:
    * **损失函数**: 直接应用**CE + Dice + Lovász**的组合策略。无需像原计划那样分阶段引入，服务器性能足以支撑复杂的损失计算。
    * **数据增强**: 从一开始就启用**强数据增强策略**。
        * **多尺度训练**: `[512, 640, 768, 1024]`随机尺寸裁剪。
        * **几何与色彩**: `flip`, `rotate(±15°)`, `ColorJitter`等。
        * **混合类增强**: `CutMix` 和 `MixUp`可以更积极地使用。
    * **难例挖掘**: OHEM或类别感知采样（Class-aware sampling）可以作为标配加入训练流程。

2.  **边界质量专项优化**:
    * 直接在模型中加入**边界辅助头 (Boundary Head)** 或使用 **Boundary Loss**。这对道路、建筑等类别的IoU提升至关重要，强大的算力可以轻松应对这种多任务学习架构。

3.  **知识蒸馏 (备选方案)**:
    * 如果在阶段1中发现DINOv3直接微调不稳定，此时可以启动**知识蒸馏**方案。
    * Teacher: DINOv3-SAT (冻结)
    * Student: 阶段1中表现最好的SegFormer-B5模型。
    * 由于服务器性能强劲，蒸馏过程会非常快。

**此阶段产出**: 一个融合了多种优化技巧的强大模型，预期`mIoU`冲击`0.88+`。

### **阶段3：推理优化与精度冲刺 (1-2天)**

强大的GPU同样是推理的利器，可以快速验证TTA、滑窗和SAM等耗时操作的效果。

1.  **滑窗推理与TTA (Test-Time Augmentation)**:
    * **滑窗**: 使用更大的瓦片尺寸（如`1024×1024`）和更高的重叠率（如`stride=512`），以获得更精细的拼接结果。
    * **TTA**: 并行测试多种增强策略（如多尺度`[0.75, 1.0, 1.25, 1.5]` + 翻转），8张卡可以同时处理不同TTA配置的推理任务，快速找到最佳组合。

2.  **SAM/EfficientSAM 边界精修**:
    * 利用A100级别的算力，可以对**全量验证集**进行SAM精修测试，而不仅仅是抽样100张。
    * 可以尝试更复杂的提示工程（例如，不仅在边界采样点，还可以结合边缘检测算法生成的区域作为提示）。

3.  **模型集成 (Ensemble)**:
    * 如果阶段1的轨道A和轨道B都取得了不错的成果，可以直接对它们的logits进行加权平均，这是最有效的上分手段之一。强大的CPU和内存确保后处理过程无瓶颈。

**此阶段产出**: 达到项目最终目标的模型，预期`mIoU`达到`0.90+`。

### **新旧计划关键策略对比**

| 策略项 | 原计划 (Kaggle/Colab) | 新计划 (燧原服务器) | 理由 |
| :--- | :--- | :--- | :--- |
| **工作流** | 串行、渐进 | **并行、高举高打** | 8张GPU可同时进行多组实验，大幅缩短周期。 |
| **基础模型** | SegFormer-B2 | **SegFormer-B5 / DINOv3-SAT直调** | 32GB显存不再是瓶颈，可以直接上大模型。 |
| **输入尺寸** | 512px 起步, 谨慎放大 | **768px / 1024px 起步** | 大显存支持高分辨率输入，对遥感任务提升显著。 |
| **批量大小** | 8 (可能需梯度累积) | **64 - 128+ (无需累积)** | 稳定梯度，加速收敛，充分利用硬件性能。 |
| **DINOv3策略** | 知识蒸馏为主 | **直接微调为主，蒸馏为备选** | 风险与收益并存，但强大的硬件值得尝试更高上限的方案。 |
| **优化策略** | 分阶段添加 (损失、增强) | **一步到位，直接集成** | 算力充裕，可直接训练更复杂的模型和损失组合。 |
| **实验周期** | 2-3 周 | **1 - 1.5 周** | 并行化和更快的单次训练速度压缩了总体时间。 |

### **极简执行序列（新版）**

1.  **环境日 (Day 1)**: 配置服务器，完成代码数据迁移和**7项健康检查**。
2.  **并行探索 (Day 2-4)**:
    * **实验组1 (4卡)**: 跑 **SegFormer-B5 + EarthVQA**，`768px`，大batch。
    * **实验组2 (4卡)**: 跑 **DINOv3-SAT直接微调**，`768px`，小学习率，监控过拟合。
3.  **择优融合 (Day 5-7)**:
    * 选择上一阶段的**冠军模型**。
    * 在其基础上，加入**Lovász损失、边界头、强数据增强**进行深度训练。
4.  **冲刺验证 (Day 8-9)**:
    * 对最优模型进行**滑窗+TTA**推理，评估最终性能。
    * (可选) 对全量验证集运行**SAM精修**，评估边界提升效果。
    * (可选) **集成**两个最佳模型，做最后冲刺。

**结论**：新服务器是项目的“超级加速器”。我们应保留原计划科学的实验思想和严谨的评估体系，但要彻底抛弃资源限制带来的“束缚”，通过**并行化、大模型、大参数**的策略，更快、更好地达成`mIoU > 0.90`的目标。