import os
import sys
import traceback
import numpy as np
from PIL import Image

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.getcwd())

# æ¡ä»¶å¯¼å…¥å¤„ç†
try:
    import streamlit as st  # type: ignore
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False
    print("Streamlitæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install streamlit")
    sys.exit(1)

try:
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
    F = None

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

# å°è¯•å¯¼å…¥MMSegmentation
try:
    from mmseg.apis import init_segmentor, inference_segmentor  # type: ignore
    # register_all_moduleså‡½æ•°åœ¨è¾ƒæ–°ç‰ˆæœ¬ä¸­å¯èƒ½ä¸å­˜åœ¨
    try:
        from mmseg.utils import register_all_modules
    except ImportError:
        register_all_modules = None
    MMSEG_AVAILABLE = True
    MMSEG_ERROR = None
    # æ³¨å†Œæ‰€æœ‰æ¨¡å—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if register_all_modules is not None:
        register_all_modules()
except (ImportError, ModuleNotFoundError) as e:
    MMSEG_AVAILABLE = False
    MMSEG_ERROR = str(e)
    print(f"MMSegmentationå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·æ­£ç¡®å®‰è£…MMSegmentationåŠå…¶ä¾èµ–")
    sys.exit(1)

# --- é…ç½® ---
# è¯·å°†è¿™é‡Œçš„è·¯å¾„ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„æ–‡ä»¶è·¯å¾„
CONFIG_FILE = 'final_standalone_config.py'
CHECKPOINT_FILE = 'checkpoints/best_mIoU_iter_6000.pth'
DEVICE = 'cpu'

# LoveDAæ•°æ®é›†çš„è°ƒè‰²æ¿ (RGBæ ¼å¼)
# 7ä¸ªç±»åˆ«ï¼šèƒŒæ™¯ã€å»ºç­‘ã€é“è·¯ã€æ°´ä½“ã€è´«ç˜ åœŸåœ°ã€æ£®æ—ã€å†œä¸š
PALETTE = [
    [255, 255, 255],  # èƒŒæ™¯ - ç™½è‰²
    [255, 0, 0],      # å»ºç­‘ - çº¢è‰²
    [255, 255, 0],    # é“è·¯ - é»„è‰²
    [0, 0, 255],      # æ°´ä½“ - è“è‰²
    [159, 129, 183],  # è´«ç˜ åœŸåœ° - ç´«è‰²
    [0, 255, 0],      # æ£®æ— - ç»¿è‰²
    [255, 195, 128]   # å†œä¸š - æ©™è‰²
]

CLASS_NAMES = ['èƒŒæ™¯', 'å»ºç­‘', 'é“è·¯', 'æ°´ä½“', 'è´«ç˜ åœŸåœ°', 'æ£®æ—', 'å†œä¸š']

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def get_mask_path(uploaded_filename):
    """
    æ ¹æ®ä¸Šä¼ çš„æ–‡ä»¶åï¼ŒæŸ¥æ‰¾å¯¹åº”çš„éªŒè¯é›†æ©ç æ–‡ä»¶
    """
    if uploaded_filename is None:
        return None
    
    # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    base_name = os.path.splitext(uploaded_filename)[0]
    
    # æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•ä¸‹æ˜¯å¦æœ‰å¯¹åº”çš„æ©ç æ–‡ä»¶
    mask_filename = f"{base_name}_mask.png"
    mask_path = os.path.join(os.getcwd(), mask_filename)
    
    if os.path.exists(mask_path):
        return mask_path
    
    return None

@st.cache_resource
def load_model(config, checkpoint):
    """
    ä½¿ç”¨MMSegmentationåŠ è½½SegFormeræ¨¡å‹ã€‚
    """
    if not MMSEG_AVAILABLE:
        st.error("âŒ MMSegmentationæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
        return None
    
    if not os.path.exists(checkpoint):
        st.error(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint}")
        return None
        
    if not os.path.exists(config):
        st.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config}")
        return None
    
    try:
        # æ£€æŸ¥torchæ˜¯å¦å¯ç”¨
        if not TORCH_AVAILABLE or torch is None:
            st.error("âŒ PyTorchæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
            return None
            
        # å…ˆåŠ è½½checkpointæ£€æŸ¥æ˜¯å¦åŒ…å«CLASSESå…ƒæ•°æ®
        checkpoint_data = torch.load(checkpoint, map_location='cpu')
        
        # ç¡®ä¿checkpointåŒ…å«å¿…è¦çš„metaä¿¡æ¯
        if 'meta' not in checkpoint_data:
            checkpoint_data['meta'] = {}
        
        # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„å…ƒæ•°æ®
        needs_temp_file = False
        
        # å¦‚æœç¼ºå°‘CLASSESï¼Œæ·»åŠ é»˜è®¤çš„ç±»åˆ«ä¿¡æ¯
        if 'CLASSES' not in checkpoint_data['meta']:
            checkpoint_data['meta']['CLASSES'] = ['èƒŒæ™¯', 'å»ºç­‘', 'é“è·¯', 'æ°´ä½“', 'è´«ç˜ åœŸåœ°', 'æ£®æ—', 'å†œä¸š']
            needs_temp_file = True
            
        # å¦‚æœç¼ºå°‘PALETTEï¼Œæ·»åŠ é»˜è®¤çš„è°ƒè‰²æ¿ä¿¡æ¯
        if 'PALETTE' not in checkpoint_data['meta']:
            checkpoint_data['meta']['PALETTE'] = [
                [255, 255, 255],  # èƒŒæ™¯ - ç™½è‰²
                [255, 0, 0],      # å»ºç­‘ - çº¢è‰²
                [255, 255, 0],    # é“è·¯ - é»„è‰²
                [0, 0, 255],      # æ°´ä½“ - è“è‰²
                [159, 129, 183],  # è´«ç˜ åœŸåœ° - ç´«è‰²
                [0, 255, 0],      # æ£®æ— - ç»¿è‰²
                [255, 195, 128]   # å†œä¸š - æ©™è‰²
            ]
            needs_temp_file = True
            
        # å¦‚æœéœ€è¦ï¼Œåˆ›å»ºä¸´æ—¶æ–‡ä»¶
        if needs_temp_file:
            temp_checkpoint = checkpoint + '.temp'
            torch.save(checkpoint_data, temp_checkpoint)
            checkpoint_to_use = temp_checkpoint
        else:
            checkpoint_to_use = checkpoint
        
        # ä½¿ç”¨MMSegmentation APIåŠ è½½æ¨¡å‹
        if init_segmentor is not None:
            model = init_segmentor(config, checkpoint_to_use, device=DEVICE)
            
            # === ADD THIS DEBUG LINE ===
            print("\n--- Verifying Loaded Config Keys ---")
            print(list(model.cfg.keys()))
            print("------------------------------------\n")
            # ===========================
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if checkpoint_to_use != checkpoint and os.path.exists(checkpoint_to_use):
                os.remove(checkpoint_to_use)
            
            # æ‰‹åŠ¨è®¾ç½®CLASSESå±æ€§ï¼ˆåŒé‡ä¿é™©ï¼‰
            if not hasattr(model, 'CLASSES') or model.CLASSES is None:
                model.CLASSES = ['èƒŒæ™¯', 'å»ºç­‘', 'é“è·¯', 'æ°´ä½“', 'è´«ç˜ åœŸåœ°', 'æ£®æ—', 'å†œä¸š']
            
            st.success("âœ… SegFormeræ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
        else:
            st.error("âŒ init_segmentorå‡½æ•°ä¸å¯ç”¨")
            return None
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None

def run_inference(model, image_np):
    """
    ç»ˆæç®€åŒ–ç‰ˆæ¨ç†å‡½æ•°ï¼Œç”¨äºå…¼å®¹æ—§ç‰ˆ MMSegmentation v0.xã€‚
    æ­¤å‡½æ•°æ‰‹åŠ¨è¿›è¡Œæ‰€æœ‰å¿…è¦çš„æ•°æ®å‡†å¤‡ï¼Œä¸å†ä¾èµ–å¤æ‚çš„ mmcv æˆ– mmseg æ•°æ®æµã€‚
    """
    if model is None:
        st.error("âŒ æ¨¡å‹æœªåŠ è½½")
        return None
    
    try:
        import torch
        cfg = model.cfg
        device = next(model.parameters()).device

        # 1. æ‰‹åŠ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†
        # ä»é…ç½®æ–‡ä»¶çš„test pipelineä¸­è·å–å‡å€¼å’Œæ ‡å‡†å·®
        normalize_cfg = None
        for transform in cfg.data.test.pipeline:
            if transform['type'] == 'Normalize':
                normalize_cfg = transform
                break
        
        if normalize_cfg is None:
            # ä½¿ç”¨é»˜è®¤çš„ImageNetå½’ä¸€åŒ–å‚æ•°
            mean = np.array([123.675, 116.28, 103.53], dtype=np.float32)
            std = np.array([58.395, 57.12, 57.375], dtype=np.float32)
        else:
            mean = np.array(normalize_cfg['mean'], dtype=np.float32)
            std = np.array(normalize_cfg['std'], dtype=np.float32)
        
        # å½’ä¸€åŒ–
        image_normalized = (image_np.astype(np.float32) - mean) / std
        
        # HWC -> CHW (é«˜, å®½, é€šé“ -> é€šé“, é«˜, å®½)
        image_transposed = image_normalized.transpose(2, 0, 1)
        
        # è½¬æ¢ä¸ºPyTorch Tensorå¹¶å¢åŠ ä¸€ä¸ªBatchç»´åº¦ (B, C, H, W)
        image_tensor = torch.from_numpy(image_transposed).unsqueeze(0).to(device)

        # 2. æ‰‹åŠ¨åˆ›å»ºæœ€ç®€åŒ–çš„å…ƒæ•°æ® (img_metas)
        # æ¨¡å‹åœ¨æ¨ç†æ—¶éœ€è¦è¿™äº›ä¿¡æ¯æ¥æ­£ç¡®ç¼©æ”¾ç»“æœ
        meta_dict = {
            'ori_shape': image_np.shape,
            'img_shape': image_np.shape,
            'pad_shape': image_np.shape,
            'scale_factor': 1.0,
            'flip': False,  # ç¡®ä¿'flip'é”®å­˜åœ¨
            'flip_direction': None
        }

        # 3. ä»¥æ¨¡å‹æœŸæœ›çš„åˆ—è¡¨æ ¼å¼è¿›è¡Œè°ƒç”¨
        # è¿™æ˜¯è§£å†³ 'imgs must be a list' å’Œ 'KeyError: flip' çš„æ ¸å¿ƒ
        with torch.no_grad():
            result = model(
                img=[image_tensor],
                img_metas=[[meta_dict]], # æ³¨æ„è¿™é‡Œæ˜¯åŒé‡åˆ—è¡¨
                return_loss=False
            )
        
        # 4. è¿”å›ç»“æœ
        # æ¨¡å‹åœ¨æ¨ç†æ¨¡å¼ä¸‹è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«æ¯ä¸ªå›¾åƒçš„åˆ†å‰²å›¾
        return result[0]

    except Exception as e:
        st.error(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None

def draw_segmentation_map(seg_map, palette):
    """
    å°†å•é€šé“çš„ç±»åˆ«ç´¢å¼•å›¾è½¬æ¢ä¸ºå½©è‰²çš„å¯è§†åŒ–åˆ†å‰²å›¾ã€‚
    """
    color_seg = np.zeros((seg_map.shape[0], seg_map.shape[1], 3), dtype=np.uint8)
    for label, color in enumerate(palette):
        color_seg[seg_map == label, :] = color
    return color_seg

def calculate_class_statistics(seg_map, class_names):
    """
    è®¡ç®—å„ç±»åˆ«çš„åƒç´ ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    unique, counts = np.unique(seg_map, return_counts=True)
    total_pixels = seg_map.size
    
    stats = {}
    for i, class_name in enumerate(class_names):
        if i in unique:
            pixel_count = counts[unique == i][0]
            percentage = (pixel_count / total_pixels) * 100
            stats[class_name] = {'pixels': pixel_count, 'percentage': percentage}
        else:
            stats[class_name] = {'pixels': 0, 'percentage': 0.0}
    
    return stats

# --- Streamlit é¡µé¢å¸ƒå±€ ---

st.set_page_config(layout="wide", page_title="MapSage V4 - é¥æ„Ÿå½±åƒåˆ†å‰²")

st.title("ğŸ›°ï¸ MapSage V4 æ¨¡å‹æ•ˆæœéªŒè¯")
st.markdown("ä¸Šä¼ ä¸€å¼ é¥æ„Ÿå½±åƒï¼ŒæŸ¥çœ‹mIoUä¸º **84.96** çš„æ¨¡å‹åˆ†å‰²æ•ˆæœã€‚")

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
config_exists = os.path.exists(CONFIG_FILE)
checkpoint_exists = os.path.exists(CHECKPOINT_FILE)

if not config_exists or not checkpoint_exists:
    st.error("âš ï¸ ç¼ºå°‘å¿…è¦æ–‡ä»¶:")
    if not config_exists:
        st.error(f"- é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
    if not checkpoint_exists:
        st.error(f"- æƒé‡æ–‡ä»¶: {CHECKPOINT_FILE}")
    st.info("è¯·æŒ‰ç…§READMEä¸­çš„è¯´æ˜å‡†å¤‡è¿™äº›æ–‡ä»¶ã€‚")
else:
    st.success("âœ… æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡")

if MMSEG_AVAILABLE and config_exists and checkpoint_exists:
    st.info("âš ï¸ **æ³¨æ„**: ç”±äºåœ¨CPUä¸Šè¿›è¡Œæ»‘çª—æ¨ç†ï¼Œå¤„ç†ä¸€å¼ å›¾ç‰‡å¯èƒ½éœ€è¦1-3åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“Š å›¾ä¾‹")
    for i, (name, color) in enumerate(zip(CLASS_NAMES, PALETTE)):
        color_hex = f"#{color[0]:02x}{color[1]:02x}{color[2]:02x}"
        st.markdown(f"<div style='display: flex; align-items: center; margin-bottom: 5px;'>" 
                    f"<div style='width: 20px; height: 20px; background-color: {color_hex}; margin-right: 10px; border: 1px solid #000;'></div>"
                    f"<span>{name}</span></div>", unsafe_allow_html=True)
    
    st.markdown("---")
    st.header("â„¹ï¸ å…³äº")
    st.write("æ­¤åº”ç”¨ç”¨äºå¿«é€ŸéªŒè¯åœ¨LoveDAæ•°æ®é›†ä¸Šè®­ç»ƒçš„é¥æ„Ÿåˆ†å‰²æ¨¡å‹çš„æ•ˆæœã€‚")
    st.write(f"**æ¨¡å‹æ€§èƒ½**: mIoU = 84.96")
    st.write(f"**æ¨ç†è®¾å¤‡**: {DEVICE.upper()}")
    
    if MMSEG_AVAILABLE:
        st.success("âœ… MMSegmentationå·²åŠ è½½")
    else:
        st.error("âŒ MMSegmentationæœªå®‰è£…")
        if 'MMSEG_ERROR' in globals():
            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                st.code(MMSEG_ERROR, language="text")

# --- ä¸»é¡µé¢ ---
uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ å›¾ç‰‡è¿›è¡Œåˆ†å‰²...", type=["jpg", "jpeg", "png", "tif", "tiff"])

if uploaded_file is not None and MMSEG_AVAILABLE and config_exists and checkpoint_exists:
    # 1. åŠ è½½å›¾ç‰‡
    try:
        image = Image.open(uploaded_file).convert("RGB")
        image_np = np.array(image)
        
        st.success(f"âœ… å›¾ç‰‡åŠ è½½æˆåŠŸï¼Œå°ºå¯¸: {image.size[0]} x {image.size[1]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„éªŒè¯é›†æ©ç æ–‡ä»¶
        mask_path = get_mask_path(uploaded_file.name)
        
        if mask_path:
            # ä¸‰è¡Œæ˜¾ç¤ºï¼šåŸå›¾ã€éªŒè¯é›†æ©ç ã€æ¨¡å‹åˆ†å‰²ç»“æœ
            st.subheader("ğŸ“· ç¬¬ä¸€è¡Œï¼šåŸå§‹å½±åƒ")
            st.image(image, use_container_width=True)
            st.write(f"å›¾ç‰‡å°ºå¯¸: {image.size[0]} x {image.size[1]} åƒç´ ")
            
            # æ˜¾ç¤ºéªŒè¯é›†æ©ç 
            st.subheader("ğŸ¯ ç¬¬äºŒè¡Œï¼šéªŒè¯é›†æ©ç å›¾")
            try:
                mask_image = Image.open(mask_path)
                # å°†æ©ç å›¾è½¬æ¢ä¸ºå½©è‰²æ˜¾ç¤º
                mask_np = np.array(mask_image)
                if len(mask_np.shape) == 2:  # å¦‚æœæ˜¯å•é€šé“æ©ç 
                    mask_colored = draw_segmentation_map(mask_np, PALETTE)
                    st.image(mask_colored, use_container_width=True, caption="éªŒè¯é›†çœŸå®æ ‡ç­¾")
                else:
                    st.image(mask_image, use_container_width=True, caption="éªŒè¯é›†çœŸå®æ ‡ç­¾")
            except Exception as e:
                st.error(f"æ— æ³•åŠ è½½æ©ç æ–‡ä»¶: {str(e)}")
            
            st.subheader("ğŸ¤– ç¬¬ä¸‰è¡Œï¼šæ¨¡å‹åˆ†å‰²ç»“æœ")
            
            # 3. åŠ è½½æ¨¡å‹å¹¶æ¨ç†
            with st.spinner('ğŸ”„ æ¨¡å‹åŠ è½½ä¸­... (é¦–æ¬¡è¿è¡Œè¾ƒæ…¢)'):
                model = load_model(CONFIG_FILE, CHECKPOINT_FILE)
            
            if model is not None:
                with st.spinner('âš™ï¸ CPUæ­£åœ¨è¿›è¡Œæ»‘çª—æ¨ç†ï¼Œè¯·ç¨å€™...'):
                    segmentation_map = run_inference(model, image_np)
                
                if segmentation_map is not None:
                    color_result_map = draw_segmentation_map(segmentation_map, PALETTE)
                    st.image(color_result_map, use_container_width=True, caption="æ¨¡å‹åˆ†å‰²ç»“æœ")
                    
                    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
                    with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"):
                        st.write(f"è¾“å‡º `segmentation_map` çš„å½¢çŠ¶: {segmentation_map.shape}")
                        st.write(f"æ•°æ®ç±»å‹: {segmentation_map.dtype}")
                        st.write(f"æœ€å°å€¼: {np.min(segmentation_map)}")
                        st.write(f"æœ€å¤§å€¼: {np.max(segmentation_map)}")
                        unique_values = np.unique(segmentation_map)
                        st.write(f"åŒ…å«çš„å”¯ä¸€å€¼ (å‰20ä¸ª): {unique_values[:20]}")
                        st.write(f"å”¯ä¸€å€¼æ€»æ•°: {len(unique_values)}")
                    
                    # æ˜¾ç¤ºç±»åˆ«ç»Ÿè®¡
                    st.subheader("ğŸ“ˆ ç±»åˆ«ç»Ÿè®¡")
                    stats = calculate_class_statistics(segmentation_map, CLASS_NAMES)
                    
                    # è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼
                    stats_data = []
                    for class_name, stat in stats.items():
                        stats_data.append({
                            'ç±»åˆ«': class_name,
                            'åƒç´ æ•°': f"{stat['pixels']:,}",
                            'å æ¯”': f"{stat['percentage']:.2f}%"
                        })
                    
                    st.table(stats_data)
                    
                    # æä¾›ä¸‹è½½åŠŸèƒ½
                    st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ")
                    
                    # è½¬æ¢ä¸ºPILå›¾åƒä»¥ä¾¿ä¸‹è½½
                    result_pil = Image.fromarray(color_result_map)
                    
                    # åˆ›å»ºä¸‹è½½æŒ‰é’®
                    import io
                    img_buffer = io.BytesIO()
                    result_pil.save(img_buffer, format='PNG')
                    img_buffer.seek(0)
                    
                    # å®‰å…¨åœ°å¤„ç†æ–‡ä»¶åï¼Œé¿å…tuple index out of rangeé”™è¯¯
                    filename_parts = uploaded_file.name.split('.')
                    base_filename = filename_parts[0] if len(filename_parts) > 0 else "image"
                    
                    st.download_button(
                        label="ä¸‹è½½åˆ†å‰²ç»“æœ",
                        data=img_buffer.getvalue(),
                        file_name=f"segmentation_result_{base_filename}.png",
                        mime="image/png"
                    )
                    
                    st.success("ğŸ‰ åˆ†å‰²å®Œæˆï¼")
            else:
                st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        else:
            # åŸæ¥çš„ä¸¤åˆ—æ˜¾ç¤ºæ–¹å¼
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ“· åŸå§‹å½±åƒ")
                st.image(image, use_container_width=True)
                st.write(f"å›¾ç‰‡å°ºå¯¸: {image.size[0]} x {image.size[1]} åƒç´ ")

            with col2:
                st.subheader("ğŸ¯ æ¨¡å‹åˆ†å‰²ç»“æœ")
                
                # 3. åŠ è½½æ¨¡å‹å¹¶æ¨ç†
                with st.spinner('ğŸ”„ æ¨¡å‹åŠ è½½ä¸­... (é¦–æ¬¡è¿è¡Œè¾ƒæ…¢)'):
                    model = load_model(CONFIG_FILE, CHECKPOINT_FILE)
                
                if model is not None:
                    with st.spinner('âš™ï¸ CPUæ­£åœ¨è¿›è¡Œæ»‘çª—æ¨ç†ï¼Œè¯·ç¨å€™...'):
                        segmentation_map = run_inference(model, image_np)
                    
                    if segmentation_map is not None:
                        color_result_map = draw_segmentation_map(segmentation_map, PALETTE)
                        st.image(color_result_map, use_container_width=True, caption="æ¨¡å‹åˆ†å‰²ç»“æœ")
                        
                        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
                        with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"):
                            st.write(f"è¾“å‡º `segmentation_map` çš„å½¢çŠ¶: {segmentation_map.shape}")
                            st.write(f"æ•°æ®ç±»å‹: {segmentation_map.dtype}")
                            st.write(f"æœ€å°å€¼: {np.min(segmentation_map)}")
                            st.write(f"æœ€å¤§å€¼: {np.max(segmentation_map)}")
                            unique_values = np.unique(segmentation_map)
                            st.write(f"åŒ…å«çš„å”¯ä¸€å€¼ (å‰20ä¸ª): {unique_values[:20]}")
                            st.write(f"å”¯ä¸€å€¼æ€»æ•°: {len(unique_values)}")
                else:
                    st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
    
    except Exception as e:
        st.error(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")

elif uploaded_file is not None:
    st.warning("è¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–å¹¶å‡†å¤‡æ¨¡å‹æ–‡ä»¶ã€‚")

# --- é¡µé¢åº•éƒ¨ä¿¡æ¯ ---
st.markdown("---")
st.markdown("""
### ğŸ”§ ä½¿ç”¨è¯´æ˜
1. **å‡†å¤‡æ–‡ä»¶**: å°†æ¨¡å‹æƒé‡æ–‡ä»¶æ”¾åœ¨ `checkpoints/` ç›®å½•ä¸‹ï¼Œé…ç½®æ–‡ä»¶æ”¾åœ¨ `configs/` ç›®å½•ä¸‹
2. **ä¸Šä¼ å›¾ç‰‡**: æ”¯æŒ JPGã€PNGã€TIF ç­‰æ ¼å¼çš„é¥æ„Ÿå½±åƒ
3. **ç­‰å¾…å¤„ç†**: CPUæ¨ç†éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
4. **æŸ¥çœ‹ç»“æœ**: åˆ†å‰²ç»“æœä¼šæ˜¾ç¤ºåœ¨å³ä¾§ï¼ŒåŒ…å«ç±»åˆ«ç»Ÿè®¡ä¿¡æ¯
5. **ä¸‹è½½ç»“æœ**: å¯ä»¥ä¸‹è½½å½©è‰²åˆ†å‰²å›¾ç”¨äºè¿›ä¸€æ­¥åˆ†æ

### âš¡ æ€§èƒ½è¯´æ˜
- **æ¨ç†æ—¶é—´**: 1-3åˆ†é’Ÿï¼ˆå–å†³äºå›¾ç‰‡å¤§å°ï¼‰
- **å†…å­˜éœ€æ±‚**: å»ºè®®16GBä»¥ä¸Š
- **æ”¯æŒæ ¼å¼**: JPG, PNG, TIF, TIFF
- **æœ€å¤§å°ºå¯¸**: å»ºè®®ä¸è¶…è¿‡2048x2048åƒç´ 
""")