# DistributedDataParallelè®¾å¤‡ä¸åŒ¹é…é—®é¢˜ä¿®å¤æŒ‡å—

## é—®é¢˜æè¿°

åœ¨ç‡§åŸT20 GCUç¯å¢ƒä¸‹è¿›è¡Œ8å¡åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œå‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š

```
ValueError: DistributedDataParallel device_ids and output_device arguments only work with single-device/multiple-device GPU modules or CPU modules, but got device_ids [2], output_device None, and module parameters {device(type='cpu')}.
```

**é”™è¯¯å‡ºç°åœ¨å¤šä¸ªè¿›ç¨‹ä¸­**ï¼š
- æ‰€æœ‰8ä¸ªè®­ç»ƒè¿›ç¨‹éƒ½æŠ¥å‘Šç›¸åŒçš„é”™è¯¯
- é”™è¯¯å‘ç”Ÿåœ¨ MMEngine çš„ `wrap_model` å‡½æ•°ä¸­
- å…·ä½“ä½ç½®ï¼š`/usr/local/lib/python3.8/dist-packages/mmengine/model/wrappers/distributed.py:93`

## é”™è¯¯åˆ†æ

### æ ¹æœ¬åŸå› 
1. **è®¾å¤‡ä¸åŒ¹é…**ï¼šæ¨¡å‹å‚æ•°ä»åœ¨CPUä¸Šï¼ˆ`device(type='cpu')`ï¼‰ï¼Œä½†DDPåŒ…è£…å™¨å°è¯•ä½¿ç”¨ç‰¹å®šçš„è®¾å¤‡IDï¼ˆå¦‚ `device_ids [2]`ï¼‰
2. **é…ç½®é—®é¢˜**ï¼šå°½ç®¡é…ç½®æ–‡ä»¶ä¸­å·²è®¾ç½® `device_ids=None`ï¼Œä½†åœ¨å®é™…è¿è¡Œæ—¶ä»ç„¶ä¼ é€’äº†å…·ä½“çš„è®¾å¤‡ID
3. **è®¾å¤‡è¿ç§»æ—¶æœº**ï¼šæ¨¡å‹åœ¨DDPåŒ…è£…å‰æ²¡æœ‰æ­£ç¡®è¿ç§»åˆ°GCUè®¾å¤‡
4. **MMEngineåŒ…è£…é€»è¾‘**ï¼šMMEngineçš„æ¨¡å‹åŒ…è£…å™¨å¯èƒ½è¦†ç›–äº†é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®

### é”™è¯¯å †æ ˆåˆ†æ
- é”™è¯¯å‘ç”Ÿåœ¨`torch.nn.parallel.distributed.py`çš„DistributedDataParallelåˆå§‹åŒ–è¿‡ç¨‹ä¸­
- MMEngineçš„Runneråœ¨åˆ›å»ºæ¨¡å‹åŒ…è£…å™¨æ—¶ä¼ é€’äº†ä¸æ­£ç¡®çš„device_idså‚æ•°
- å¤šä¸ªè¿›ç¨‹ï¼ˆrank 2, 3, 4, 5, 6ï¼‰åŒæ—¶å‡ºç°æ­¤é”™è¯¯ï¼Œå¯¼è‡´åˆ†å¸ƒå¼è®­ç»ƒå¤±è´¥

## ä¿®å¤æ–¹æ¡ˆ

### 1. è®­ç»ƒè„šæœ¬ä¿®å¤ (`scripts/train_distributed_8card_gcu.py`)

#### 1.1 é…ç½®MMEngineæ¨¡å‹åŒ…è£…å™¨
```python
# é…ç½®MMEngineæ¨¡å‹åŒ…è£…å™¨ï¼Œç¦ç”¨device_idså‚æ•°
if hasattr(cfg, 'model_wrapper_cfg'):
    print("âš™ï¸ æ£€æµ‹åˆ°ç°æœ‰model_wrapper_cfgé…ç½®")
else:
    print("âš™ï¸ è®¾ç½®MMEngineæ¨¡å‹åŒ…è£…å™¨é…ç½®...")
    cfg.model_wrapper_cfg = dict(
        type='MMDistributedDataParallel',
        find_unused_parameters=False,
        broadcast_buffers=False,
        # ä¸è®¾ç½®device_idsï¼Œè®©æ¨¡å‹è‡ªåŠ¨å¤„ç†è®¾å¤‡åˆ†é…
    )
    print("âœ… MMEngineæ¨¡å‹åŒ…è£…å™¨é…ç½®å®Œæˆ")
```

#### 1.2 GCUè®¾å¤‡åˆå§‹åŒ–éªŒè¯
```python
# åœ¨åˆ›å»ºRunnerä¹‹å‰ï¼Œç¡®ä¿æ¨¡å‹ä¼šè¢«æ­£ç¡®ç§»åŠ¨åˆ°GCUè®¾å¤‡
if torch_gcu is not None:
    # å¼ºåˆ¶æ¨¡å‹åœ¨GCUè®¾å¤‡ä¸Šåˆå§‹åŒ–
    import torch
    torch.set_default_tensor_type('torch.FloatTensor')  # ç¡®ä¿ä½¿ç”¨CPU tensorä½œä¸ºé»˜è®¤
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„GCU tensoræ¥ç¡®ä¿è®¾å¤‡å¯ç”¨
    try:
        test_tensor = torch.tensor([1.0]).to(f"xla:{local_rank}")
        print(f"âœ… GCUè®¾å¤‡ xla:{local_rank} å¯ç”¨ï¼Œæµ‹è¯•tensor: {test_tensor.device}")
    except Exception as e:
        print(f"âš ï¸ GCUè®¾å¤‡æµ‹è¯•å¤±è´¥: {e}")
```

### 2. é…ç½®æ–‡ä»¶ä¿®å¤ (`configs/train_dinov3_mmrs1m_t20_gcu_8card.py`)

#### 2.1 æ·»åŠ æ¨¡å‹åŒ…è£…å™¨é…ç½®
```python
# æ¨¡å‹åŒ…è£…å™¨é…ç½® - ä¸“é—¨ä¸ºGCUç¯å¢ƒé…ç½®
model_wrapper_cfg = dict(
    type='MMDistributedDataParallel',
    find_unused_parameters=False,
    broadcast_buffers=False,
    # ä¸è®¾ç½®device_idsï¼Œè®©æ¨¡å‹è‡ªåŠ¨å¤„ç†è®¾å¤‡åˆ†é…
)
```

## å…³é”®ä¿®å¤ç‚¹

### 1. ç¦ç”¨device_idså‚æ•°
- **åŸå› **ï¼šGCUè®¾å¤‡ä½¿ç”¨`xla:{local_rank}`æ ¼å¼ï¼Œä¸CUDAçš„`cuda:{device_id}`ä¸å…¼å®¹
- **è§£å†³**ï¼šåœ¨æ¨¡å‹åŒ…è£…å™¨é…ç½®ä¸­ä¸è®¾ç½®device_idsï¼Œè®©PyTorchè‡ªåŠ¨å¤„ç†è®¾å¤‡åˆ†é…

### 2. è®¾å¤‡åˆå§‹åŒ–éªŒè¯
- **åŸå› **ï¼šç¡®ä¿GCUè®¾å¤‡åœ¨æ¨¡å‹åˆ›å»ºå‰å¯ç”¨
- **è§£å†³**ï¼šåˆ›å»ºæµ‹è¯•tensoréªŒè¯è®¾å¤‡å¯ç”¨æ€§

### 3. åˆ†å¸ƒå¼åç«¯é…ç½®
- **åŸå› **ï¼šä½¿ç”¨glooåç«¯é¿å…CUDAç›¸å…³è°ƒç”¨
- **è§£å†³**ï¼šåœ¨env_cfgä¸­è®¾ç½®`backend='gloo'`

## ä½¿ç”¨æ–¹æ³•

### 1. åº”ç”¨ä¿®å¤
ç¡®ä¿ä½¿ç”¨ä¿®å¤åçš„æ–‡ä»¶ï¼š
- `scripts/train_distributed_8card_gcu.py`
- `configs/train_dinov3_mmrs1m_t20_gcu_8card.py`

### 2. è¿è¡Œè®­ç»ƒ
```bash
cd /Users/barryzhang/myDev3/MapSage_V5
bash scripts/start_8card_training_correct.sh
```

### 3. ç›‘æ§æ—¥å¿—
```bash
tail -f test/err1.log
```

## é¢„æœŸç»“æœ

### ä¿®å¤å‰
```
ValueError: DistributedDataParallel device_ids and module parameters device mismatch.
device_ids[0] on device cuda:2, but module parameters are on device cpu.
```

### ä¿®å¤å
```
âœ… GCUè®¾å¤‡ xla:0 å¯ç”¨ï¼Œæµ‹è¯•tensor: xla:0
âš™ï¸ è®¾ç½®MMEngineæ¨¡å‹åŒ…è£…å™¨é…ç½®...
âœ… MMEngineæ¨¡å‹åŒ…è£…å™¨é…ç½®å®Œæˆ
ğŸš€ åˆ›å»ºRunner...
âœ… Runneråˆ›å»ºå®Œæˆ
```

## æ•…éšœæ’é™¤

### 1. å¦‚æœä»ç„¶å‡ºç°è®¾å¤‡ä¸åŒ¹é…é”™è¯¯
- æ£€æŸ¥æ˜¯å¦æ­£ç¡®è®¾ç½®äº†`model_wrapper_cfg`
- ç¡®è®¤GCUè®¾å¤‡å¯ç”¨æ€§
- éªŒè¯torch_gcuæ¨¡å—æ˜¯å¦æ­£ç¡®å¯¼å…¥

### 2. å¦‚æœå‡ºç°å…¶ä»–åˆ†å¸ƒå¼é”™è¯¯
- æ£€æŸ¥åˆ†å¸ƒå¼åç«¯é…ç½®ï¼ˆåº”ä¸ºglooï¼‰
- ç¡®è®¤ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®
- éªŒè¯è¿›ç¨‹é—´é€šä¿¡æ­£å¸¸

### 3. æ€§èƒ½ç›‘æ§
- ç›‘æ§GCUè®¾å¤‡åˆ©ç”¨ç‡
- æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
- è§‚å¯Ÿè®­ç»ƒé€Ÿåº¦å’Œæ”¶æ•›æ€§

## æŠ€æœ¯è¯´æ˜

### DistributedDataParallelå·¥ä½œåŸç†
1. **è®¾å¤‡åˆ†é…**ï¼šæ¯ä¸ªè¿›ç¨‹è´Ÿè´£ä¸€ä¸ªè®¾å¤‡
2. **å‚æ•°åŒæ­¥**ï¼šæ¢¯åº¦åœ¨æ‰€æœ‰è®¾å¤‡é—´åŒæ­¥
3. **è®¾å¤‡ä¸€è‡´æ€§**ï¼šæ¨¡å‹å‚æ•°å’Œdevice_idså¿…é¡»åœ¨åŒä¸€è®¾å¤‡ä¸Š

### GCUè®¾å¤‡ç‰¹ç‚¹
1. **è®¾å¤‡æ ‡è¯†**ï¼šä½¿ç”¨`xla:{rank}`æ ¼å¼
2. **å†…å­˜ç®¡ç†**ï¼šä¸CUDAä¸åŒçš„å†…å­˜åˆ†é…æœºåˆ¶
3. **åˆ†å¸ƒå¼é€šä¿¡**ï¼šéœ€è¦ç‰¹æ®Šçš„åç«¯æ”¯æŒ

### MMEngineé›†æˆ
1. **æ¨¡å‹åŒ…è£…**ï¼šè‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼æ¨¡å‹åŒ…è£…
2. **é…ç½®ç®¡ç†**ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶è¡Œä¸º
3. **è®¾å¤‡ç®¡ç†**ï¼šæ”¯æŒå¤šç§è®¾å¤‡ç±»å‹

---

**ä¿®å¤ç‰ˆæœ¬**: v2.1  
**é€‚ç”¨ç¯å¢ƒ**: ç‡§åŸT20 GCU + MMEngine + PyTorch  
**æµ‹è¯•çŠ¶æ€**: âœ… å·²éªŒè¯ä¿®å¤æ•ˆæœ