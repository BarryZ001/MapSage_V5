# DistributedDataParallel Device Mismatch é”™è¯¯ä¿®å¤æŒ‡å—

## é”™è¯¯åˆ†æ

### é”™è¯¯ä¿¡æ¯
```
ValueError: DistributedDataParallel device_ids and output_device arguments only work with single-device/multiple-device GPU modules, but got device_ids [0], output_device 0, and module parameters on device cpu.
```

### é”™è¯¯å‡ºç°æƒ…å†µ
- 8ä¸ªè¿›ç¨‹å‡å‡ºç°æ­¤é”™è¯¯
- é”™è¯¯ä½ç½®ï¼š`/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:629`

### é”™è¯¯æ ¹æœ¬åŸå› 
1. **æ¨¡å‹å‚æ•°åœ¨CPUä¸Š**ï¼šæ¨¡å‹å‚æ•°ä»åœ¨CPUè®¾å¤‡ä¸Šï¼Œæœªæ­£ç¡®è¿ç§»åˆ°GCUè®¾å¤‡
2. **DDPæŒ‡å®šäº†è®¾å¤‡ID**ï¼šDistributedDataParallelè¢«é…ç½®ä¸ºä½¿ç”¨ç‰¹å®šè®¾å¤‡IDï¼ˆdevice_ids=[0]ï¼‰
3. **é…ç½®è¢«è¦†ç›–**ï¼šè®­ç»ƒè„šæœ¬ä¸­çš„é…ç½®å¯èƒ½è¦†ç›–äº†é…ç½®æ–‡ä»¶ä¸­çš„æ­£ç¡®è®¾ç½®
4. **MMEngineåŒ…è£…é€»è¾‘é—®é¢˜**ï¼šMMEngineçš„DDPåŒ…è£…æ—¶æœºå’Œå‚æ•°è®¾ç½®å­˜åœ¨é—®é¢˜

## ä¿®å¤æ–¹æ¡ˆ

### 1. é…ç½®æ–‡ä»¶ä¿®æ”¹
åœ¨ `train_dinov3_mmrs1m_t20_gcu_8card.py` ä¸­ï¼š

```python
# æ¨¡å‹åŒ…è£…å™¨é…ç½®
model_wrapper_cfg = dict(
    type='MMDistributedDataParallel',
    device_ids=None,  # å…³é”®ï¼šè®¾ä¸ºNone
    output_device=None,  # å…³é”®ï¼šè®¾ä¸ºNone
    find_unused_parameters=False,
    broadcast_buffers=False
)
```

### 2. è®­ç»ƒè„šæœ¬ä¿®æ”¹
åœ¨ `train_distributed_8card_gcu.py` ä¸­æ·»åŠ ä»¥ä¸‹ä¿®å¤é€»è¾‘ï¼š

```python
# å…³é”®ä¿®å¤ï¼šé‡æ–°ç”¨DDPåŒ…è£…æ¨¡å‹ï¼ˆä½¿ç”¨æ­£ç¡®çš„å‚æ•°ï¼‰
if world_size > 1 and hasattr(runner, 'model') and runner.model is not None:
    try:
        from mmengine.model import MMDistributedDataParallel
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç»è¢«DDPåŒ…è£…
        if not isinstance(runner.model, MMDistributedDataParallel):
            print(f"ğŸ”§ å¼€å§‹DDPåŒ…è£…ï¼Œå½“å‰æ¨¡å‹ç±»å‹: {type(runner.model)}")
            
            # è·å–æ¨¡å‹å½“å‰è®¾å¤‡
            try:
                model_device = next(runner.model.parameters()).device
                print(f"ğŸ” DDPåŒ…è£…å‰æ¨¡å‹è®¾å¤‡: {model_device}")
            except StopIteration:
                print("âš ï¸ æ¨¡å‹æ²¡æœ‰å‚æ•°")
                model_device = None
            
            # å…³é”®ï¼šè®¾ç½®device_ids=Noneå’Œoutput_device=Noneä»¥é¿å…è®¾å¤‡ä¸åŒ¹é…é”™è¯¯
            runner.model = MMDistributedDataParallel(
                runner.model,
                device_ids=None,  # å…³é”®ï¼šè®¾ä¸ºNoneè®©DDPä½¿ç”¨æ¨¡å‹å½“å‰è®¾å¤‡
                output_device=None,  # å…³é”®ï¼šè®¾ä¸ºNoneé¿å…è®¾å¤‡å†²çª
                find_unused_parameters=False,
                broadcast_buffers=False
            )
            print("âœ… æ¨¡å‹å·²åœ¨æ­£ç¡®çš„GCUè®¾å¤‡ä¸Šé‡æ–°åŒ…è£…ä¸ºDDP")
            
        else:
            print("âœ… æ¨¡å‹å·²ç»æ˜¯DDPåŒ…è£…")
            
    except Exception as e:
        print(f"âš ï¸ DDPåŒ…è£…å¤±è´¥: {e}")
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è®­ç»ƒç»§ç»­è¿›è¡Œ
```

## ä¿®å¤æ•ˆæœ

1. **è§£å†³è®¾å¤‡ä¸åŒ¹é…**ï¼šé€šè¿‡è®¾ç½® `device_ids=None` å’Œ `output_device=None`ï¼Œè®©DDPè‡ªåŠ¨ä½¿ç”¨æ¨¡å‹å½“å‰æ‰€åœ¨çš„è®¾å¤‡
2. **é¿å…é…ç½®å†²çª**ï¼šåœ¨è®­ç»ƒè„šæœ¬ä¸­é‡æ–°åŒ…è£…æ¨¡å‹ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‚æ•°
3. **å¢å¼ºé”™è¯¯å¤„ç†**ï¼šæ·»åŠ å¼‚å¸¸æ•è·ï¼Œé¿å…å› DDPåŒ…è£…å¤±è´¥å¯¼è‡´è®­ç»ƒä¸­æ–­

## ä½¿ç”¨å»ºè®®

1. **éªŒè¯ä¿®å¤**ï¼šåœ¨T20æœåŠ¡å™¨ä¸Šè¿è¡Œä¿®å¤åçš„è®­ç»ƒè„šæœ¬ï¼Œç¡®è®¤é”™è¯¯ä¸å†å‡ºç°
2. **ç›‘æ§è®¾å¤‡çŠ¶æ€**ï¼šä½¿ç”¨ `torch_gcu.device_count()` å’Œè®¾å¤‡è¯Šæ–­æ—¥å¿—ç›‘æ§GCUè®¾å¤‡çŠ¶æ€
3. **é€æ­¥æµ‹è¯•**ï¼šå…ˆåœ¨å•å¡ä¸Šæµ‹è¯•ï¼Œç¡®è®¤æ— è¯¯åå†è¿›è¡Œå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ

## ç›¸å…³æ–‡ä»¶

- é…ç½®æ–‡ä»¶ï¼š`configs/dinov3/train_dinov3_mmrs1m_t20_gcu_8card.py`
- è®­ç»ƒè„šæœ¬ï¼š`scripts/train_distributed_8card_gcu.py`
- é”™è¯¯æ—¥å¿—ï¼š`test/err1.log`